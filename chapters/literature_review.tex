\chapter{Background and Significance}\label{section:lit_review}

% Provide a high-level overview of the literature this work aims to build on.

My thesis aims to build on prior work on safety verification (both model-based and black-box) and program analysis (in the form of differentiable and probabilistic programming). This section will review each of these fields with an eye towards framing the significance of my planned thesis contributions.

\subsection{Safety verification}

% general motivation, high-level problem statement.

% Split on model-based/model-free, segue

Safety and robustness are critical concerns for any robotic system, and there is a correspondingly large body of work studying how to verify safety properties for autonomous systems. These approaches can be broadly categorized into \textit{model-based} and \textit{model-free} works. Model-based approaches rely on a mathematical model of the system to be verified, and use this model to prove that the system satisfies the desired safety properties. Model-free approaches, on the other hand, do not require a mathematical model of the system, and instead use a large number of samples of the system's input-output behavior to characterize its safety.

Regardless of approach, verification methods typically aim to solve one of three problems~\cite{corsoSurveyAlgorithmsBlackBox2021}: falsification, likely failure analysis, or failure probability estimation. Denote the disturbance space $y \in \mathcal{Y} \subseteq \R^n$, a simulator $f \maps \mathcal{Y} \to \Xi$ that maps disturbances to system traces $\xi$, and a specification $\psi \maps \Xi \to \R$ that determines whether a trace satisfies ($\psi(\xi) \geq 0$) or does not satisfy ($\psi(\xi) < 0$) the safety constraints. In this context, the falsification problem involves solving an optimization for a counterexample
%
\begin{equation}
    \text{find } {y \in \mathcal{Y}} \text{ s.t. } \psi(f(y)) < 0
\end{equation}
%
which is commonly reparameterized as a minimization problem to find the worst counterexample
%
\begin{equation}
    \min_{y \in \mathcal{Y}} \psi(f(y))\label{ch4:eq:falsification_opt}
\end{equation}
%
The likely failure analysis problem adds information about the prior distribution of disturbances $p(y)$ and aims to find the most likely counterexample
%
\begin{equation}
    \max_{y \in \mathcal{Y}} p(y) \text{ s.t. } \psi(f(y)) < 0 \label{ch4:eq:likely_failure_opt}
\end{equation}
%
Finally, the failure probability estimation problem aims to estimate the probability that the system violates the safety constraints
%
\begin{equation}
    \Pr\left[\psi(f(y)) < 0\right] = \mathbb{E}_{y \sim p(y)}\left[\mathbbm{1}\{\psi(f(y))\} \right] \label{ch4:eq:failure_probability}
\end{equation}

\subsubsection{Model-based safety verification}

% Historical context

% Logical models: sat, extension to SMT

% Dynamical systems: reachability, HJB, certificates

% limitations on complexity of model; segue

Early approaches to model-based verification and fault identification used symbolic logical models of the system under test to formally reason about failures using (computationally expensive) satisfiability (SAT) solvers or search~\cite{dekleerDiagnosingMultipleFaults1987,benardRemoteAgentExperiment2000}. More recent approaches to model-based failure mode identification have used mathematical models of the system dynamics to frame the problem through the lens of reachability~\cite{annpureddySTaLiRoToolTemporal2011,bansalHamiltonJacobiReachabilityBrief2017}, optimal control~\cite{chouUsingControlSynthesis2018}, or optimization (e.g. sum-of-squares, or SoS~\cite{ahmadiApplicationsPolynomialOptimization2016,majumdarControlVerificationHighdimensional2014}).

The primary challenge facing all of these methods is that it may be difficult or impossible to construct a symbolic model for the system under test. For example, simulating the dynamics of a power transmission system or certain contact models requires solving an optimization problem and does not have a closed form. Even when it is theoretically possible to obtain a closed-form symbolic model, in practice the need to construct and manipulate large sets of equations introduces the possibility of error and requires a large amount of human effort. Historically, this difficulty motivated the development of model-free approaches to safety verification.

\subsubsection{Black-box safety verification}

% Motivation, historical context

In practice, although we may not have access to a mathematical or symbolic model of a system, we often have access to a simulator instead, motivating a set of so-called ``black-box'' methods. These methods are characterized by restricting the verification algorithm to sampling input-output pairs from the simulator without side information such as gradients~\cite{corsoSurveyAlgorithmsBlackBox2021}. Since black-box methods are usually quite easy to integrate with an existing simulator (often relying on a standardized API such as the OpenAI Gym interface~\cite{brockmanOpenAIGym2016}), they have seen widespread use, particularly in verification for autonomous vehicles~\cite{xuSafeBenchBenchmarkingPlatform2022,riedmaierSurveyScenarioBasedSafety2020,okellyScalableEndtoEndAutonomous2018,corsoAdaptiveStressTesting2019,wangAdvSimGeneratingSafetyCritical2021,sunCornerCaseGeneration2021,zhongGuidedConditionalDiffusion2022,corsoInterpretableSafetyValidation2020a,zhangAdversarialRobustnessTrajectory2022,hanselmannKINGGeneratingSafetyCritical2022a}. The three most common types of black-box verification method involve black-box optimization, reinforcement learning, or black-box inference methods~\cite{corsoSurveyAlgorithmsBlackBox2021}.

\paragraph{Black-box optimization} uses the optimization formulations in Eq.~\eqref{ch4:eq:falsification_opt} or Eq.~\eqref{ch4:eq:likely_failure_opt} to search for a set of inputs that violate the safety property of interest, using methods like Bayesian optimization~\cite{wangAdvSimGeneratingSafetyCritical2021}, REINFORCE~\cite{dingLearningCollideAdaptive2020a}, and ant colony optimization~\cite{annpureddySTaLiRoToolTemporal2011}. There are a large number of subtly-different black-box optimization schemes that could be applied to this problem~\cite{kochenderfer_wheeler_2019}, all making different tradeoffs between exploration and exploitation.

\paragraph{Reinforcement learning} break the monolithic optimization problem in Eq.~\eqref{ch4:eq:falsification_opt} into a sequential decision making problem by simulating single steps rather than entire trajectories, then optimizing a policy that maximizes a reward that encourages violation of the safety property~\cite{corsoAdaptiveStressTesting2019}. This reward is often hand-designed using domain expertise, e.g. by rewarding an adversarial vehicle for reducing the distance between it and the vehicle under test~\cite{dingLearningCollideAdaptive2020a}.

\paragraph{Black-box inference} takes inspiration from algorithms for approximate Bayesian inference and are most often applied to the failure probability estimation~\cite{okellyScalableEndtoEndAutonomous2018} and likely failure mode problems~\cite{zhouRoCUSRobotController2021}. To estimate failure probability, \cite{okellyScalableEndtoEndAutonomous2018} uses adaptive importance sampling to guide exploration of the search space towards regions that are more likely to induce a failure (while adjusting the failure probability estimate to account for this biased exploration). To generate likely failure modes, \cite{zhouRoCUSRobotController2021} uses gradient-free Markov chain Monte Carlo (MCMC) to sample failure modes that are likely to induce a failure.

% \subsubsection{Adversarial optimization}

% Once we have generated a counterexample, using either a model-based or black-box method, a natural next question is how we might use that counterexample to guide further optimization of the system. The idea that counterexamples can be used for continued optimization to improve the robustness of a system is they key idea behind a body of work on adversarial optimization (or adversarial training in the machine learning literature). Verification using adversarial optimization has been applied in both model-based~\cite{dontiAdversariallyRobustLearning2021,yaghoubiGrayboxAdversarialTesting2018} and model-free~\cite{corsoSurveyAlgorithmsBlackBox2021} contexts. Generally speaking, model-based adversarial techniques use gradient-based optimization to locally search for adversarial examples that cause a system failure, then use gradient-based optimization to locally repair those failures~\cite{dontiAdversariallyRobustLearning2021}. The drawback of these methods is that they are inherently local and typically yield only a single adversarial counterexample. Model-free approaches~\cite{corsoSurveyAlgorithmsBlackBox2021} can avoid the issue of local minima by using black-box optimization techniques but incur additional computational cost as a result.

\subsubsection{Limitations and significance}

In the context of prior work on model-based and black-box safety verification, this thesis aims to address two major technical gaps.

\paragraph{Model-based approaches are difficult to scale to complex systems} The requirement of a symbolic model is either theoretically impossible (when closed-form models do not exist) or practically infeasible (for large-scale systems with multiple interacting subsystems). The difficulty of constructing symbolic models by hand motivates my work in this thesis, which seeks to automatically extract information about the mathematical structure of a system from the simulator using program analysis techniques (discussed in the next section).

\paragraph{Black-box methods struggle with sample complexity} Lacking access to gradient information that could help guide their exploration of high-dimensional spaces, black-box methods often struggle to scale to high-dimensional problems, or (if they can scale) require a large number of simulated rollouts to converge. Although black-box methods are easy to integrate with existing simulators, these scalability and sample-complexity issues motivate my work in this thesis, which seeks to improve scalability and sample complexity by incorporating additional side information (e.g. automatically-derived gradients) into the optimization process.

\subsection{Programs as mathematical models}

Historically, symbolic models have been synonymous with hand derivation, a tedious and error-prone process that does not scale to complex systems. However, recent work in the programming languages community has shown that there is an alternate way to construct these models: by exploiting the rich mathematical structure available embedded in computer programs themselves.

In practice, often the term ``black-box'' is used to describe the setting where we have access to a computer program implementing a simulator of the system under test. The next two sections will show how we can obtain varying degrees of introspection into the structure of these programs using program analysis methods, effectively granting the ability to look inside the black box. In particular, we will discuss two exciting program analysis techniques that are relevant to this thesis: automatic differentiation (which treats computer programs as mathematical functions that can be differentiated) and probabilistic programming (which treats stochastic programs as graphical models that can be used for Bayesian inference).

\subsubsection{Automatic differentiation}

Perhaps the most well-known (and widely-used) program analysis method in the machine learning and robotics communities is automatic differentiation (autodiff, or AD). AD achieved widespread use in the form of backpropagation for training neural networks~\cite{rumelhartLearningRepresentationsBackpropagating1986}. The popularity of neural networks prompted the development of differentiable tensor math libraries such as PyTorch~\cite{pytorch}, TensorFlow~\cite{tensorflow2015-whitepaper}, and JAX~\cite{jax2018github}, and specialized AD tools followed in the form of differentiable optimization layers \cite{agrawalDifferentiableConvexOptimization2019}, simulators \cite{huDiffTaichiDifferentiableProgramming2019}, renderers~\cite{huDiffTaichiDifferentiableProgramming2019,lelidecDifferentiableRenderingPerturbed2021}, and even task specifications~\cite{leungBackPropagationSignalTemporal2021}, to name but a few (the discussion in this document is largely Python-focused, but similar ecosystems exist in Julia, C++, and other LLVM languages~\cite{NEURIPS2020_9332c513}).

At a high level, the aim of automatic differentiation is to allow the user to implement some function $y = f(x): \R^n \mapsto \R^m$ and then provide the ability, without writing any additional code, to obtain the Jacobian $Df(x) \in \R^{m\times n}$. This is typically done in one of two ways, referred to as forward- and reverse-mode AD, respectively. In the interest of space, this document will provide only a brief overview of these two methods; \cite{AutodiffCookbookJAX} provides a more thorough introduction.

Forward-mode AD computes the product between a vector in the input tangent space $\delta x$ and the Jacobian, ``pushing forward'' into the tangent space of the output $\delta x \mapsto \delta y = Df(x) \delta x$. As a result, forward-mode AD is sometimes referred to as the Jacobian-vector product (JVP) or the pushforward map. It is typically implemented by operator overloading, in which primitive operations (e.g. $+$, $\times$, $\sin$, etc.) are overloaded to operate on a new data type that carries both the primal $x$ and tangent $\delta x$. As the function is computed and each primitive operation is carried out, the tangent value is updated using hand-derived derivative rules for each operation. The benefit of forward-mode AD is that its memory usage is constant with respect to the number of operations used to define $f$ (roughly double the memory usage of just evaluating the function value). The potential downside is that computing the Jacobian requires one primal and tangent evaluation of $f$ for each column of the Jacobian; this is fine for functions with few inputs and many outputs, but does not scale to typical machine learning applications (where we often wish to differentiate with respect to thousands of model parameters).

Reverse-mode AD computes the product of a vector in the output tangent space $\delta y$ and the transposed Jacobian, ``pulling back'' into the tangent space of the input $\delta y \mapsto \delta x = Df(x)^T \delta y$, and it is referred to as the pullback map or vector-Jacobian product (VJP) accordingly. This mode is typically implemented as generalized backpropagation that tracks which primitive operations are applied in evaluating the output value $y = f(x)$ and constructs a computation graph. To compute the derivative, we trace backwards through the computation graph, applying derivative rules for each computation. The benefit of this method is that computing the full Jacobian requires one forward and backward pass for each row of the Jacobian, which is much more efficient in practice for systems with many input parameters and few outputs (including typical ML and optimization applications where there are many parameters or decision variables that yield a scalar objective output). The downside of this mode is that it is much more memory intensive, since the results of intermediate operations during the forward pass are typically cached and reused during the backwards pass, and the memory requirements scale linearly with the size of the function's computation graph.

Both of these modes require hand-derived derivative rules for the primitive operations used in computing $f$; however, in certain cases these rules may be overridden to provide more accurate or numerically stable gradients. An important case that commonly arises in robotics is the case where $f$ involves solving either an optimization (e.g. $f(x) = \argmin_y g(y, x)$) or root-finding problem (e.g. $f(x) = \text{find}_y \text{ s.t. } g(y, x) = 0$). In practice, these problems are solved iteratively, but na\"ively differentiating the primitive operations applied in each iteration is both costly and inaccurate. Instead, these optimization and root-finding problems are treated as primitive operations for the purposes of AD, and the derivative rules are found automatically using the implicit function theorem~\cite{agrawalDifferentiableConvexOptimization2019}. This approach allows for accurate differentiation of implicit dynamics (including certain contact models~\cite{howelllecleach2022}), rendering (since raytracing is a root-finding procedure), and optimization-based control.

It is important to note that although the gradients derived from AD are often referred to as exact or analytic, they are still only estimates of the true gradient. Most commonly used AD systems are not sound, admitting pathological inputs that can yield arbitrarily wrong gradients when differentiated (e.g. $f(x) = \set{x \text{ if } x \neq 0;\ -x \text{ otherwise}}$, which is identically equal to $y = x$ in both value and gradient but yields $df/dx(0) = -1$ when differentiated with most AD libraries). It is possible to detect some of these pathological cases, either at runtime or at compile-time, but even non-pathological functions can be stiff (with very large gradients), non-smooth, or even discontinuous. As a result, it is important to consider how these inaccuracies will affect downstream consumers of the gradient (e.g. for optimization). The downstream effects of these artifacts is an active area of research~\cite{suh2021_bundled_gradients,suhDifferentiableSimulatorsGive2022,metzGradientsAreNot2022}.

\paragraph{Significance of proposed thesis} The last few years have seen a surge of applications of AD, including robotics problems such as control synthesis and system identification~\cite{xuAcceleratedPolicyLearning2022,agrawalDifferentiableConvexOptimization2019,amosOptNetDifferentiableOptimization2017,belubute_peres_lcp_physics,du2021underwater}. However, despite these successful applications, two important research questions remain to be answered in this thesis. First, since both modes of AD require more computation than a standard function evaluation, we must ask whether the derivative juice is worth the computational squeeze. That is, do AD-derived gradients provide enough of a performance increase on downstream tasks, relative to gradient-free optimizers or zero-order gradient estimates and evaluated on robotics-relevant benchmarks, to merit this additional computational expense? Second, given that AD can yield poorly-conditioned gradients on many problems of interest for robotics, can we design downstream algorithms that are robust to variance or inaccuracy in the gradients they receive?

\subsubsection{Probabilistic programming}

Differentiable programming, although popular, is just the tip of the program analysis iceberg. Another promising emerging field of program analysis is that of probabilistic programming, which extends its view to include programs that make random choices (e.g. by querying a random number generator). Probabilistic programming takes the perspective that the computation graph of such a program can be viewed as a graphical probabilistic model (e.g. Bayesian network) that encodes a joint distribution over variables involved in the computation~\cite{woodNewApproachProbabilistic2014}. With this mindset, we can gain an additional level of introspection into the behavior of a program by automatically deriving this graphical model and applying approximate Bayesian inference techniques; for instance conditioning on certain variables and estimating the posterior distribution.

It is important to note that probabilistic programming is not an alternative to AD (in fact, most probabilistic programming frameworks rely on AD). AD treats programs as mathematical functions that can be differentiated, and probabilistic programming assigns a semantic meaning to those derivatives in the context of probabilistic inference problems. Moreover, while it is relatively easy to port existing code to use AD (e.g. replacing \texttt{numpy} with \texttt{jax.numpy} in Python), probabilistic programming frameworks require additional annotation of the source code, often defining additional syntax to annotate random choices (so that such choices can be traced and referred to while solving inference problems).

Treating programs as probabilistic models offers a number of benefits. Both constrained and unconstrained optimization problems can be transcribed as posterior inference problems (this is the optimization-as-inference approach discussed in~\cite{maSamplingCanBe2019,levineReinforcementLearningControl2018a}), but inference also allows us to answer questions such as the likely failure analysis problem in~\eqref{ch4:eq:likely_failure_opt}. In addition, the probabilistic mindset allows us to deal with models that combine continuous and discrete choices in a principled way (as hybrid continuous-discrete graphical models) and design inference algorithms accordingly~\cite{cusumano-townerGenGeneralpurposeProbabilistic2019}. Finally, probabilistic programming can also be applied to program synthesis, since the structure of the program's computation graph can itself be seen as the output of a stochastic program-generating process, allowing us to use conditional inference to search over the space of programs that might solve a particular problem~\cite{cusumano-townerAutomatingInvolutiveMCMC2020}.

\paragraph{Significance of proposed thesis} Probabilistic programming has been applied to a large number of problems in statistical inference; in fact, many of its original applications involved automating (with a convenient programming interface) traditional statistical inference tasks such as regression and hierarchical modeling~\cite{cusumano-townerGenGeneralpurposeProbabilistic2019}. Although probabilistic graphical models such as factor graphs have been applied widely in robotics, with deep roots in the SLAM community~\cite{dellaertFactorGraphsExploiting2021}, these methods have experienced some of the same hurdles as traditional model-based verification methods discussed above: it is difficult to derive these models by hand, particularly for complex dynamical systems found in traditional ``black-box'' settings. This thesis will close this gap by applying probabilistic programming to automatically generating these models for robotics safety verification and optimization problems.
