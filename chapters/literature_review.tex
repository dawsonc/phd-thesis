\chapter{Background and Significance}\label{section:lit_review}

This section provides an overview of relevant literature, with an eye towards framing the significance of the contributions of this thesis. Where relevant, later chapters will also include a focused review of literature specific to the problems studied in each chapter.

\section{Safety verification}

Safety and robustness are critical concerns for any robotic system, and there is a correspondingly large body of work studying how to verify safety properties for autonomous systems. These approaches can be broadly categorized into \textit{model-based} and \textit{model-free} works. Model-based approaches rely on a mathematical model of the system to be verified, and use this model to prove that the system satisfies the desired safety properties. Model-free approaches, on the other hand, do not require a mathematical model of the system, instead using a large number of samples of the system's input-output behavior to characterize its safety.

Regardless of approach, verification methods typically aim to solve one of three problems~\cite{corsoSurveyAlgorithmsBlackBox2021}: falsification, likely failure analysis, or failure probability estimation. Denote the disturbance space $y \in \mathcal{Y} \subseteq \R^n$, a simulator $f \maps \mathcal{Y} \to \Xi$ that maps disturbances to system traces $\xi$, and a specification $\psi \maps \Xi \to \R$ that determines whether a trace satisfies ($\psi(\xi) \geq 0$) or does not satisfy ($\psi(\xi) < 0$) the safety constraints. In this context, the falsification problem involves solving an optimization for a counterexample
%
\begin{equation}
	\text{find } {y \in \mathcal{Y}} \text{ s.t. } \psi(f(y)) < 0
\end{equation}
%
which is commonly reparameterized as a minimization problem to find the worst counterexample
%
\begin{equation}
	\min_{y \in \mathcal{Y}} \psi(f(y))\label{ch4:eq:falsification_opt}
\end{equation}
%
The likely failure analysis problem adds information about the prior distribution of disturbances $p(y)$ and aims to find the most likely counterexample
%
\begin{equation}
	\max_{y \in \mathcal{Y}} p(y) \text{ s.t. } \psi(f(y)) < 0 \label{ch4:eq:likely_failure_opt}
\end{equation}
%
Finally, the failure probability estimation problem aims to estimate the probability that the system violates the safety constraints
%
\begin{equation}
	\Pr\left[\psi(f(y)) < 0\right] = \mathbb{E}_{y \sim p(y)}\left[\mathbbm{1}\{\psi(f(y))\} \right] \label{ch4:eq:failure_probability}
\end{equation}

In this thesis, we focus primarily on falsification and likely failure analysis.

\subsection{Model-based safety verification}

Early approaches to model-based verification and fault identification use symbolic logical models of the system under test to formally reason about failures using computationally expensive tools like satisfiability (SAT) solvers or search~\cite{dekleerDiagnosingMultipleFaults1987,benardRemoteAgentExperiment2000}. More recent approaches to model-based failure identification use mathematical models of the system dynamics to frame the problem through the lens of reachability~\cite{annpureddySTaLiRoToolTemporal2011,bansalHamiltonJacobiReachabilityBrief2017}, optimal control~\cite{chouUsingControlSynthesis2018}, or optimization (e.g. sum-of-squares~\cite{ahmadiApplicationsPolynomialOptimization2016,majumdarControlVerificationHighdimensional2014}).

The primary challenge facing all of these methods is that it may be difficult or impossible to construct a symbolic model for the system under test. For example, simulating the dynamics of a power transmission system or certain contact models requires solving an optimization problem and does not have a closed form. Even when it is theoretically possible to obtain a closed-form symbolic model, in practice the need to construct and manipulate large sets of equations introduces the possibility of error and requires a large amount of human effort. Historically, this difficulty motivated the development of model-free approaches to safety verification.

\subsection{Black-box safety verification}

In practice, although we may not have access to a mathematical or symbolic model of a system, we often have access to a simulator instead, motivating a set of so-called ``black-box'' methods. These methods are restricted to sampling input-output pairs from the simulator without side information such as gradients~\cite{corsoSurveyAlgorithmsBlackBox2021}. Since black-box methods are usually quite easy to integrate with an existing simulator (often relying on a standardized API such as the OpenAI Gym interface~\cite{brockmanOpenAIGym2016}), they have seen widespread use, particularly in verification for autonomous vehicles~\cite{xuSafeBenchBenchmarkingPlatform2022,riedmaierSurveyScenarioBasedSafety2020,okellyScalableEndtoEndAutonomous2018,corsoAdaptiveStressTesting2019,wangAdvSimGeneratingSafetyCritical2021,sunCornerCaseGeneration2021,zhongGuidedConditionalDiffusion2022,corsoInterpretableSafetyValidation2020a,zhangAdversarialRobustnessTrajectory2022,hanselmannKINGGeneratingSafetyCritical2022a}. The three most common types of black-box verification method involve black-box optimization, reinforcement learning, or black-box inference methods~\cite{corsoSurveyAlgorithmsBlackBox2021}.

\paragraph{Black-box optimization} These methods use the optimization formulations in Eq.~\eqref{ch4:eq:falsification_opt} or Eq.~\eqref{ch4:eq:likely_failure_opt} to search for a set of inputs that violate the safety property of interest, using methods like Bayesian optimization~\cite{wangAdvSimGeneratingSafetyCritical2021}, REINFORCE~\cite{dingLearningCollideAdaptive2020a}, and ant colony optimization~\cite{annpureddySTaLiRoToolTemporal2011}. There are a large number of subtly-different black-box optimization schemes that could be applied to the verification problem~\cite{kochenderfer_wheeler_2019}, all making different trade-offs between exploration and exploitation.

\paragraph{Reinforcement learning (RL)} RL breaks the monolithic optimization problem in Eq.~\eqref{ch4:eq:falsification_opt} into a sequential decision making problem by simulating single steps rather than entire trajectories, then optimizing a policy that maximizes a reward that encourages violation of the safety property~\cite{corsoAdaptiveStressTesting2019}. This reward is often hand-designed using domain expertise, e.g. by rewarding an adversarial vehicle for reducing the distance between it and the vehicle under test~\cite{dingLearningCollideAdaptive2020a}.

\paragraph{Black-box inference} These methods take inspiration from algorithms for approximate Bayesian inference and are most often applied to the failure probability estimation~\cite{okellyScalableEndtoEndAutonomous2018} and likely failure mode problems~\cite{zhouRoCUSRobotController2021}. To estimate failure probability, \cite{okellyScalableEndtoEndAutonomous2018} uses adaptive importance sampling to guide exploration of the search space towards regions that are more likely to induce a failure (while adjusting the failure probability estimate to account for this biased exploration). To generate likely failure modes, \cite{zhouRoCUSRobotController2021} uses gradient-free Markov chain Monte Carlo (MCMC) to sample failure modes that are likely to induce a failure, while \cite{okellyScalableEndtoEndAutonomous2018} uses adaptive importance sampling to accomplish a similar goal.

\subsection{Limitations}

In the context of prior work on model-based and black-box safety verification, this thesis aims to address two major technical gaps.

\paragraph{Model-based approaches are difficult to scale to complex systems} The requirement of a symbolic model is either theoretically impossible (when closed-form models do not exist) or practically infeasible (for large-scale systems with multiple interacting subsystems). The difficulty of constructing symbolic models by hand motivates the work in this thesis, which seeks to automatically extract information about the mathematical structure of a system from the simulator using program analysis techniques (discussed in the next section).

\paragraph{Black-box methods struggle with sample complexity} Lacking access to gradient information, black-box methods often struggle to scale to high-dimensional problems, or (if they can scale) require a large number of simulated rollouts to converge. Although black-box methods are easy to integrate with existing simulators, these scalability and sample-complexity issues also motivate the work in this thesis, which seeks to improve scalability and sample complexity by incorporating additional side information (e.g. automatically-derived gradients) into the optimization process.

\section{Programs as mathematical models}

Historically, symbolic models have been synonymous with hand derivation, a tedious and error-prone process that does not scale to complex systems. However, recent work in the programming languages community has shown that there is another way to construct these models: by exploiting the rich mathematical structure embedded in computer programs themselves.

In practice, the term ``black-box'' is often used to describe the setting where we have access to a computer program implementing a simulator of the system under test. The next two sections will show how we can obtain varying degrees of transparency into the structure of these programs using program analysis methods, effectively granting the ability to look inside the black box. In particular, we will discuss two exciting program analysis techniques that are relevant to this thesis: automatic differentiation (which treats computer programs as mathematical functions that can be differentiated) and probabilistic programming (which treats stochastic programs as graphical models that can be used for Bayesian inference).

\subsection{Automatic differentiation}

Perhaps the most well-known (and widely-used) program analysis method in the machine learning and robotics communities is automatic differentiation (autodiff, or AD). AD achieved widespread use in the form of backpropagation for training neural networks~\cite{rumelhartLearningRepresentationsBackpropagating1986}. The popularity of neural networks prompted the development of differentiable tensor math libraries such as PyTorch~\cite{pytorch}, TensorFlow~\cite{tensorflow2015-whitepaper}, and JAX~\cite{jax2018github}. Following these general-purpose libraries, a number of specialized AD have also emerged in the form of differentiable optimization layers \cite{agrawalDifferentiableConvexOptimization2019}, physical simulators~\cite{huDiffTaichiDifferentiableProgramming2019}, renderers~\cite{huDiffTaichiDifferentiableProgramming2019,lelidecDifferentiableRenderingPerturbed2021}, and even formal task specifications~\cite{leungBackPropagationSignalTemporal2021}, to name but a few.\footnote{The discussion in this document is focused on the Python ecosystem, but similar tools exist in Julia, C++, and other LLVM languages~\cite{NEURIPS2020_9332c513}.}

At a high level, the aim of automatic differentiation is to allow the user to implement some function $y = f(x): \R^n \rightarrow \R^m$ and then obtain the Jacobian $Df(x) \in \R^{m\times n}$ without writing any additional code. This is typically done in one of two ways, referred to as forward- and reverse-mode AD, respectively. In the interest of space, this document will provide only a brief overview of these two methods; \cite{AutodiffCookbookJAX} provides a more thorough introduction.

Forward-mode AD computes the product between a vector in the input tangent space $\delta x$ and the Jacobian, ``pushing forward'' into the tangent space of the output $\delta x \rightarrow \delta y = Df(x) \delta x$. As a result, forward-mode AD is sometimes referred to as the Jacobian-vector product (JVP) or the pushforward map. It is typically implemented by operator overloading, in which primitive operations (e.g. $+$, $\times$, $\sin$, etc.) are overloaded to operate on a new data type that carries both the primal $x$ and tangent $\delta x$. As the function is computed and each primitive operation is carried out, the tangent value is updated using hand-derived derivative rules for each operation. The benefit of forward-mode AD is that its memory usage is constant with respect to the number of operations used to define $f$ (roughly double the memory usage of evaluating the function value alone). The potential downside is that computing the Jacobian requires one primal and tangent evaluation of $f$ for each column of the Jacobian; this is fine for functions with few inputs and many outputs, but does not scale to typical machine learning applications (where we often wish to differentiate with respect to thousands of model parameters).

Reverse-mode AD computes the product of a vector in the output tangent space $\delta y$ and the transposed Jacobian, ``pulling back'' into the tangent space of the input $\delta y \rightarrow \delta x = Df(x)^T \delta y$, and it is referred to as the pullback map or vector-Jacobian product (VJP) accordingly. This mode is typically implemented as generalized backpropagation, constructing a computation graph containing the primitive operations applied while evaluating $y = f(x)$. To compute the derivative, we trace backwards through the computation graph, applying derivative rules for each computation. The benefit of this method is that computing the full Jacobian requires one forward and backward pass for each row of the Jacobian, which is much more efficient for systems with many input parameters and few outputs (including typical ML and optimization applications where there are many parameters or decision variables that yield a scalar objective output). The downside of this mode is that it is much more memory intensive, since the results of intermediate operations during the forward pass are typically cached and reused during the backwards pass, and the memory requirements scale linearly with the size of the computation graph.

Both of these modes require hand-derived derivative rules for the primitive operations used in computing $f$; however, in certain cases these rules may be overridden to provide more accurate or numerically stable gradients. An important case that commonly arises in robotics is the case where $f$ involves solving either an optimization (e.g. $f(x) = \argmin_y g(y, x)$) or root-finding problem (e.g. $f(x) = \text{find}_y \text{ s.t. } g(y, x) = 0$). In practice, these problems are solved iteratively, but na\"ively differentiating the primitive operations applied in each iteration is both costly and inaccurate. Instead, these optimization and root-finding problems are treated as primitive operations for the purposes of AD, and the derivative rules are found automatically using the implicit function theorem~\cite{agrawalDifferentiableConvexOptimization2019}. This approach allows for accurate differentiation of implicit dynamics (including certain contact models~\cite{howelllecleach2022}), rendering (since raytracing is a root-finding procedure), and optimization-based control.

It is important to note that although the gradients derived from AD are often referred to as exact or analytic, they are still only estimates of the true gradient. Most commonly used AD systems are not sound, admitting pathological inputs that can yield arbitrarily wrong gradients when differentiated (e.g. $f(x) = \set{x \text{ if } x \neq 0;\ -x \text{ otherwise}}$, which is identically equal to $y = x$ in both value and gradient but yields $df/dx(0) = -1$ when differentiated with most AD libraries). It is possible to detect some of these pathological cases, either at runtime or at compile-time, but even non-pathological functions can be stiff (with very large gradients), non-smooth, or even discontinuous. As a result, it is important to consider how these inaccuracies will affect downstream consumers of the gradient (e.g. for optimization). The downstream effects of these artifacts is an active area of research~\cite{suh2021_bundled_gradients,suhDifferentiableSimulatorsGive2022,metzGradientsAreNot2022}.

\paragraph{Significance of this thesis} The last few years have seen a surge of applications of AD, including robotics problems such as control synthesis and system identification~\cite{xuAcceleratedPolicyLearning2022,agrawalDifferentiableConvexOptimization2019,amosOptNetDifferentiableOptimization2017,belubute_peres_lcp_physics,du2021underwater}. However, despite these successful applications, two important research questions remain to be answered in this thesis. First, since both modes of AD require more computation than a standard function evaluation, we must ask whether the derivative juice is worth the computational squeeze. That is, do AD-derived gradients provide enough of a performance increase on downstream tasks, relative to gradient-free optimizers or zero-order gradient estimates and evaluated on robotics-relevant benchmarks, to merit this additional computational expense? Second, given that AD can yield poorly-conditioned gradients on many problems of interest for robotics, can we design downstream algorithms that are robust to variance or inaccuracy in the gradients they receive? We will answer both of these questions in the affirmative in the following chapters.

\subsection{Probabilistic programming}

Differentiable programming, although popular, is just the tip of the program analysis iceberg. Another promising type of program analysis is probabilistic programming, which considers programs that make random choices (e.g. by querying a random number generator). Probabilistic programming views the computation graph of such a program as a graphical probabilistic model (e.g. Bayesian network) that encodes a joint distribution over variables involved in the computation~\cite{woodNewApproachProbabilistic2014}. With this mindset, we can gain an additional level of transparency into the behavior of a program by automatically deriving this graphical model and applying approximate Bayesian inference techniques; for instance conditioning on certain variables and estimating the posterior distribution.

It is important to note that probabilistic programming is not an alternative to AD; in fact, most probabilistic programming frameworks rely on AD. AD treats programs as mathematical functions that can be differentiated, and probabilistic programming assigns a semantic meaning to those derivatives in the context of probabilistic inference problems. Moreover, while it is relatively easy to port existing code to use AD (e.g. replacing \texttt{numpy} with \texttt{jax.numpy} in Python), probabilistic programming requires additional changes the source code, often defining additional syntax to annotate random choices (so that those choices can be traced and referred to while solving inference problems).

Treating programs as probabilistic models offers a number of benefits. Both constrained and unconstrained optimization problems can be transcribed as posterior inference problems (this is the optimization-as-inference approach discussed in~\cite{maSamplingCanBe2019,levineReinforcementLearningControl2018a} and explored in detail in Chapter~\ref{ch:corl}), but inference also allows us to answer questions such as the likely failure analysis problem in~\eqref{ch4:eq:likely_failure_opt}.
% In addition, the probabilistic mindset allows us to deal with models that combine continuous and discrete choices in a principled way (as hybrid continuous-discrete graphical models) and design inference algorithms accordingly~\cite{cusumano-townerGenGeneralpurposeProbabilistic2019}. Finally,
% Probabilistic programming can also be applied to program synthesis, since the structure of the program's computation graph can itself be seen as the output of a stochastic program-generating process, allowing us to use conditional inference to search over the space of programs that might solve a particular problem~\cite{cusumano-townerAutomatingInvolutiveMCMC2020}.

\paragraph{Significance of this thesis} Probabilistic programming has been applied to a large number of problems in statistical inference; in fact, many of its original applications involved automating traditional statistical inference tasks such as regression and hierarchical modeling with a convenient programming interface~\cite{cusumano-townerGenGeneralpurposeProbabilistic2019}. Although probabilistic graphical models such as factor graphs have been applied widely in robotics, with deep roots in the SLAM community~\cite{dellaertFactorGraphsExploiting2021}, these methods have experienced some of the same hurdles as traditional model-based verification methods discussed above: it is difficult to derive these models by hand, particularly for complex dynamical systems found in traditional ``black-box'' settings. This thesis will close this gap by applying probabilistic programming to automatically generating these models for robotics safety verification and optimization problems.

\section{Design optimization for robotics}

Optimization is a fundamental tool for robotics, with a long history of use for motion planning and trajectory optimization~\cite{schulmanMotionPlanningSequential2014}, optimal control~\cite{liberzonCalculusVariationsOptimal2012}, localization and mapping~\cite{dellaertFactorGraphsExploiting2021}, and formal verification~\cite{liuAlgorithmsVerifyingDeep2021}, to name just a few applications. Without much risk of overstatement: for any given roboticist and any given robotics problem, the odds are good that he or she thinks about that problem through the lens of optimization. Given the huge variety of optimization problems found in robotics and control, it is important to narrow the scope of optimization problems considered in this thesis.

In particular, this thesis will focus on \textit{end-to-end design optimization problems} in robotics and cyberphysical systems. By design optimization, we mean the problem of finding some optimal set of parameters specifying the design of a system; e.g. control gains, physical layout of the system, neural network parameters, or roles of different agents in a multi-agent system. By taking an end-to-end approach to design optimization, we consider the joint optimization problem over all of these design parameters (e.g. simultaneously optimizing the hardware design parameters, control gains, and perception module), where we seek to simultaneously optimize the parameters of all subsystems to achieve some desired behavior.

Automatic differentiation is a key enabling technology for end-to-end robot design optimization. Recent years have seen the development of a wide range of differentiable simulation environments for rigid contact~\cite{heiden2021neuralsim,belubute_peres_lcp_physics,qiaoDifferentiableSimulationSoft2021,howelllecleach2022}, articulated robots~\cite{qiaoEfficientDifferentiableSimulation2021}, soft and deformable bodies~\cite{huChainQueenRealTimeDifferentiable2019,chenDaxBenchBenchmarkingDeformable2023,qiaoDifferentiableSimulationSoft2021}, hydrodynamics~\cite{ma2021diffaqua,leeAquariumFullyDifferentiable2023}, rendering~\cite{zhaoPhysicsbasedDifferentiableRendering2020,Jakob2020DrJit,lelidecDifferentiableRenderingPerturbed2021}, and more~\cite{huDiffTaichiDifferentiableProgramming2019, kidgerNeuralDifferentialEquations2022, murthyGradSimDifferentiableSimulation2021}.
%
These differentiable simulators have enabled a number of end-to-end design optimization approaches for specific domains, including simple walking robots~\cite{Schulz_robogami}, quadrotors~\cite{du2016computational}, soft robots~\cite{soft_robot_optimization_review,matthewsEfficientAutomaticDesign2023}, and swimming robots~\cite{du2021underwater,ma2021diffaqua}.

\subsection{Adversarial optimization}

A particularly noteworthy sub-genre of optimization is \textit{adversarial optimization}, where we solve a falsification or likely failure prediction problem to yield a counterexample (i.e. a set of disturbance parameters that leads to poor performance).
% 
Once we have generated such a counterexample, using either model-based or black-box methods (e.g. \cite{xuSafeBenchBenchmarkingPlatform2022,riedmaierSurveyScenarioBasedSafety2020,okellyScalableEndtoEndAutonomous2018,corsoAdaptiveStressTesting2019,wangAdvSimGeneratingSafetyCritical2021,sunCornerCaseGeneration2021,zhongGuidedConditionalDiffusion2022,corsoInterpretableSafetyValidation2020a,zhangAdversarialRobustnessTrajectory2022,hanselmannKINGGeneratingSafetyCritical2022a}), a natural next question is how we might use that counterexample to guide further optimization of the system. Re-optimizing the design of a system given these counterexamples can help improve robustness; this is the key idea behind the body of work on adversarial optimization (or adversarial training in the machine learning literature). Verification using adversarial optimization has been applied in both model-based~\cite{dontiAdversariallyRobustLearning2021} and model-free~\cite{corsoSurveyAlgorithmsBlackBox2021} contexts. Generally speaking, model-based adversarial techniques use gradient-based optimization to locally search for adversarial examples that cause a system failure, then use gradient-based optimization to locally repair those failures~\cite{dontiAdversariallyRobustLearning2021,dawsonRobustCounterexampleguidedOptimization2022b}. The drawback of these methods is that they are inherently local and typically yield only a single adversarial counterexample. Model-free approaches~\cite{corsoSurveyAlgorithmsBlackBox2021} can avoid the issue of local minima by using black-box optimization techniques but incur additional computational cost as a result.

\subsection{Limitations}

Most existing works on design optimization for robotics are specific to a particular application. Other works employ optimization to design specific subsystems, such as controllers~\cite{xu_uav_controllers} or motion plans~\cite{schulmanMotionPlanningSequential2014}. Moreover, most existing works on design optimization do not consider the problem of simultaneously verifying the safety of the optimized designs, nor do they consider how the results of verification can be used to guide further optimization. Works that do consider adversarial optimization typically rely on local optimization, which risks getting stuck in a local equilibrium and giving a false positive indication of the system's safety.

In contrast, this thesis develops general-purpose tools for robot design optimization that can be applied not only to a range of robot design problems but also to optimize the design of multiple subsystems simultaneously through the use of end-to-end simulation. The primary goal of this thesis is to close the loop between safety verification and design optimization by developing algorithms that use the results of verification to guide the optimization of more robust designs. Moreover, we address several key technical challenges that have limited the success of prior work on adversarial optimization for robotics, particularly issues of gradient quality and local equilibria.