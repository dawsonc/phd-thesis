@article{2020SciPy-NMeth,
  title = {{{SciPy}} 1.0: {{Fundamental}} Algorithms for Scientific Computing in Python},
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {van der Walt}, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  year = {2020},
  journal = {Nature Methods},
  volume = {17},
  pages = {261--272},
  doi = {10.1038/s41592-019-0686-2}
}

@article{adimoolamClassificationCoveragebasedFalsification2017,
  title = {Classification and Coverage-Based Falsification for Embedded Control Systems},
  author = {Adimoolam, Arvind and Dang, Thao and Donz{\'e}, Alexandre and Kapinski, James and Jin, Xiaoqing},
  year = {2017},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {10426 LNCS},
  pages = {483--503},
  publisher = {{Springer Verlag}},
  issn = {16113349},
  doi = {10.1007/978-3-319-63387-9_24/TABLES/2},
  urldate = {2022-10-18},
  abstract = {Many industrial cyber-physical system (CPS) designs are too complex to formally verify system-level properties. A practical approach for testing and debugging these system designs is falsification, wherein the user provides a temporal logic specification of correct system behaviors, and some technique for selecting test cases is used to identify behaviors that demonstrate that the specification does not hold for the system. While coverage metrics are often used to measure the exhaustiveness of this kind of testing approach for software systems, existing falsification approaches for CPS designs do not consider coverage for the signal variables. We present a new coverage measure for continuous signals and a new falsification technique that leverages the measure to efficiently identify falsifying traces. This falsification algorithm combines global and local search methods and uses a classification technique based on support vector machines to identify regions of the search space on which to focus effort. We use an industrial example from an automotive fuel cell application and other benchmark models to compare the new approach against existing falsification tools.},
  isbn = {9783319633862},
  file = {/home/cbd/Zotero/storage/LXCV9XH8/full-text.pdf}
}

@misc{AdversariallyRobustLearning,
  title = {Adversarially Robust Learning for Security-Constrained Optimal Power Flow},
  urldate = {2022-12-04},
  file = {/home/cbd/Zotero/storage/9KB7VPCS/f0f07e680de407b0f12abf15bd520097-Abstract.html}
}

@inproceedings{afsharNonVolumePreservingHamiltonian2021,
  title = {Non-{{Volume Preserving Hamiltonian Monte Carlo}} and {{No-U-TurnSamplers}}},
  booktitle = {Proceedings of {{The}} 24th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Afshar, Hadi Mohasel and Oliveira, Rafael and Cripps, Sally},
  year = {2021},
  month = mar,
  pages = {1675--1683},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2022-11-24},
  abstract = {Volume preservation is usually regarded as a necessary property for the leapfrog transition functions that are used in Hamiltonian Monte Carlo (HMC) and No-U-Turn (NUTS) samplers to guarantee convergence to the target distribution. In this work we rigorously prove that with minimal algorithmic modifications, both HMC and NUTS can be combined with transition functions that are not necessarily volume preserving. In light of these results, we propose a non-volume preserving transition function that conserves the Hamiltonian better than the baseline leapfrog mechanism, on piecewise-continuous distributions. The resulting samplers do not require any assumptions on the geometry of the discontinuity boundaries, and our experimental results show a significant improvement upon traditional HMC and NUTS.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/V3AIJ4X7/Afshar et al. - 2021 - Non-Volume Preserving Hamiltonian Monte Carlo and .pdf;/home/cbd/Zotero/storage/WITQ9PWG/Afshar et al. - 2021 - Non-Volume Preserving Hamiltonian Monte Carlo and .pdf}
}

@article{agarwalEmployingAdversarialRobustness2022,
  title = {Employing Adversarial Robustness Techniques for Large-Scale Stochastic Optimal Power Flow},
  author = {Agarwal, Aayushya and Donti, Priya L. and Kolter, J. Zico and Pileggi, Larry},
  year = {2022},
  month = nov,
  journal = {Electric Power Systems Research},
  volume = {212},
  pages = {108497},
  issn = {0378-7796},
  doi = {10.1016/j.epsr.2022.108497},
  urldate = {2022-12-04},
  abstract = {High penetrations of renewables and extreme weather phenomena are driving the need for large-scale stochastic optimization for power grid operations and planning. However, large-scale stochastic optimization remains computationally challenging due to the wide range of potential probabilistic outcomes and the non-convexity of the AC network constraints. Using a minimax formulation rooted in robust optimization, we define a generic methodology to obtain a feasible dispatch that accommodates the probabilistic nature of loads and renewable generation sources. We introduce a method to efficiently solve this minimax formulation, adopting techniques from the literature on adversarial robustness in machine learning to improve scalability and convergence. We demonstrate that our method maintains AC feasibility over a wide range of probabilistic scenarios, and demonstrate the scalability of our method by determining a dispatch for a synthetic 11,000 bus system.},
  langid = {english},
  keywords = {Bilevel optimization,Optimal power flow,Stochastic optimization},
  file = {/home/cbd/Zotero/storage/8C46JUAN/S0378779622006101.html}
}

@inproceedings{agarwalSynthesizingAdversarialVisual2022,
  title = {Synthesizing {{Adversarial Visual Scenarios}} for {{Model-Based Robotic Control}}},
  booktitle = {6th {{Annual Conference}} on {{Robot Learning}}},
  author = {Agarwal, Shubhankar and Chinchali, Sandeep P.},
  year = {2022},
  month = nov,
  urldate = {2023-03-14},
  abstract = {Today's robots often interface data-driven perception and planning models with classical model-predictive controllers (MPC). Often, such learned perception/planning models produce erroneous waypoint predictions on out-of-distribution (OoD) or even adversarial visual inputs, which increase control cost. However, today's methods to train robust perception models are largely task-agnostic -- they augment a dataset using random image transformations or adversarial examples targeted at the vision model in isolation. As such, they often introduce pixel perturbations that are ultimately benign for control. In contrast to prior work that synthesizes adversarial examples for single-step vision tasks, our key contribution is to synthesize adversarial scenarios tailored to multi-step, model-based control. To do so, we use differentiable MPC methods to calculate the sensitivity of a model-based controller to errors in state estimation. We show that re-training vision models on these adversarial datasets improves control performance on OoD test scenarios by up to 36.2\% compared to standard task-agnostic data augmentation. We demonstrate our method on examples of robotic navigation, manipulation in RoboSuite, and control of an autonomous air vehicle.},
  langid = {english},
  keywords = {00-read,00-relevant,differentiable simulation,gradient-based optimization},
  file = {/home/cbd/Zotero/storage/3P4ZTAIV/Agarwal and Chinchali - 2022 - Synthesizing Adversarial Visual Scenarios for Mode.pdf}
}

@inproceedings{agrawalDifferentiableConvexOptimization2019,
  title = {Differentiable {{Convex Optimization Layers}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen and Diamond, Steven and Kolter, J. Zico},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-05-15},
  abstract = {Recent work has shown how to embed differentiable optimization problems (that is, problems whose solutions can be backpropagated through) as layers within deep learning architectures. This method provides a useful inductive bias for certain problems, but existing software for differentiable optimization layers is rigid and difficult to apply to new settings. In this paper, we propose an approach to differentiating through disciplined convex programs, a subclass of convex optimization problems used by domain-specific languages (DSLs) for convex optimization. We introduce disciplined parametrized programming, a subset of disciplined convex programming, and we show that every disciplined parametrized program can be represented as the composition of an affine map from parameters to problem data, a solver, and an affine map from the solver's solution to a solution of the original problem (a new form we refer to as affine-solver-affine form). We then demonstrate how to efficiently differentiate through each of these components, allowing for end-to-end analytical differentiation through the entire convex program. We implement our methodology in version 1.1 of CVXPY, a popular Python-embedded DSL for convex optimization, and additionally implement differentiable layers for disciplined convex programs in PyTorch and TensorFlow 2.0. Our implementation significantly lowers the barrier to using convex optimization problems in differentiable programs. We present applications in linear machine learning models and in stochastic control, and we show that our layer is competitive (in execution time) compared to specialized differentiable solvers from past work.},
  file = {/home/cbd/Zotero/storage/5MTEAULG/Agrawal et al. - 2019 - Differentiable Convex Optimization Layers.pdf}
}

@article{ahmadiApplicationsPolynomialOptimization2016,
  title = {Some Applications of Polynomial Optimization in Operations Research and Real-Time Decision Making},
  author = {Ahmadi, Amir Ali and Majumdar, Anirudha},
  year = {2016},
  month = apr,
  journal = {Optimization Letters},
  volume = {10},
  number = {4},
  pages = {709--729},
  issn = {1862-4480},
  doi = {10.1007/s11590-015-0894-3},
  urldate = {2023-05-23},
  abstract = {We demonstrate applications of algebraic techniques that optimize and certify polynomial inequalities to problems of interest in the operations research and transportation engineering communities. Three problems are considered: (1) wireless coverage of targeted geographical regions with guaranteed signal quality and minimum transmission power, (2) computing real-time certificates of collision avoidance for a simple model of an unmanned vehicle (UV) navigating through a cluttered environment, and (3) designing a nonlinear hovering controller for a quadrotor UV, which has recently been used for load transportation. On our smaller-scale applications, we apply the sum of squares (SOS) relaxation and solve the underlying problems with semidefinite programming. On the larger-scale or real-time applications, we use our recently introduced ``SDSOS Optimization'' techniques which result in second order cone programs. To the best of our knowledge, this is the first study of real-time applications of sum of squares techniques in optimization and control. No knowledge in dynamics and control is assumed from the reader.},
  langid = {english},
  keywords = {Algebraic techniques in optimization,Lyapunov methods,Polynomial optimization,Real-time optimization,Second order cone programming,Semidefinite programming},
  file = {/home/cbd/Zotero/storage/PL8LBSHQ/Ahmadi and Majumdar - 2016 - Some applications of polynomial optimization in op.pdf}
}

@book{aiama,
  title = {Artificial Intelligence: {{A}} Modern Approach (2nd Edition)},
  author = {Russell, Stuart J. and Norvig, Peter},
  year = {2002},
  month = dec,
  isbn = {0-13-790395-2}
}

@book{allgowerNumericalContinuationMethods1990,
  title = {Numerical {{Continuation Methods}}},
  author = {Allgower, Eugene L. and Georg, Kurt},
  year = {1990},
  series = {Springer {{Series}} in {{Computational Mathematics}}},
  volume = {13},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-61257-2},
  urldate = {2024-01-03},
  isbn = {978-3-642-64764-2 978-3-642-61257-2},
  keywords = {Algorithmus,Approximation,bifurcation,boundary element method,complementary pivoting,computation,curve and surface approximation,eigenvalue problem,nichtlineare Differentialgleichung,nonlinear systems,nonlinear systems of equations,Numerical continuation,numerische Kontinuitatsmethoden,strategy,Verzweigungspunkte},
  file = {/home/cbd/Zotero/storage/GJCD87RJ/Allgower and Georg - 1990 - Numerical Continuation Methods.pdf}
}

@article{alquierPropertiesVariationalApproximations2016,
  title = {On the Properties of Variational Approximations of {{Gibbs}} Posteriors},
  author = {Alquier, Pierre and Ridgway, James and Chopin, Nicolas},
  year = {2016},
  journal = {Journal of Machine Learning Research},
  volume = {17},
  number = {236},
  pages = {1--41},
  issn = {1533-7928},
  urldate = {2023-08-14},
  abstract = {The PAC-Bayesian approach is a powerful set of techniques to derive non-asymptotic risk bounds for random estimators. The corresponding optimal distribution of estimators, usually called the Gibbs posterior, is unfortunately often intractable. One may sample from it using Markov chain Monte Carlo, but this is usually too slow for big datasets. We consider instead variational approximations of the Gibbs posterior, which are fast to compute. We undertake a general study of the properties of such approximations. Our main finding is that such a variational approximation has often the same rate of convergence as the original PAC-Bayesian procedure it approximates. In addition, we show that, when the risk function is convex, a variational approximation can be obtained in polynomial time using a convex solver. We give finite sample oracle inequalities for the corresponding estimator. We specialize our results to several learning tasks (classification, ranking, matrix completion), discuss how to implement a variational approximation in each case, and illustrate the good properties of said approximation on real datasets.},
  file = {/home/cbd/Zotero/storage/W8LP5CKF/Alquier et al. - 2016 - On the properties of variational approximations of.pdf}
}

@article{althoff_reachability_review,
  title = {Set Propagation Techniques for Reachability Analysis},
  author = {Althoff, Matthias and Frehse, Goran and Girard, Antoine},
  year = {2021},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {4},
  number = {1},
  eprint = {https://doi.org/10.1146/annurev-control-071420-081941},
  pages = {369--395},
  doi = {10.1146/annurev-control-071420-081941}
}

@article{amodei2016_ai_safety,
  title = {Concrete Problems in {{AI}} Safety},
  author = {Amodei, Dario and Olah, Christopher and Steinhardt, Jacob and Christiano, Paul Francis and Schulman, John and Man{\'e}, Dandelion},
  year = {2016},
  journal = {ArXiv},
  volume = {abs/1606.06565}
}

@inproceedings{amosOptNetDifferentiableOptimization2017,
  title = {{{OptNet}}: {{Differentiable}} Optimization as a Layer in Neural Networks},
  shorttitle = {{{OptNet}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}} - {{Volume}} 70},
  author = {Amos, Brandon and Kolter, J. Zico},
  year = {2017},
  month = aug,
  series = {{{ICML}}'17},
  pages = {136--145},
  publisher = {{JMLR.org}},
  address = {{Sydney, NSW, Australia}},
  urldate = {2023-01-04},
  abstract = {This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end train-able deep networks. These layers encode constraints and complex dependencies between the hidden states that traditional convolutional and fully-connected layers often cannot capture. In this paper, we explore the foundations for such an architecture: we show how techniques from sensitivity analysis, bilevel optimization, and implicit differentiation can be used to exactly differentiate through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one notable example, we show that the method is capable of learning to play mini-Sudoku (4x4) given just input and output games, with no a priori information about the rules of the game; this highlights the ability of our architecture to learn hard constraints better than other neural architectures.},
  file = {/home/cbd/Zotero/storage/LYN5IEK5/Amos and Kolter - 2017 - OptNet differentiable optimization as a layer in .pdf}
}

@article{annpureddySTaLiRoToolTemporal2011,
  title = {S-{{TaLiRo}}: {{A Tool}} for {{Temporal Logic Falsification}} for {{Hybrid Systems}}},
  author = {Annpureddy, Yashwanth and Liu, Che and Fainekos, Georgios and Sankaranarayanan, Sriram},
  year = {2011},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {6605 LNCS},
  pages = {254--257},
  publisher = {{Springer, Berlin, Heidelberg}},
  issn = {03029743},
  doi = {10.1007/978-3-642-19835-9_21},
  urldate = {2022-02-18},
  abstract = {S-TaLiRo is a Matlab (TM) toolbox that searches for trajectories of minimal robustness in Simulink/Stateflow diagrams. It can analyze arbitrary Simulink models or user defined functions that model the system. At the heart of the tool, we use randomized testing based on stochastic optimization techniques including Monte-Carlo methods and Ant-Colony Optimization. Among the advantages of the toolbox is the seamless integration inside the Matlab environment, which is widely used in the industry for model-based development of control software. We present the architecture of S-TaLiRo and its working on an application example. {\copyright} 2011 Springer-Verlag.},
  isbn = {9783642198342},
  keywords = {stl,to_read},
  file = {/home/cbd/Zotero/storage/WXANP755/full-text.pdf}
}

@inproceedings{annpureddySTaLiRoToolTemporal2011b,
  title = {S-{{TaLiRo}}: {{A Tool}} for {{Temporal Logic Falsification}} for {{Hybrid Systems}}},
  shorttitle = {S-{{TaLiRo}}},
  booktitle = {Tools and {{Algorithms}} for the {{Construction}} and {{Analysis}} of {{Systems}}},
  author = {Annpureddy, Yashwanth and Liu, Che and Fainekos, Georgios and Sankaranarayanan, Sriram},
  editor = {Abdulla, Parosh Aziz and Leino, K. Rustan M.},
  year = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {254--257},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-19835-9_21},
  abstract = {S-TaLiRo is a Matlab (TM) toolbox that searches for trajectories of minimal robustness in Simulink/Stateflow diagrams. It can analyze arbitrary Simulink models or user defined functions that model the system. At the heart of the tool, we use randomized testing based on stochastic optimization techniques including Monte-Carlo methods and Ant-Colony Optimization. Among the advantages of the toolbox is the seamless integration inside the Matlab environment, which is widely used in the industry for model-based development of control software. We present the architecture of S-TaLiRo and its working on an application example.},
  isbn = {978-3-642-19835-9},
  langid = {english},
  keywords = {00-read,00-relevant,Control Software,Hybrid System,Statistical Model Check,Stochastic Optimization Algorithm,Temporal Logic},
  file = {/home/cbd/Zotero/storage/4LC2MF66/Annpureddy et al. - 2011 - S-TaLiRo A Tool for Temporal Logic Falsification .pdf}
}

@misc{ApplicationsPolynomialOptimization,
  title = {Some Applications of Polynomial Optimization in Operations Research and Real-Time Decision Making {\textbar} {{SpringerLink}}},
  urldate = {2023-05-23},
  file = {/home/cbd/Zotero/storage/4F8WXQBI/s11590-015-0894-3.html}
}

@article{araujoTestingValidationVerification2022,
  title = {Testing, {{Validation}}, and {{Verification}} of {{Robotic}} and {{Autonomous Systems}}: {{A Systematic Review}}},
  shorttitle = {Testing, {{Validation}}, and {{Verification}} of {{Robotic}} and {{Autonomous Systems}}},
  author = {Araujo, Hugo and Mousavi, Mohammad Reza and Varshosaz, Mahsa},
  year = {2022},
  month = jun,
  journal = {ACM Transactions on Software Engineering and Methodology},
  issn = {1049-331X},
  doi = {10.1145/3542945},
  urldate = {2023-03-14},
  abstract = {We perform a systematic literature review on testing, validation, and verification of robotic and autonomous systems (RAS). The scope of this review covers peer-reviewed research papers proposing, improving or evaluating testing techniques, process, or tools that address the system-level qualities of RAS. Our survey is performed based on a rigorous methodology structured in three phases. First, we made use of a set of 26 seed papers (selected by domain experts) and the SERP-TEST taxonomy to design our search query and (domain-specific) taxonomy. Second, we conducted a search in three academic search engines and applied our inclusion and exclusion criteria to the results. Respectively, we made use of related work and domain specialists (50 academics and 15 industry experts) to validate and refine the search query. As a result, we encountered 10,735 studies, out of which, 195 were included, reviewed and coded. Our objective is to answer four research questions, pertaining to (1) the type of models, (2) measures for system performance and testing adequacy, (3) tools and their availability, and (4) evidence of applicability, particularly in industrial contexts. We analyse the results of our coding to identify strengths and gaps in the domain and present recommendations to researchers and practitioners. Our findings show that variants of temporal logics are most widely used for modelling requirements and properties, while variants of state-machines and transition systems are used widely for modelling system behaviour. Other common models concern epistemic logics for specifying requirements and belief-desire-intention models for specifying system behaviour. Apart from time and epistemics, other aspects captured in models concern probabilities (e.g., for modelling uncertainty) and continuous trajectories (e.g., for modelling vehicle dynamics and kinematics). Many papers lack any rigorous measure of efficiency, effectiveness, or adequacy for their proposed techniques, processes, or tools. Among those that provide a measure of efficiency, effectiveness, or adequacy the majority use domain-agnostic generic measures such as number of failures, size of state-space or verification time were most used. There is a trend in addressing the research gap in this respect by developing domain-specific notions of performance and adequacy. Defining widely-accepted rigorous measures of performance and adequacy for each domain is an identified research gap. In terms of tools, the most widely used tools are well-established model-checkers such as Prism and Uppaal, as well as simulation tools such as Gazebo; Matlab/Simulink is another widely used toolset in this domain. Overall there is very limited evidence of industrial applicability in the papers published in this domain. There is even a gap considering consolidated benchmarks for various types of autonomous systems.},
  keywords = {00-read,00-relevant},
  file = {/home/cbd/Zotero/storage/5YKFTB8N/Araujo et al. - 2022 - Testing, Validation, and Verification of Robotic a.pdf}
}

@inproceedings{ariefDeepProbabilisticAccelerated2021,
  title = {Deep {{Probabilistic Accelerated Evaluation}}: {{A Robust Certifiable Rare-Event Simulation Methodology}} for {{Black-Box Safety-Critical Systems}}},
  shorttitle = {Deep {{Probabilistic Accelerated Evaluation}}},
  booktitle = {Proceedings of {{The}} 24th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Arief, Mansur and Huang, Zhiyuan and Kumar, Guru Koushik Senthil and Bai, Yuanlu and He, Shengyi and Ding, Wenhao and Lam, Henry and Zhao, Ding},
  year = {2021},
  month = mar,
  pages = {595--603},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-03-14},
  abstract = {Evaluating the reliability of intelligent physical systems against rare safety-critical events poses a huge testing burden for real-world applications. Simulation provides a useful platform to evaluate the extremal risks of these systems before their deployments. Importance Sampling (IS), while proven to be powerful for rare-event simulation, faces challenges in handling these learning-based systems due to their black-box nature that fundamentally undermines its efficiency guarantee, which can lead to under-estimation without diagnostically detected. We propose a framework called Deep Probabilistic Accelerated Evaluation (Deep-PrAE) to design statistically guaranteed IS, by converting black-box samplers that are versatile but could lack guarantees, into one with what we call a relaxed efficiency certificate that allows accurate estimation of bounds on the safety-critical event probability. We present the theory of Deep-PrAE that combines the dominating point concept with rare-event set learning via deep neural network classifiers, and demonstrate its effectiveness in numerical examples including the safety-testing of an intelligent driving algorithm.},
  langid = {english},
  keywords = {00-read,00-relevant},
  file = {/home/cbd/Zotero/storage/53VMCXKN/Arief et al. - 2021 - Deep Probabilistic Accelerated Evaluation A Robus.pdf;/home/cbd/Zotero/storage/BZZ5W4KN/Arief et al. - 2021 - Deep Probabilistic Accelerated Evaluation A Robus.pdf}
}

@inproceedings{asimInvertibleGenerativeModels2020,
  title = {Invertible Generative Models for Inverse Problems: {{Mitigating}} Representation Error and Dataset Bias},
  shorttitle = {Invertible Generative Models for Inverse Problems},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Asim, Muhammad and Daniels, Max and Leong, Oscar and Ahmed, Ali and Hand, Paul},
  year = {2020},
  month = nov,
  pages = {399--409},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-04},
  abstract = {Trained generative models have shown remarkable performance as priors for inverse problems in imaging -- for example, Generative Adversarial Network priors permit recovery of test images from 5-10x fewer measurements than sparsity priors. Unfortunately, these models may be unable to represent any particular image because of architectural choices, mode collapse, and bias in the training dataset. In this paper, we demonstrate that invertible neural networks, which have zero representation error by design, can be effective natural signal priors at inverse problems such as denoising, compressive sensing, and inpainting. Given a trained generative model, we study the empirical risk formulation of the desired inverse problem under a regularization that promotes high likelihood images, either directly by penalization or algorithmically by initialization. For compressive sensing, invertible priors can yield higher accuracy than sparsity priors across almost all undersampling ratios, and due to their lack of representation error, invertible priors can yield better reconstructions than GAN priors for images that have rare features of variation within the biased training set, including out-of-distribution natural images. We additionally compare performance for compressive sensing to unlearned methods, such as the deep decoder, and we establish theoretical bounds on expected recovery error in the case of a linear invertible model.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/BD9XXE5Y/Asim et al. - 2020 - Invertible generative models for inverse problems.pdf;/home/cbd/Zotero/storage/S2SUB4FA/Asim et al. - 2020 - Invertible generative models for inverse problems.pdf}
}

@misc{austinTimelineEventsFebruary2021,
  type = {Report},
  title = {The {{Timeline}} and {{Events}} of the {{February}} 2021 {{Texas Electric Grid Blackouts}}},
  author = {{University of Texas at Austin}},
  year = {2021},
  month = jul,
  publisher = {{University of Texas at Austin. Energy Institute.}},
  urldate = {2022-12-31},
  abstract = {This report recounts the factors contributing to the disruptions in electricity and natural gas service in Texas during Winter Storm Uri, with a particular focus on the outages in electrical service in the Electric Reliability Council of Texas (ERCOT) power region during the period from February 15-18, 2021. In pursuing this report's objective, the Energy Institute at the University of Texas at Austin assembled a team of faculty and researchers to identify and review credible sources of data in an attempt to provide a factual account of what happened and what went wrong during the winter storm. The report provide recommendations, but to create a common basis of fact to educate the debate over policy changes under consideration as a response to the winter storm. The report specifically limited the scope of this report to the events and economic impacts of February 2021, including a comparison to previous winter storm blackouts of 1989 and 2011. To provide additional historical context, the report include an appendix that describes the long-term evolution of the ERCOT electricity market. This report is not intended to comprehensively address all issues stemming from such a complex event, but can inform future assessments.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/GHAB6JGN/Austin - 2021 - The Timeline and Events of the February 2021 Texas.pdf}
}

@misc{AutodiffCookbookJAX,
  title = {The {{Autodiff Cookbook}} --- {{JAX}} Documentation},
  urldate = {2023-06-07},
  file = {/home/cbd/Zotero/storage/6IYDREVS/autodiff_cookbook.html}
}

@inproceedings{bakHyLAAToolComputing2017,
  title = {{{HyLAA}}: {{A Tool}} for {{Computing Simulation-Equivalent Reachability}} for {{Linear Systems}}},
  shorttitle = {{{HyLAA}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Hybrid Systems}}: {{Computation}} and {{Control}}},
  author = {Bak, Stanley and Duggirala, Parasara Sridhar},
  year = {2017},
  month = apr,
  pages = {173--178},
  publisher = {{ACM}},
  doi = {10.1145/3049797.3049808},
  urldate = {2023-02-07},
  abstract = {Simulations are a practical method of increasing the confidence that a system design is correct. This paper presents techniques which aim to determine all the states that can be reached using a particular hybrid automaton simulation algorithm, a property we call simulation-equivalent reachability. Although this is a slightly weaker property than traditional reachability, its computation can be efficient and accurate. We present HyLAA, the first tool for simulation-equivalent reachability for hybrid automata with affine dynamics. HyLAA's analysis is exact; upon completion, the tool provides a concrete simulation trace to an unsafe state if and only if the hybrid automaton simulation engine could produce such a trace. In the backend, the tool implements an efficient algorithm for continuous post that exploits the superposition principle of linear systems, requiring only n+1 simulations per mode for an n-dimensional linear system. This technique is capable of analyzing a replicated helicopter system with over 1000 state variables in less than 20 minutes. The tool also contains several novel performance enhancements, such as invariant constraint elimination, warm-start linear programming, and trace-guided set deaggregation.},
  keywords = {abstraction-refinement,aggregation,constraint propagation,discrete time,generalized star,hybrid systems,invariants,reachable set,safety verification},
  file = {/home/cbd/Zotero/storage/R6F2QBMY/Bak and Duggirala - 2017 - HyLAA A Tool for Computing Simulation-Equivalent .pdf}
}

@inproceedings{bansalHamiltonJacobiReachabilityBrief2017,
  title = {Hamilton-{{Jacobi}} Reachability: {{A}} Brief Overview and Recent Advances},
  shorttitle = {Hamilton-{{Jacobi}} Reachability},
  booktitle = {2017 {{IEEE}} 56th {{Annual Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Bansal, Somil and Chen, Mo and Herbert, Sylvia and Tomlin, Claire J.},
  year = {2017},
  month = dec,
  pages = {2242--2253},
  doi = {10.1109/CDC.2017.8263977},
  abstract = {Hamilton-Jacobi (HJ) reachability analysis is an important formal verification method for guaranteeing performance and safety properties of dynamical systems; it has been applied to many small-scale systems in the past decade. Its advantages include compatibility with general nonlinear system dynamics, formal treatment of bounded disturbances, and the availability of well-developed numerical tools. The main challenge is addressing its exponential computational complexity with respect to the number of state variables. In this tutorial, we present an overview of basic HJ reachability theory and provide instructions for using the most recent numerical tools, including an efficient GPU-parallelized implementation of a Level Set Toolbox for computing reachable sets. In addition, we review some of the current work in high-dimensional HJ reachability to show how the dimensionality challenge can be alleviated via various general theoretical and application-specific insights.},
  keywords = {Aircraft,Games,Level set,Safety,Tools,Trajectory,Tutorials},
  file = {/home/cbd/Zotero/storage/4R6T38ET/Bansal et al. - 2017 - Hamilton-Jacobi reachability A brief overview and.pdf;/home/cbd/Zotero/storage/Y7AMDKRC/8263977.html}
}

@inproceedings{baramEndtoEndDifferentiableAdversarial2017,
  title = {End-to-{{End Differentiable Adversarial Imitation Learning}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Baram, Nir and Anschel, Oron and Caspi, Itai and Mannor, Shie},
  year = {2017},
  month = jul,
  pages = {390--399},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-03-14},
  abstract = {Generative Adversarial Networks (GANs) have been successfully applied to the problem of policy imitation in a model-free setup. However, the computation graph of GANs, that include a stochastic policy as the generative model, is no longer differentiable end-to-end, which requires the use of high-variance gradient estimation. In this paper, we introduce the Model-based Generative Adversarial Imitation Learning (MGAIL) algorithm. We show how to use a forward model to make the computation fully differentiable, which enables training policies using the exact gradient of the discriminator. The resulting algorithm trains competent policies using relatively fewer expert samples and interactions with the environment. We test it on both discrete and continuous action domains and report results that surpass the state-of-the-art.},
  langid = {english},
  keywords = {00-read},
  file = {/home/cbd/Zotero/storage/ZVNN8GWN/Baram et al. - 2017 - End-to-End Differentiable Adversarial Imitation Le.pdf}
}

@incollection{barrettSatisfiabilityModuloTheories2018,
  title = {Satisfiability {{Modulo Theories}}},
  booktitle = {Handbook of {{Model Checking}}},
  author = {Barrett, Clark and Tinelli, Cesare},
  editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
  year = {2018},
  pages = {305--343},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-10575-8_11},
  urldate = {2022-12-19},
  abstract = {Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining satisfiability can be extended with additional functionality such as producing models, proofs, unsatisfiable cores, and interpolants.},
  isbn = {978-3-319-10575-8},
  langid = {english},
  file = {/home/cbd/Zotero/storage/X7QZQYKP/Barrett and Tinelli - 2018 - Satisfiability Modulo Theories.pdf}
}

@article{bartheProvingExpectedSensitivity2017,
  title = {Proving Expected Sensitivity of Probabilistic Programs},
  author = {Barthe, Gilles and Espitau, Thomas and Gr{\'e}goire, Benjamin and Hsu, Justin and Strub, Pierre Yves},
  year = {2017},
  month = dec,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {2},
  number = {POPL},
  eprint = {1708.02537},
  issn = {24751421},
  doi = {10.1145/3158145},
  urldate = {2022-10-15},
  abstract = {Program sensitivity, also known as Lipschitz continuity, describes how small changes in a program's input lead to bounded changes in the output. We propose an average notion of program sensitivity ...},
  archiveprefix = {arxiv},
  keywords = {Kantorovich distance,Program sensitivity,relational program logics},
  file = {/home/cbd/Zotero/storage/75VCJCNU/full-text.pdf}
}

@inproceedings{bartlettSpectrallynormalizedMarginBounds2017,
  title = {Spectrally-Normalized Margin Bounds for Neural Networks},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2024-01-22},
  abstract = {This paper presents a margin-based multiclass generalization bound for neural networks that scales with their margin-normalized "spectral complexity": their Lipschitz constant, meaning the product of the spectral norms of the weight matrices, times a certain correction factor. This bound is empirically investigated for a standard AlexNet network trained with SGD on the MNIST and CIFAR10 datasets, with both original and random labels; the bound, the Lipschitz constants, and the excess risks are all in direct correlation, suggesting both that SGD selects predictors whose complexity scales with the difficulty of the learning task, and secondly that the presented bound is sensitive to this complexity.},
  file = {/home/cbd/Zotero/storage/6ZYQ56LL/Bartlett et al. - 2017 - Spectrally-normalized margin bounds for neural net.pdf}
}

@inproceedings{bartolomeisCertifiedDefencesHurt2022,
  title = {Certified Defences Hurt Generalisation},
  booktitle = {I {{Can}}'t {{Believe It}}'s {{Not Better Workshop}}: {{Understanding Deep Learning Through Empirical Falsification}}},
  author = {Bartolomeis, Piersilvio De and Clarysse, Jacob and Yang, Fanny and Sanyal, Amartya},
  year = {2022},
  month = dec,
  urldate = {2023-03-14},
  abstract = {In recent years, much work has been devoted to designing certified defences for neural networks, i.e., methods for learning neural networks that are provably robust to certain adversarial perturbations. Due to the non-convexity of the problem, dominant approaches in this area rely on convex approximations, which are inherently loose. In this paper, we question the effectiveness of such approaches for realistic computer vision tasks. First, we provide extensive empirical evidence to show that certified defences suffer not only worse accuracy but also worse robustness and fairness than empirical defences. We hypothesise that the reason for why certified defences suffer in generalisation is (i) the large number of relaxed non-convex constraints and (ii) strong alignment between the adversarial perturbations and the "signal" direction. We provide a combination of theoretical and experimental evidence to support these hypotheses.},
  langid = {english},
  keywords = {00-read},
  file = {/home/cbd/Zotero/storage/8LVSBMZ9/Bartolomeis et al. - 2022 - Certified defences hurt generalisation.pdf}
}

@misc{bazrafshanComputationallyEfficientSolutions2020,
  title = {Computationally {{Efficient Solutions}} for {{Large-Scale Security-Constrained Optimal Power Flow}}},
  author = {Bazrafshan, Mohammadhafez and Baker, Kyri and Mohammadi, Javad},
  year = {2020},
  month = may,
  number = {arXiv:2006.00585},
  eprint = {2006.00585},
  primaryclass = {math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.00585},
  urldate = {2022-12-15},
  abstract = {In this paper, we discuss our approach and algorithmic framework for solving large-scale security constrained optimal power flow (SCOPF) problems. SCOPF is a mixed integer non-convex optimization problem that aims to obtain the minimum dispatch cost while maintaining the system N-1 secure. Finding a feasible solution for this problem over large networks is challenging and this paper presents contingency selection, approximation methods, and decomposition techniques to address this challenge in a short period of time. The performance of the proposed methods are verified through large-scale synthetic and actual power networks in the Grid Optimization (GO) competition organized by the U.S. Advanced Research Projects Agency-Energy (ARPA-E). As many prior works focus on small-scale systems and are not benchmarked using validated, publicly available datasets, we aim to present a practical solution to SCOPF that has been proven to achieve good performance on realistically sized (30,000 buses) networks.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Optimization and Control},
  file = {/home/cbd/Zotero/storage/ISJWU2UN/Bazrafshan et al. - 2020 - Computationally Efficient Solutions for Large-Scal.pdf;/home/cbd/Zotero/storage/3ZKZEWHU/2006.html}
}

@article{beltaFormalMethodsControl2019,
  title = {Formal {{Methods}} for {{Control Synthesis}}: {{An Optimization Perspective}}},
  shorttitle = {Formal {{Methods}} for {{Control Synthesis}}},
  author = {Belta, Calin and Sadraddini, Sadra},
  year = {2019},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {2},
  number = {1},
  pages = {115--140},
  doi = {10.1146/annurev-control-053018-023717},
  urldate = {2023-02-07},
  abstract = {In control theory, complicated dynamics such as systems of (nonlinear) differential equations are controlled mostly to achieve stability. This fundamental property, which can be with respect to a desired operating point or a prescribed trajectory, is often linked with optimality, which requires minimizing a certain cost along the trajectories of a stable system. In formal verification (model checking), simple systems, such as finite-state transition graphs that model computer programs or digital circuits, are checked against rich specifications given as formulas of temporal logics. The formal synthesis problem, in which the goal is to synthesize or control a finite system from a temporal logic specification, has recently received increased interest. In this article, we review some recent results on the connection between optimal control and formal synthesis. Specifically, we focus on the following problem: Given a cost and a correctness temporal logic specification for a dynamical system, generate an optimal control strategy that satisfies the specification. We first provide a short overview of automata-based methods, in which the dynamics of the system are mapped to a finite abstraction that is then controlled using an automaton corresponding to the specification. We then provide a detailed overview of a class of methods that rely on mapping the specification and the dynamics to constraints of an optimization problem. We discuss advantages and limitations of these two types of approaches and suggest directions for future research.},
  keywords = {formal methods,mathematical programming,model predictive control,temporal logics},
  file = {/home/cbd/Zotero/storage/HDXLG9XF/Belta and Sadraddini - 2019 - Formal Methods for Control Synthesis An Optimizat.pdf}
}

@article{beltaSymbolicControlPlanning2007,
  title = {Symbolic {{Control}} and {{Planning}} of {{Robotic Motion}}},
  author = {Belta, Calin and Bicci, Antonio and Egerstedt, Magnus and Frazzoli, Emilio and Klavins, Eric and Pappas, George},
  year = {2007},
  month = mar,
  journal = {IEEE Robotics and Automation},
  volume = {14},
  number = {1},
  pages = {51--70},
  urldate = {2022-02-07},
  keywords = {survey},
  file = {/home/cbd/Zotero/storage/EHJ6Z67F/fulltext.pdf}
}

@inproceedings{belubute_peres_lcp_physics,
  title = {End-to-End Differentiable Physics for Learning and Control},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {{de Avila Belbute-Peres}, Filipe and Smith, Kevin and Allen, Kelsey and Tenenbaum, Josh and Kolter, J. Zico},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}}
}

@unpublished{benardRemoteAgentExperiment2000,
  title = {Remote {{Agent Experiment}}},
  author = {Benard, Doug and Dorais, Gregory A. and Gamble, Ed and Kanefsky, Bob and Kurien, James and Millar, William and Muscettola, Nicola and Nayak, Pandu and Rouquette, Nicolas and Rajan, Kanna and Norvig, Peter},
  year = {2000},
  month = jan,
  urldate = {2023-01-04},
  abstract = {Remote Agent (RA) is a model-based, reusable artificial intelligence (At) software system that enables goal-based spacecraft commanding and robust fault recovery. RA was flight validated during an experiment on board of DS1 between May 17th and May 21th, 1999.},
  keywords = {Cybernetics Artificial Intelligence And Robotics},
  file = {/home/cbd/Zotero/storage/TGQID6K5/Benard et al. - 2000 - Remote Agent Experiment.pdf;/home/cbd/Zotero/storage/G68G6TJ7/20000116204.html}
}

@article{bengioEstimatingPropagatingGradients2013,
  title = {Estimating or {{Propagating Gradients Through Stochastic Neurons}} for {{Conditional Computation}}},
  author = {Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  year = {2013},
  month = aug,
  eprint = {1308.3432},
  urldate = {2022-02-19},
  abstract = {Stochastic neurons and hard non-linearities can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic or non-smooth neurons? I.e., can we "back-propagate" through these stochastic neurons? We examine this question, existing approaches, and compare four families of solutions, applicable in different settings. One of them is the minimum variance unbiased gradient estimator for stochatic binary neurons (a special case of the REINFORCE algorithm). A second approach, introduced here, decomposes the operation of a binary stochastic neuron into a stochastic binary part and a smooth differentiable part, which approximates the expected effect of the pure stochatic binary neuron to first order. A third approach involves the injection of additive or multiplicative noise in a computational graph that is otherwise differentiable. A fourth approach heuristically copies the gradient with respect to the stochastic output directly as an estimator of the gradient with respect to the sigmoid argument (we call this the straight-through estimator). To explore a context where these estimators are useful, we consider a small-scale version of \{{\textbackslash}em conditional computation\}, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the neural network. In this case, it is important that the gating units produce an actual 0 most of the time. The resulting sparsity can be potentially be exploited to greatly reduce the computational cost of large deep networks for which conditional computation would be useful.},
  archiveprefix = {arxiv},
  keywords = {to_read},
  file = {/home/cbd/Zotero/storage/IGHM3P9U/full-text.pdf}
}

@article{betancourtConceptualIntroductionHamiltonian2017,
  title = {A {{Conceptual Introduction}} to {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, Michael},
  year = {2017},
  month = jan,
  eprint = {1701.02434},
  doi = {10.48550/arxiv.1701.02434},
  urldate = {2022-09-27},
  abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
  archiveprefix = {arxiv},
  file = {/home/cbd/Zotero/storage/7HP5G2NC/full-text.pdf}
}

@article{beutnerGuaranteedBoundsPosterior2022,
  title = {Guaranteed {{Bounds}} for {{Posterior Inference}} in {{Universal Probabilistic Programming}}},
  author = {Beutner, Raven and Ong, Luke and Zaiser, Fabian},
  year = {2022},
  month = apr,
  eprint = {2204.02948},
  publisher = {{ACM}},
  doi = {10.48550/arxiv.2204.02948},
  urldate = {2022-04-14},
  abstract = {We propose a new method to approximate the posterior distribution of probabilistic programs by means of computing guaranteed bounds. The starting point of our work is an interval-based trace semantics for a recursive, higher-order probabilistic programming language with continuous distributions. Taking the form of (super-/subadditive) measures, these lower/upper bounds are non-stochastic and provably correct: using the semantics, we prove that the actual posterior of a given program is sandwiched between the lower and upper bounds (soundness); moreover the bounds converge to the posterior (completeness). As a practical and sound approximation, we introduce a weight-aware interval type system, which automatically infers interval bounds on not just the return value but also weight of program executions, simultaneously. We have built a tool implementation, called GuBPI, which automatically computes these posterior lower/upper bounds. Our evaluation on examples from the literature shows that the bounds are useful, and can even be used to recognise wrong outputs from stochastic posterior inference procedures.},
  archiveprefix = {arxiv},
  keywords = {abstract interpretation,Bayesian inference,interval arithmetic,operational semantics,probabilistic programming,symbolic execution,type system,verification},
  file = {/home/cbd/Zotero/storage/IQ32PFZB/full-text.pdf}
}

@article{binghamPyroDeepUniversal2019,
  title = {Pyro: {{Deep}} Universal Probabilistic Programming},
  shorttitle = {Pyro},
  author = {Bingham, Eli and Chen, Jonathan P. and Jankowiak, Martin and Obermeyer, Fritz and Pradhan, Neeraj and Karaletsos, Theofanis and Singh, Rohit and Szerlip, Paul and Horsfall, Paul and Goodman, Noah D.},
  year = {2019},
  month = jan,
  journal = {The Journal of Machine Learning Research},
  volume = {20},
  number = {1},
  pages = {973--978},
  issn = {1532-4435},
  abstract = {Pyro is a probabilistic programming language built on Python as a platform for developing advanced probabilistic models in AI research. To scale to large data sets and high-dimensional models, Pyro uses stochastic variational inference algorithms and probability distributions built on top of PyTorch, a modern GPU-accelerated deep learning framework. To accommodate complex or model-specific algorithmic behavior, Pyro leverages Poutine, a library of composable building blocks for modifying the behavior of probabilistic programs.},
  keywords = {approximate Bayesian inference,deep learning,generative models,graphical models,probabilistic programming},
  file = {/home/cbd/Zotero/storage/7HMM6HZ5/Bingham et al. - 2019 - Pyro deep universal probabilistic programming.pdf}
}

@article{blanchet_2020_evt,
  title = {On Distributionally Robust Extreme Value Analysis},
  author = {Blanchet, Jose and He, Fei and Murthy, Karthyek},
  year = {2020},
  month = jan,
  journal = {Extremes. Statistical Theory and Applications in Science, Engineering and Economics},
  volume = {23},
  number = {2},
  pages = {317--347},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {1572-915X},
  doi = {10.1007/s10687-019-00371-1}
}

@article{bleiVariationalInferenceReview2016,
  title = {Variational {{Inference}}: {{A Review}} for {{Statisticians}}},
  author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
  year = {2016},
  month = jan,
  journal = {Journal of the American Statistical Association},
  volume = {112},
  number = {518},
  eprint = {1601.00670v9},
  pages = {859--877},
  publisher = {{American Statistical Association}},
  doi = {10.1080/01621459.2017.1285773},
  urldate = {2022-10-16},
  abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
  archiveprefix = {arxiv},
  keywords = {Algorithms,Computationally intensive methods,Statistical computing},
  file = {/home/cbd/Zotero/storage/HIP2QVDX/full-text.pdf}
}

@article{bobkov,
  title = {Variance of Lipschitz Functions and an Isoperimetric Problem for a Class of Product Measures},
  author = {Bobkov, Sergei G. and Houdr{\'e}, Christian},
  year = {1996},
  journal = {Bernoulli. Official Journal of the Bernoulli Society for Mathematical Statistics and Probability},
  volume = {2},
  number = {3},
  pages = {249--255},
  publisher = {{International Statistical Institute (ISI) and Bernoulli Society for Mathematical Statistics and Probability}},
  issn = {13507265},
  abstract = {The maximal variance of Lipschitz functions (with respect to the {$\ell$} 1-distance) of independent random vectors is found. This is then used to solve the isoperimetric problem, uniformly in the class of product probability measures with given variance.},
  jstor = {3318522}
}

@article{Bodily2017MultiobjectiveDO,
  title = {Multi-Objective Design Optimization of a Soft, Pneumatic Robot},
  author = {Bodily, Daniel M. and Allen, Thomas F. and Killpack, Marc D.},
  year = {2017},
  journal = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages = {1864--1871}
}

@inproceedings{boraCompressedSensingUsing2017,
  title = {Compressed {{Sensing}} Using {{Generative Models}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Bora, Ashish and Jalal, Ajil and Price, Eric and Dimakis, Alexandros G.},
  year = {2017},
  month = jul,
  pages = {537--546},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-04},
  abstract = {The goal of compressed sensing is to estimate a vector from an underdetermined system of noisy linear measurements, by making use of prior knowledge on the structure of vectors in the relevant domain. For almost all results in this literature, the structure is represented by sparsity in a well-chosen basis. We show how to achieve guarantees similar to standard compressed sensing but without employing sparsity at all. Instead, we suppose that vectors lie near the range of a generative model G:Rk{$\rightarrow$}RnG:Rk{$\rightarrow$}RnG: {\textbackslash}mathbb\{R\}\^{}k {\textbackslash}to {\textbackslash}mathbb\{R\}\^{}n. Our main theorem is that, if GGG is LLL-Lipschitz, then roughly (klogL)O(klogL){\textbackslash}mathcal\{O\}(k {\textbackslash}log L) random Gaussian measurements suffice for an {$\ell$}2/{$\ell$}2{$\ell$}2/{$\ell$}2{\textbackslash}ell\_2/{\textbackslash}ell\_2 recovery guarantee. We demonstrate our results using generative models from published variational autoencoder and generative adversarial networks. Our method can use 555-101010x fewer measurements than Lasso for the same accuracy.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/3A7TV68A/Bora et al. - 2017 - Compressed Sensing using Generative Models.pdf;/home/cbd/Zotero/storage/FLPXIRUP/Bora et al. - 2017 - Compressed Sensing using Generative Models.pdf}
}

@book{boucheron_lugosi_massart_2016,
  title = {Concentration Inequalities: {{A}} Nonasymptotic Theory of {{Independence}}},
  author = {Boucheron, St{\'e}phane and Lugosi, G{\'a}bor and Massart, Pascal},
  year = {2016},
  publisher = {{Oxford University Press}},
  address = {{Oxford}}
}

@article{bouvierQuantitativeResilienceLinear2021,
  title = {Quantitative Resilience of Linear Driftless Systems},
  author = {Bouvier, Jean Baptiste and Xu, Kathleen and Ornik, Melkior},
  year = {2021},
  journal = {Conference on Control and its Applications},
  pages = {32--39},
  publisher = {{Siam Society}},
  doi = {10.1137/1.9781611976847.5},
  urldate = {2022-02-01},
  abstract = {This paper introduces the notion of quantitative resilience of a control system. Following prior work, we study linear driftless systems enduring a loss of control authority over some of their actuators. Such a malfunction results in actuators producing possibly undesirable inputs over which the controller has real-time readings but no control. By definition, a system is resilient if it can still reach a target after a partial loss of control authority. However, after such a malfunction, a resilient system might be significantly slower to reach a target compared to its initial capabilities. We quantify this loss of performance through the new concept of quantitative resilience. We define such a metric as the maximal ratio of the minimal times required to reach any target for the initial and malfunctioning systems. Na\"{\i}ve computation of quantitative resilience directly from the definition is a complex task as it requires solving four nested, possibly nonlinear, optimization problems. The main technical contribution of this work is to provide an efficient method to compute quantitative resilience. Relying on control theory and on two novel geometric results we reduce the computation of quantitative resilience to a single linear optimization problem. We demonstrate our method on an opinion dynamics scenario.},
  isbn = {9781611976847},
  keywords = {control theory,Optimization in Control and Systems Theory,Robust Control},
  file = {/home/cbd/Zotero/storage/78I3I5ZY/full-text.pdf}
}

@misc{brockmanOpenAIGym2016,
  title = {{{OpenAI Gym}}},
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  year = {2016},
  month = jun,
  number = {arXiv:1606.01540},
  eprint = {1606.01540},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1606.01540},
  urldate = {2023-05-24},
  abstract = {OpenAI Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/cbd/Zotero/storage/AATXLVUC/Brockman et al. - 2016 - OpenAI Gym.pdf;/home/cbd/Zotero/storage/GM6NAUNQ/1606.html}
}

@article{bunksMultiscaleSeismicWaveform1995,
  title = {Multiscale Seismic Waveform Inversion},
  author = {Bunks, Carey and Saleck, Fatimetou M. and Zaleski, S. and Chavent, G.},
  year = {1995},
  month = oct,
  journal = {Geophysics},
  volume = {60},
  number = {5},
  pages = {1457--1473},
  issn = {0016-8033},
  doi = {10.1190/1.1443880},
  urldate = {2024-01-17},
  abstract = {Iterative inversion methods have been unsuccessful at inverting seismic data obtained from complicated earth models (e.g. the Marmousi model), the primary difficulty being the presence of numerous local minima in the objective function. The presence of local minima at all scales in the seismic inversion problem prevent iterative methods of inversion from attaining a reasonable degree of convergence to the neighborhood of the global minimum. The multigrid method is a technique that improves the performance of iterative inversion by decomposing the problem by scale. At long scales there are fewer local minima and those that remain are further apart from each other. Thus, at long scales iterative methods can get closer to the neighborhood of the global minimum. We apply the multigrid method to a subsampled, low-frequency version of the Marmousi data set. Although issues of source estimation, source bandwidth, and noise are not treated, results show that iterative inversion methods perform much better when employed with a decomposition by scale. Furthermore, the method greatly reduces the computational burden of the inversion that will be of importance for 3-D extensions to the method.},
  file = {/home/cbd/Zotero/storage/EYMR8E63/Bunks et al. - 1995 - Multiscale seismic waveform inversion.pdf;/home/cbd/Zotero/storage/4K3TNQ29/Multiscale-seismic-waveform-inversion.html}
}

@misc{bureauoftransportationstatisticsTranStatsDepartmentTransportation,
  title = {{{TranStats}}. {{U}}.{{S}}. {{Department}} of {{Transportation}}},
  author = {{Bureau of Transportation Statistics}}
}

@techreport{cainHistoryOptimalPower2012,
  title = {History of {{Optimal Power Flow}} and {{Formulations}}},
  author = {Cain, Mary B and O'Neill, Richard P and Castillo, Anya},
  year = {2012},
  institution = {{Federal Energy Regulatory Commission}},
  abstract = {The purpose of this paper is to present a literature review of the AC Optimal Power Flow (ACOPF) problem and propose areas where the ACOPF could be improved. The ACOPF is at the heart of Independent System Operator (ISO) power markets, and is solved in some form every year for system planning, every day for day-ahead markets, every hour, and even every 5 minutes. It was first formulated in 1962, and formulations have changed little over the years. With advances in computing power and solution algorithms, we can model more of the constraints and remove unnecessary limits and approximations that were previously required to find a solution in reasonable time. One example is nonlinear voltage magnitude constraints that are modeled as linear thermal proxy constraints. In this paper, we refer to the full ACOPF as an ACOPF that simultaneously optimizes real and reactive power. Today, 50 years after the problem was formulated, we still do not have a fast, robust solution technique for the full ACOPF. Finding a good solution technique for the full ACOPF could potentially save tens of billions of dollars annually. Based on our literature review, we find that the ACOPF research community lacks a common understanding of the problem, its formulation, and objective functions. However, we do not claim that this literature review is a complete review---our intent was simply to capture the major formulations of the ACOPF. Instead, in this paper, we seek to clearly present the ACOPF problem through clear formulations of the problem and its parameters. This paper defines and discusses the polar power-voltage, rectangular power-voltage, and rectangular current-voltage formulations of the ACOPF. Additionally, it discusses the different types of constraints and objective functions. This paper lays the groundwork for further research on the convex approximation of the ACOPF solution space, a survey of solution techniques, and computational performance of different formulations.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/L8VQNRG2/Cain et al. - 2012 - History of Optimal Power Flow and Formulations.pdf}
}

@article{capitanescuStateoftheartChallengesFuture2011,
  title = {State-of-the-Art, Challenges, and Future Trends in Security Constrained Optimal Power Flow},
  author = {Capitanescu, F. and Martinez Ramos, J. L. and Panciatici, P. and Kirschen, D. and Marano Marcolini, A. and Platbrood, L. and Wehenkel, L.},
  year = {2011},
  month = aug,
  journal = {Electric Power Systems Research},
  volume = {81},
  number = {8},
  pages = {1731--1741},
  issn = {0378-7796},
  doi = {10.1016/j.epsr.2011.04.003},
  urldate = {2022-12-15},
  abstract = {This paper addresses the main challenges to the security constrained optimal power flow (SCOPF) computations. We first discuss the issues related to the SCOPF problem formulation such as the use of a limited number of corrective actions in the post-contingency states and the modeling of voltage and transient stability constraints. Then we deal with the challenges to the techniques for solving the SCOPF, focusing mainly on: approaches to reduce the size of the problem by either efficiently identifying the binding contingencies and including only these contingencies in the SCOPF or by using approximate models for the post-contingency states, and the handling of discrete variables. We finally address the current trend of extending the SCOPF formulation to take into account the increasing levels of uncertainty in the operation planning. For each such topic we provide a review of the state of the art, we identify the advances that are needed, and we indicate ways to bridge the gap between the current state of the art and these needs.},
  langid = {english},
  keywords = {Mixed integer linear programming,Mixed integer nonlinear programming,Nonlinear programming,Optimal power flow,Security constrained optimal power flow},
  file = {/home/cbd/Zotero/storage/8DU42AL2/Capitanescu et al. - 2011 - State-of-the-art, challenges, and future trends in.pdf;/home/cbd/Zotero/storage/PSVV6494/S0378779611000885.html}
}

@article{cascaval2021differentiable,
  title = {Differentiable {{3D CAD}} Programs for Bidirectional Editing},
  author = {Cascaval, Dan and Shalah, Mira and Quinn, Phillip and Bodik, Rastislav and Agrawala, Maneesh and Schulz, Adriana},
  year = {2021},
  journal = {arXiv},
  volume = {abs/2110.01182}
}

@inproceedings{changNeuralLyapunovControl2019,
  title = {Neural {{Lyapunov Control}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chang, Ya-Chien and Roohi, Nima and Gao, Sicun},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-06-05},
  abstract = {We propose new methods for learning control policies and neural network Lyapunov functions for nonlinear control problems, with provable guarantee of stability. The framework consists of a learner that attempts to find the control and Lyapunov functions, and a falsifier that finds counterexamples to quickly guide the learner towards solutions. The procedure terminates when no counterexample is found by the falsifier, in which case the controlled nonlinear system is provably stable. The approach significantly simplifies the process of Lyapunov control design, provides end-to-end correctness guarantee, and can obtain much larger regions of attraction than existing methods such as LQR and SOS/SDP. We show experiments on how the new methods obtain high-quality solutions for challenging robot control problems such as path tracking for wheeled vehicles and humanoid robot balancing.},
  file = {/home/cbd/Zotero/storage/MZ7RID5J/Chang et al. - 2019 - Neural Lyapunov Control.pdf}
}

@inproceedings{CharrasGarrido2013ExtremeVA,
  title = {Extreme Value Analysis: An Introduction},
  author = {{Charras-Garrido}, M. and Lezaud, Pascal},
  year = {2013}
}

@inproceedings{chaudhuriContinuityAnalysisPrograms2010,
  title = {Continuity {{Analysis}} of {{Programs}}},
  booktitle = {{{POPL}}'10, {{January}} 17-23, 2010, {{Madrid}}, {{Spain}}},
  author = {Chaudhuri, Swarat and Gulwani, Sumit and Lublinerman, Roberto},
  year = {2010},
  month = jan,
  urldate = {2023-02-10},
  abstract = {We present an analysis to automatically determine if a program represents a continuous function, or equivalently, if infinitesimal changes to its inputs can only cause infinitesimal changes to its outputs. The analysis used to verify the robustness of programs whose inputs can have small amounts of error and uncertainty---e.g., embedded controllers processing slightly unreliable sensor [{\dots}]},
  langid = {american},
  file = {/home/cbd/Zotero/storage/XIFZM9YZ/Chaudhuri et al. - 2010 - Continuity Analysis of Programs.pdf}
}

@inproceedings{chaudhuriProvingProgramsRobust2011,
  title = {Proving Programs Robust},
  booktitle = {Proceedings of the 19th {{ACM SIGSOFT}} Symposium and the 13th {{European}} Conference on {{Foundations}} of Software Engineering},
  author = {Chaudhuri, Swarat and Gulwani, Sumit and Lublinerman, Roberto and Navidpour, Sara},
  year = {2011},
  month = sep,
  series = {{{ESEC}}/{{FSE}} '11},
  pages = {102--112},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2025113.2025131},
  urldate = {2023-02-10},
  abstract = {We present a program analysis for verifying quantitative robustness properties of programs, stated generally as: "If the inputs of a program are perturbed by an arbitrary amount epsilon, then its outputs change at most by (K . epsilon), where K can depend on the size of the input but not its value." Robustness properties generalize the analytic notion of continuity---e.g., while the function ex is continuous, it is not robust. Our problem is to verify the robustness of a function P that is coded as an imperative program, and can use diverse data types and features such as branches and loops. Our approach to the problem soundly decomposes it into two subproblems: (a) verifying that the smallest possible perturbations to the inputs of P do not change the corresponding outputs significantly, even if control now flows along a different control path; and (b) verifying the robustness of the computation along each control-flow path of P. To solve the former subproblem, we build on an existing method for verifying that a program encodes a continuous function [5]. The latter is solved using a static analysis that bounds the magnitude of the slope of any function computed by a control flow path of P. The outcome is a sound program analysis for robustness that uses proof obligations which do not refer to epsilon-changes and can often be fully automated using off-the-shelf SMT-solvers. We identify three application domains for our analysis. First, our analysis can be used to guarantee the predictable execution of embedded control software, whose inputs come from physical sources and can suffer from error and uncertainty. A guarantee of robustness ensures that the system does not react disproportionately to such uncertainty. Second, our analysis is directly applicable to approximate computation, and can be used to provide foundations for a recently-proposed program approximation scheme called \{loop perforation\}. A third application is in database privacy: proofs of robustness of queries are essential to differential privacy, the most popular notion of privacy for statistical databases.},
  isbn = {978-1-4503-0443-6},
  keywords = {continuity,lipschitz,perturbations,program approximation,quantitative program analysis,robustness,sensitivity,uncertainty},
  file = {/home/cbd/Zotero/storage/9AZWCU32/Chaudhuri et al. - 2011 - Proving programs robust.pdf}
}

@inproceedings{chenContinuousTimeFlowsEfficient2018,
  title = {Continuous-{{Time Flows}} for {{Efficient Inference}} and {{Density Estimation}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Chen, Changyou and Li, Chunyuan and Chen, Liqun and Wang, Wenlin and Pu, Yunchen and Duke, Lawrence Carin},
  year = {2018},
  month = jul,
  pages = {824--833},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-30},
  abstract = {Two fundamental problems in unsupervised learning are efficient inference for latent-variable models and robust density estimation based on large amounts of unlabeled data. Algorithms for the two tasks, such as normalizing flows and generative adversarial networks (GANs), are often developed independently. In this paper, we propose the concept of continuous-time flows (CTFs), a family of diffusion-based methods that are able to asymptotically approach a target distribution. Distinct from normalizing flows and GANs, CTFs can be adopted to achieve the above two goals in one framework, with theoretical guarantees. Our framework includes distilling knowledge from a CTF for efficient inference, and learning an explicit energy-based distribution with CTFs for density estimation. Both tasks rely on a new technique for distribution matching within amortized learning. Experiments on various tasks demonstrate promising performance of the proposed CTF framework, compared to related techniques.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/85MK7HGK/Chen et al. - 2018 - Continuous-Time Flows for Efficient Inference and .pdf;/home/cbd/Zotero/storage/J7DTMIKR/Chen et al. - 2018 - Continuous-Time Flows for Efficient Inference and .pdf}
}

@article{chenCooperativeTaskMotion2021,
  title = {Cooperative {{Task}} and {{Motion Planning}} for {{Multi-Arm Assembly Systems}}},
  author = {Chen, Jingkai and Li, Jiaoyang and Huang, Yijiang and Garrett, Caelan and Sun, Dawei and Fan, Chuchu and Hofmann, Andreas and Mueller, Caitlin and Koenig, Sven and Williams, Brian C},
  year = {2021},
  journal = {IEEE Robotics and Automation Letters (RA-L)},
  urldate = {2022-01-30},
  abstract = {Planning for a team of robots to complete varying assembly tasks in dynamic environments is one of the key technical challenges for developing the next generation of manufacturing automation. In this paper, we present a cooperative task and motion planning framework that jointly plans safe, optimized assembly plans for multiple robot arms to assemble complex spatial structures. We demonstrate our planning system on several challenging domains including Lego bricks, bars, plates, and irregular-shaped blocks with up to three robots with grippers or suction plates for assembling up to 23 objects. We show that, with our framework, assembly plans can be automatically planned for various complex structures and potentially applied to real-world manufacturing.},
  keywords = {construction,path planning,tamp},
  file = {/home/cbd/Zotero/storage/RLSXB6U8/full-text.pdf}
}

@inproceedings{chenDaxBenchBenchmarkingDeformable2023,
  title = {{{DaxBench}}: {{Benchmarking Deformable Object Manipulation}} with {{Differentiable Physics}}},
  shorttitle = {{{DaxBench}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Chen, Siwei and Xu, Yiqing and Yu, Cunjun and Li, Linfeng and Ma, Xiao and Xu, Zhongwen and Hsu, David},
  year = {2023},
  month = feb,
  urldate = {2023-06-12},
  abstract = {Deformable object manipulation (DOM) is a long-standing challenge in robotics and has attracted significant interest recently. This paper presents DaXBench, a differentiable simulation framework for DOM. While existing work often focuses on a specific type of deformable objects, DaXBench supports fluid, rope, cloth ...; it provides a general-purpose benchmark to evaluate widely different DOM methods, including planning, imitation learning, and reinforcement learning. DaXBench combines recent advances in deformable object simulation with JAX, a high-performance computational framework. All DOM tasks in DaXBench are wrapped with the OpenAI Gym API for easy integration with DOM algorithms. We hope that DaXBench provides to the research community a comprehensive, standardized benchmark and a valuable tool to support the development and evaluation of new DOM methods. The code and video are available online.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/JHGDSBY5/Chen et al. - 2023 - DaxBench Benchmarking Deformable Object Manipulat.pdf}
}

@inproceedings{chenDecomposedReachabilityAnalysis2016,
  title = {Decomposed {{Reachability Analysis}} for {{Nonlinear Systems}}},
  booktitle = {2016 {{IEEE Real-Time Systems Symposium}} ({{RTSS}})},
  author = {Chen, Xin and Sankaranarayanan, Sriram},
  year = {2016},
  month = nov,
  pages = {13--24},
  doi = {10.1109/RTSS.2016.011},
  abstract = {We introduce an approach to conservatively abstract a nonlinear continuous system by a hybrid automaton whose continuous dynamics are given by a decomposition of the original dynamics. The decomposed dynamics is in the form of a set of lower-dimensional ODEs with time-varying uncertainties whose ranges are defined by the hybridization domains. We propose several techniques in the paper to effectively compute abstractions and flowpipe overapproximations. First, a novel method is given to reduce the overestimation accumulation in a Taylor model flowpipe construction scheme. Then we present our decomposition method, as well as the framework of on-the-fly hybridization. A combination of the two techniques allows us to handle much larger, nonlinear systems with comparatively large initial sets. Our prototype implementation is compared with existing reachability tools for offline and online flowpipe construction on challenging benchmarks of dimensions ranging from 7 to 30. Our code has successfully passed the artifact evaluation.},
  keywords = {Automobiles,Computational modeling,Continuous time systems,cyber-physical system,decomposition,hybridization,integration,Nonlinear dynamical systems,ODE,Real-time systems,Uncertainty,verification},
  file = {/home/cbd/Zotero/storage/HTRWU34Y/Chen and Sankaranarayanan - 2016 - Decomposed Reachability Analysis for Nonlinear Sys.pdf;/home/cbd/Zotero/storage/PQ67RJCQ/7809839.html}
}

@misc{chengDiffTuneHyperparameterFreeAutoTuning2023,
  title = {{{DiffTune}}\$\^{}+\$: {{Hyperparameter-Free Auto-Tuning}} Using {{Auto-Differentiation}}},
  shorttitle = {{{DiffTune}}\$\^{}+\$},
  author = {Cheng, Sheng and Song, Lin and Kim, Minkyung and Wang, Shenlong and Hovakimyan, Naira},
  year = {2023},
  month = may,
  number = {arXiv:2212.03194},
  eprint = {2212.03194},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2212.03194},
  urldate = {2023-06-12},
  abstract = {Controller tuning is a vital step to ensure the controller delivers its designed performance. DiffTune has been proposed as an automatic tuning method that unrolls the dynamical system and controller into a computational graph and uses auto-differentiation to obtain the gradient for the controller's parameter update. However, DiffTune uses the vanilla gradient descent to iteratively update the parameter, in which the performance largely depends on the choice of the learning rate (as a hyperparameter). In this paper, we propose to use hyperparameter-free methods to update the controller parameters. We find the optimal parameter update by maximizing the loss reduction, where a predicted loss based on the approximated state and control is used for the maximization. Two methods are proposed to optimally update the parameters and are compared with related variants in simulations on a Dubin's car and a quadrotor. Simulation experiments show that the proposed first-order method outperforms the hyperparameter-based methods and is more robust than the second-order hyperparameter-free methods.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Robotics},
  file = {/home/cbd/Zotero/storage/MMITXVJB/Cheng et al. - 2023 - DiffTune$^+$ Hyperparameter-Free Auto-Tuning usin.pdf;/home/cbd/Zotero/storage/3MBGIKSU/2212.html}
}

@techreport{chengResponseTimeAnalysis2022,
  title = {Response {{Time Analysis}} of {{Real-Time Quantum Computing Systems}}},
  author = {Cheng, Albert M K},
  year = {2022},
  abstract = {Despite the potential of quantum computing for drastically accelerating suitable real-time applications, response time analysis is still required to guarantee that quantum programs running on quantum computers satisfy application-specific timing requirements. This paper describes an inaugural project to determine whether a quantum program running on a quantum computer satisfies the timing constraints of a real-time application, that is, is quantum computing punctual and reliable in this time-sensitive application domain? Can this timing guarantee be formally verified? We leverage our work on the functional reactive programming (FRP) model to predict the worst-case response time (WCRT) of fault-tolerant classical computing systems since the timing analysis of re-executions for fault recovery plus transient-faults-induced wasted execution times is similar to determining the response time of FRP tasks. Ongoing work shows that accounting for wasted execution times due to errors in quantum computers resulting from quantum decoherence and state fidelity can be treated similarly and develops a mapping from quantum programs to FRP programs for efficient timing analysis.},
  keywords = {Fault tolerance,Formal verification,Quantum computing,Real-time systems,Reliability,Response time analysis,review},
  file = {/home/cbd/Zotero/storage/BN348AWR/NFM22_paper_100.pdf}
}

@inproceedings{chenNeuralOrdinaryDifferential2018,
  title = {Neural {{Ordinary Differential Equations}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2024-01-21},
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  file = {/home/cbd/Zotero/storage/TZYLKIU7/Chen et al. - 2018 - Neural Ordinary Differential Equations.pdf}
}

@inproceedings{chenNL2TLTransformingNatural2023,
  title = {{{NL2TL}}: {{Transforming Natural Languages}} to {{Temporal Logics}} Using {{Large Language Models}}},
  shorttitle = {{{NL2TL}}},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Chen, Yongchao and Gandhi, Rujul and Zhang, Yang and Fan, Chuchu},
  editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  year = {2023},
  month = dec,
  pages = {15880--15903},
  publisher = {{Association for Computational Linguistics}},
  address = {{Singapore}},
  doi = {10.18653/v1/2023.emnlp-main.985},
  urldate = {2024-02-24},
  abstract = {Temporal Logic (TL) can be used to rigorously specify complex high-level specification for systems in many engineering applications. The translation between natural language (NL) and TL has been under-explored due to the lack of dataset and generalizable model across different application domains. In this paper, we propose an accurate and generalizable transformation framework of English instructions from NL to TL, exploring the use of Large Language Models (LLMs) at multiple stages. Our contributions are twofold. First, we develop a framework to create a dataset of NL-TL pairs combining LLMs and human annotation. We publish a dataset with 23K NL-TL pairs. Then, we finetune T5 models on the lifted versions (i.e., the specific Atomic Propositions (AP) are hidden) of the NL and TL. The enhanced generalizability originates from two aspects: 1) Usage of lifted NL-TL characterizes common logical structures, without constraints of specific domains. 2) Application of LLMs in dataset creation largely enhances corpus richness. We test the generalization of trained models on five varied domains. To achieve full NL-TL transformation, we either combine the lifted model with AP recognition task or do the further finetuning on each specific domain. During the further finetuning, our model achieves higher accuracy ({\textbackslash}textgreater 95\%) using only {\textbackslash}textless10\% training data, compared with the baseline sequence to sequence (Seq2Seq) model.},
  file = {/home/cbd/Zotero/storage/AMYJKY9C/Chen et al. - 2023 - NL2TL Transforming Natural Languages to Temporal .pdf}
}

@misc{chenStochasticGradientHamiltonian2014,
  title = {Stochastic {{Gradient Hamiltonian Monte Carlo}}},
  author = {Chen, Tianqi and Fox, Emily B. and Guestrin, Carlos},
  year = {2014},
  month = may,
  number = {arXiv:1402.4102},
  eprint = {1402.4102},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1402.4102},
  urldate = {2023-03-06},
  abstract = {Hamiltonian Monte Carlo (HMC) sampling methods provide a mechanism for defining distant proposals with high acceptance probabilities in a Metropolis-Hastings framework, enabling more efficient exploration of the state space than standard random-walk proposals. The popularity of such methods has grown significantly in recent years. However, a limitation of HMC methods is the required gradient computation for simulation of the Hamiltonian dynamical system-such computation is infeasible in problems involving a large sample size or streaming data. Instead, we must rely on a noisy gradient estimate computed from a subset of the data. In this paper, we explore the properties of such a stochastic gradient HMC approach. Surprisingly, the natural implementation of the stochastic approximation can be arbitrarily bad. To address this problem we introduce a variant that uses second-order Langevin dynamics with a friction term that counteracts the effects of the noisy gradient, maintaining the desired target distribution as the invariant distribution. Results on simulated data validate our theory. We also provide an application of our methods to a classification task using neural networks and to online Bayesian matrix factorization.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/cbd/Zotero/storage/QNXK4B8F/Chen et al. - 2014 - Stochastic Gradient Hamiltonian Monte Carlo.pdf;/home/cbd/Zotero/storage/A6AE9FJL/1402.html}
}

@inproceedings{chenTaylorModelFlowpipe2012,
  title = {Taylor {{Model Flowpipe Construction}} for {{Non-linear Hybrid Systems}}},
  booktitle = {2012 {{IEEE}} 33rd {{Real-Time Systems Symposium}}},
  author = {Chen, Xin and {\'A}brah{\'a}m, Erika and Sankaranarayanan, Sriram},
  year = {2012},
  month = dec,
  pages = {183--192},
  issn = {1052-8725},
  doi = {10.1109/RTSS.2012.70},
  abstract = {We propose an approach for verifying non-linear hybrid systems using higher-order Taylor models that are a combination of bounded degree polynomials over the initial conditions and time, bloated by an interval. Taylor models are an effective means for computing rigorous bounds on the complex time trajectories of non-linear differential equations. As a result, Taylor models have been successfully used to verify properties of non-linear continuous systems. However, the handling of discrete (controller) transitions remains a challenging problem. In this paper, we provide techniques for handling the effect of discrete transitions on Taylor model flow pipe construction. We explore various solutions based on two ideas: domain contraction and range over-approximation. Instead of explicitly computing the intersection of a Taylor model with a guard set, domain contraction makes the domain of a Taylor model smaller by cutting away parts for which the intersection is empty. It is complemented by range over-approximation that translates Taylor models into commonly used representations such as template polyhedra or zonotopes, on which intersections with guard sets have been previously studied. We provide an implementation of the techniques described in the paper and evaluate the various design choices over a set of challenging benchmarks.},
  keywords = {Approximation methods,Computational modeling,Mathematical model,Polynomials,Safety,Taylor series,Trajectory},
  file = {/home/cbd/Zotero/storage/ECQZUS23/Chen et al. - 2012 - Taylor Model Flowpipe Construction for Non-linear .pdf;/home/cbd/Zotero/storage/KELJFHJV/6424802.html}
}

@article{chibaneNeuralUnsignedDistance2020,
  title = {Neural {{Unsigned Distance Fields}} for {{Implicit Function Learning}}},
  author = {Chibane, Julian and Mir, Aymen and {Pons-Moll}, Gerard},
  year = {2020},
  month = oct,
  journal = {Advances in Neural Information Processing Systems},
  volume = {2020-December},
  eprint = {2010.13938},
  publisher = {{Neural information processing systems foundation}},
  issn = {10495258},
  urldate = {2022-03-03},
  abstract = {In this work we target a learnable output representation that allows continuous, high resolution outputs of arbitrary shape. Recent works represent 3D surfaces implicitly with a Neural Network, thereby breaking previous barriers in resolution, and ability to represent diverse topologies. However, neural implicit representations are limited to closed surfaces, which divide the space into inside and outside. Many real world objects such as walls of a scene scanned by a sensor, clothing, or a car with inner structures are not closed. This constitutes a significant barrier, in terms of data pre-processing (objects need to be artificially closed creating artifacts), and the ability to output open surfaces. In this work, we propose Neural Distance Fields (NDF), a neural network based model which predicts the unsigned distance field for arbitrary 3D shapes given sparse point clouds. NDF represent surfaces at high resolutions as prior implicit models, but do not require closed surface data, and significantly broaden the class of representable shapes in the output. NDF allow to extract the surface as very dense point clouds and as meshes. We also show that NDF allow for surface normal calculation and can be rendered using a slight modification of sphere tracing. We find NDF can be used for multi-target regression (multiple outputs for one input) with techniques that have been exclusively used for rendering in graphics. Experiments on ShapeNet show that NDF, while simple, is the state-of-the art, and allows to reconstruct shapes with inner structures, such as the chairs inside a bus. Notably, we show that NDF are not restricted to 3D shapes, and can approximate more general open surfaces such as curves, manifolds, and functions. Code is available for research at https://virtualhumans.mpi-inf.mpg.de/ndf/.},
  archiveprefix = {arxiv},
  keywords = {to_read},
  file = {/home/cbd/Zotero/storage/WHFBPY7C/full-text.pdf}
}

@misc{chiDiffusionPolicyVisuomotor2023,
  title = {Diffusion {{Policy}}: {{Visuomotor Policy Learning}} via {{Action Diffusion}}},
  shorttitle = {Diffusion {{Policy}}},
  author = {Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
  year = {2023},
  month = mar,
  number = {arXiv:2303.04137},
  eprint = {2303.04137},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2303.04137},
  urldate = {2023-03-21},
  abstract = {This paper introduces Diffusion Policy, a new way of generating robot behavior by representing a robot's visuomotor policy as a conditional denoising diffusion process. We benchmark Diffusion Policy across 11 different tasks from 4 different robot manipulation benchmarks and find that it consistently outperforms existing state-of-the-art robot learning methods with an average improvement of 46.9\%. Diffusion Policy learns the gradient of the action-distribution score function and iteratively optimizes with respect to this gradient field during inference via a series of stochastic Langevin dynamics steps. We find that the diffusion formulation yields powerful advantages when used for robot policies, including gracefully handling multimodal action distributions, being suitable for high-dimensional action spaces, and exhibiting impressive training stability. To fully unlock the potential of diffusion models for visuomotor policy learning on physical robots, this paper presents a set of key technical contributions including the incorporation of receding horizon control, visual conditioning, and the time-series diffusion transformer. We hope this work will help motivate a new generation of policy learning techniques that are able to leverage the powerful generative modeling capabilities of diffusion models. Code, data, and training details will be publicly available.},
  archiveprefix = {arxiv},
  keywords = {00-read,00-relevant,Computer Science - Robotics}
}

@inproceedings{Cho2008_sample_variance,
  title = {Variance of the Sample Variance},
  booktitle = {Proceedings of the Survey Research Methods Section},
  author = {Cho, Eungchun and Cho, Moon Jung},
  year = {2008},
  publisher = {{American Statistical Association}}
}

@misc{choiWAICWhyGenerative2019,
  title = {{{WAIC}}, but {{Why}}? {{Generative Ensembles}} for {{Robust Anomaly Detection}}},
  shorttitle = {{{WAIC}}, but {{Why}}?},
  author = {Choi, Hyunsun and Jang, Eric and Alemi, Alexander A.},
  year = {2019},
  month = may,
  number = {arXiv:1810.01392},
  eprint = {1810.01392},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1810.01392},
  urldate = {2024-01-30},
  abstract = {Machine learning models encounter Out-of-Distribution (OoD) errors when the data seen at test time are generated from a different stochastic generator than the one used to generate the training data. One proposal to scale OoD detection to high-dimensional data is to learn a tractable likelihood approximation of the training distribution, and use it to reject unlikely inputs. However, likelihood models on natural data are themselves susceptible to OoD errors, and even assign large likelihoods to samples from other datasets. To mitigate this problem, we propose Generative Ensembles, which robustify density-based OoD detection by way of estimating epistemic uncertainty of the likelihood model. We present a puzzling observation in need of an explanation -- although likelihood measures cannot account for the typical set of a distribution, and therefore should not be suitable on their own for OoD detection, WAIC performs surprisingly well in practice.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/774U49UH/Choi et al. - 2019 - WAIC, but Why Generative Ensembles for Robust Ano.pdf;/home/cbd/Zotero/storage/SVCHLI87/1810.html}
}

@book{chopinIntroductionSequentialMonte2020,
  title = {An {{Introduction}} to {{Sequential Monte Carlo}}},
  author = {Chopin, Nicolas and Papaspiliopoulos, Omiros},
  year = {2020},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  urldate = {2022-10-17},
  isbn = {978-3-030-47844-5},
  file = {/home/cbd/Zotero/storage/MASZ35I4/978-3-030-47845-2.pdf}
}

@article{chouUsingControlSynthesis2018,
  title = {Using Control Synthesis to Generate Corner Cases: {{A}} Case Study on Autonomous Driving},
  author = {Chou, Glen and Sahin, Yunus Emre and Yang, Liren and Rutledge, Kwesi J. and Nilsson, Petter and Ozay, Necmiye},
  year = {2018},
  month = nov,
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {37},
  number = {11},
  eprint = {1807.09537},
  pages = {2906--2917},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {02780070},
  doi = {10.1109/TCAD.2018.2858464},
  urldate = {2022-10-15},
  abstract = {This paper employs correct-by-construction control synthesis, in particular controlled invariant set computations, for falsification. Our hypothesis is that if it is possible to compute a 'large enough' controlled invariant set either for the actual system model or some simplification of the system model, interesting corner cases for other control designs can be generated by sampling initial conditions from the boundary of this controlled invariant set. Moreover, if falsifying trajectories for a given control design can be found through such sampling, then the controlled invariant set can be used as a supervisor to ensure safe operation of the control design under consideration. In addition to interesting initial conditions, which are mostly related to safety violations in transients, we use solutions from a dual game, a reachability game for the safety specification, to find falsifying inputs. We also propose optimization-based heuristics for input generation for cases when the state is outside the winning set of the dual game. To demonstrate the proposed ideas, we consider case studies from basic autonomous driving functionality, in particular, adaptive cruise control and lane keeping. We show how the proposed technique can be used to find interesting falsifying trajectories for classical control designs like proportional controllers, proportional integral controllers and model predictive controllers, as well as an open source real-world autonomous driving package.},
  archiveprefix = {arxiv},
  keywords = {Formal verification,system verification,vehicle safety},
  file = {/home/cbd/Zotero/storage/9WQUJXQR/full-text.pdf}
}

@book{coles_2001,
  title = {An Introduction to Statistical Modeling of Extreme Values},
  author = {Coles, Stuart},
  year = {2001},
  publisher = {{Springer}},
  address = {{London}}
}

@inproceedings{corsoAdaptiveStressTesting2019,
  title = {Adaptive {{Stress Testing}} with {{Reward Augmentation}} for {{Autonomous Vehicle Validatio}}},
  booktitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  author = {Corso, Anthony and Du, Peter and {Driggs-Campbell}, Katherine and Kochenderfer, Mykel J.},
  year = {2019},
  month = oct,
  pages = {163--168},
  doi = {10.1109/ITSC.2019.8917242},
  abstract = {Determining possible failure scenarios is a critical step in the evaluation of autonomous vehicle systems. Real world vehicle testing is commonly employed for autonomous vehicle validation, but the costs and time requirements are high. Consequently, simulation driven methods such as Adaptive Stress Testing (AST) have been proposed to aid in validation. AST formulates the problem of finding the most likely failure scenarios as a Markov decision process, which can be solved using reinforcement learning. In practice, AST tends to find scenarios where failure is unavoidable and tends to repeatedly discover the same types of failures of a system. This work addresses these issues by encoding domain relevant information into the search procedure. With this modification, the AST method discovers a larger and more expressive subset of the failure space when compared to the original AST formulation. We show that our approach is able to identify useful failure scenarios of an autonomous vehicle policy.},
  keywords = {00-read,00-relevant,rl},
  file = {/home/cbd/Zotero/storage/892KV96V/Corso et al. - 2019 - Adaptive Stress Testing with Reward Augmentation f.pdf;/home/cbd/Zotero/storage/LQ76U7XA/8917242.html}
}

@inproceedings{corsoInterpretableSafetyValidation2020a,
  title = {Interpretable {{Safety Validation}} for {{Autonomous Vehicles}}},
  booktitle = {2020 {{IEEE}} 23rd {{International Conference}} on {{Intelligent Transportation Systems}} ({{ITSC}})},
  author = {Corso, Anthony and Kochenderfer, Mykel J.},
  year = {2020},
  month = sep,
  pages = {1--6},
  doi = {10.1109/ITSC45102.2020.9294490},
  abstract = {An open problem for autonomous driving is how to validate the safety of an autonomous vehicle in simulation. Automated testing procedures can find failures of an autonomous system but these failures may be difficult to interpret due to their high dimensionality and may be so unlikely as to not be important. This work describes an approach for finding interpretable failures of an autonomous system. The failures are described by signal temporal logic expressions that can be understood by a human, and are optimized to produce failures that have high likelihood. Our methodology is demonstrated for the safety validation of an autonomous vehicle in the context of an unprotected left turn and a crosswalk with a pedestrian. Compared to a baseline importance sampling approach, our methodology finds more failures with higher likelihood while retaining interpretability.},
  keywords = {00-read,00-relevant,rl},
  file = {/home/cbd/Zotero/storage/9H93QCRZ/Corso and Kochenderfer - 2020 - Interpretable Safety Validation for Autonomous Veh.pdf;/home/cbd/Zotero/storage/9F3PV6JW/9294490.html}
}

@article{corsoSurveyAlgorithmsBlackBox2021,
  title = {A {{Survey}} of {{Algorithms}} for {{Black-Box Safety Validation}} of {{Cyber-Physical Systems}}},
  author = {Corso, Anthony and Moss, Robert and Koren, Mark and Lee, Ritchie and Kochenderfer, Mykel},
  year = {2021},
  month = oct,
  journal = {Journal of Artificial Intelligence Research},
  volume = {72},
  pages = {377--428},
  issn = {1076-9757},
  doi = {10.1613/jair.1.12716},
  urldate = {2023-03-14},
  abstract = {Autonomous cyber-physical systems (CPS) can improve safety and efficiency for safety-critical applications, but require rigorous testing before deployment. The complexity of these systems often precludes the use of formal verification and real-world testing can be too dangerous during development. Therefore, simulation-based techniques have been developed that treat the system under test as a black box operating in a simulated environment. Safety validation tasks include finding disturbances in the environment that cause the system to fail (falsification), finding the most-likely failure, and estimating the probability that the system fails. Motivated by the prevalence of safety-critical artificial intelligence, this work provides a survey of state-of-the-art safety validation techniques for CPS with a focus on applied algorithms and their modifications for the safety validation problem. We present and discuss algorithms in the domains of optimization, path planning, reinforcement learning, and importance sampling. Problem decomposition techniques are presented to help scale algorithms to large state spaces, which are common for CPS. A brief overview of safety-critical applications is given, including autonomous vehicles and aircraft collision avoidance systems. Finally, we present a survey of existing academic and commercially available safety validation tools.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {00-read,00-relevant},
  file = {/home/cbd/Zotero/storage/XQ7KK3CL/Corso et al. - 2021 - A Survey of Algorithms for Black-Box Safety Valida.pdf}
}

@article{cramerWhatCausedChaos2022,
  title = {What {{Caused}} the {{Chaos}} at {{Southwest}}},
  author = {Cramer, Maria and Levenson, Michael},
  year = {2022},
  month = dec,
  journal = {The New York Times},
  issn = {0362-4331},
  urldate = {2024-01-26},
  abstract = {While carriers like Delta, American Airlines and United bounced back after severe winter weather wreaked havoc on holiday travel, the low-cost carrier canceled thousands of flights. Here's why.},
  chapter = {Travel},
  langid = {american},
  keywords = {Airlines and Airplanes,Airports,Customer Relations,Delays (Transportation),Pilots,Snow and Snowstorms,Southwest Airlines Company,Southwest Airlines Pilots Assn,Travel and Vacations,Weather},
  file = {/home/cbd/Zotero/storage/H6NSDSBV/southwest-airlines-flight-cancellations.html}
}

@article{csiszarAxiomaticCharacterizationsInformation2008,
  title = {Axiomatic {{Characterizations}} of {{Information Measures}}},
  author = {Csisz{\'a}r, Imre},
  year = {2008},
  month = sep,
  journal = {Entropy. An International and Interdisciplinary Journal of Entropy and Information Studies},
  volume = {10},
  number = {3},
  pages = {261--273},
  publisher = {{Molecular Diversity Preservation International}},
  issn = {1099-4300},
  doi = {10.3390/e10030261},
  urldate = {2024-01-06},
  abstract = {Axiomatic characterizations of Shannon entropy, Kullback I-divergence, and some generalized information measures are surveyed. Three directions are treated: (A) Characterization of functions of probability distributions suitable as information measures. (B) Characterization of set functions on the subsets of \{1; : : : ;N\} representable by joint entropies of components of an N-dimensional random vector. (C) Axiomatic characterization of MaxEnt and related inference rules. The paper concludes with a brief discussion of the relevance of the axiomatic approach for information theory.},
  langid = {english},
  keywords = {Bregman distance,f- divergence,f-entropy,functional equation,Kullback I-divergence,maximum entropy,proper score,Renyi information measures,Shannon entropy,transitive inference rule},
  file = {/home/cbd/Zotero/storage/8MGS4RWY/Csiszr - 2008 - Axiomatic Characterizations of Information Measure.pdf}
}

@article{csiszarInformationTheoryStatistics2004,
  title = {Information {{Theory}} and {{Statistics}}: {{A Tutorial}}},
  shorttitle = {Information {{Theory}} and {{Statistics}}},
  author = {Csisz{\'a}r, I. and Shields, P. C.},
  year = {2004},
  month = dec,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {1},
  number = {4},
  pages = {417--528},
  publisher = {{Now Publishers, Inc.}},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000004},
  urldate = {2024-01-08},
  abstract = {Information Theory and Statistics: A Tutorial},
  langid = {english},
  file = {/home/cbd/Zotero/storage/RQUDHZ2W/Csiszr and Shields - 2004 - Information Theory and Statistics A Tutorial.pdf}
}

@misc{cusumano-townerAutomatingInvolutiveMCMC2020,
  title = {Automating {{Involutive MCMC}} Using {{Probabilistic}} and {{Differentiable Programming}}},
  author = {{Cusumano-Towner}, Marco and Lew, Alexander K. and Mansinghka, Vikash K.},
  year = {2020},
  month = jul,
  number = {arXiv:2007.09871},
  eprint = {2007.09871},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2007.09871},
  urldate = {2022-11-10},
  abstract = {Involutive MCMC is a unifying mathematical construction for MCMC kernels that generalizes many classic and state-of-the-art MCMC algorithms, from reversible jump MCMC to kernels based on deep neural networks. But as with MCMC samplers more generally, implementing involutive MCMC kernels is often tedious and error-prone, especially when sampling on complex state spaces. This paper describes a technique for automating the implementation of involutive MCMC kernels given (i) a pair of probabilistic programs defining the target distribution and an auxiliary distribution respectively and (ii) a differentiable program that transforms the execution traces of these probabilistic programs. The technique, which is implemented as part of the Gen probabilistic programming system, also automatically detects user errors in the specification of involutive MCMC kernels and exploits sparsity in the kernels for improved efficiency. The paper shows example Gen code for a split-merge reversible jump move in an infinite Gaussian mixture model and a state-dependent mixture of proposals on a combinatorial space of covariance functions for a Gaussian process.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Computation},
  file = {/home/cbd/Zotero/storage/FZUQEXUW/Cusumano-Towner et al. - 2020 - Automating Involutive MCMC using Probabilistic and.pdf;/home/cbd/Zotero/storage/ECAE458I/Cusumano-Towner et al. - 2020 - Automating Involutive MCMC using Probabilistic and.html}
}

@inproceedings{cusumano-townerGenGeneralpurposeProbabilistic2019,
  title = {Gen: {{A}} General-Purpose Probabilistic Programming System with Programmable Inference},
  shorttitle = {Gen},
  booktitle = {Proceedings of the 40th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {{Cusumano-Towner}, Marco F. and Saad, Feras A. and Lew, Alexander K. and Mansinghka, Vikash K.},
  year = {2019},
  month = jun,
  series = {{{PLDI}} 2019},
  pages = {221--236},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3314221.3314642},
  urldate = {2024-01-04},
  abstract = {Although probabilistic programming is widely used for some restricted classes of statistical models, existing systems lack the flexibility and efficiency needed for practical use with more challenging models arising in fields like computer vision and robotics. This paper introduces Gen, a general-purpose probabilistic programming system that achieves modeling flexibility and inference efficiency via several novel language constructs: (i) the generative function interface for encapsulating probabilistic models; (ii) interoperable modeling languages that strike different flexibility/efficiency trade-offs; (iii) combinators that exploit common patterns of conditional independence; and (iv) an inference library that empowers users to implement efficient inference algorithms at a high level of abstraction. We show that Gen outperforms state-of-the-art probabilistic programming systems, sometimes by multiple orders of magnitude, on diverse problems including object tracking, estimating 3D body pose from a depth image, and inferring the structure of a time series.},
  isbn = {978-1-4503-6712-7},
  keywords = {Markov chain Monte Carlo,Probabilistic programming,sequential Monte Carlo,variational inference},
  file = {/home/cbd/Zotero/storage/X7I3LA84/Cusumano-Towner et al. - 2019 - Gen a general-purpose probabilistic programming s.pdf}
}

@article{dalalyanTheoreticalGuaranteesApproximate2017,
  title = {Theoretical Guarantees for Approximate Sampling from Smooth and Log-Concave Densities},
  author = {Dalalyan, Arnak S.},
  year = {2017},
  journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
  volume = {79},
  number = {3},
  pages = {651--676},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {1369-7412},
  urldate = {2023-05-06},
  abstract = {Sampling from various kinds of distribution is an issue of paramount importance in statistics since it is often the key ingredient for constructing estimators, test procedures or confidence intervals. In many situations, exact sampling from a given distribution is impossible or computationally expensive and, therefore, one needs to resort to approximate sampling strategies. However, there is no well-developed theory providing meaningful non-asymptotic guarantees for the approximate sampling procedures, especially in high dimensional problems. The paper makes some progress in this direction by considering the problem of sampling from a distribution having a smooth and log-concave density defined on R{$\rho$}, for some integer P{$>$}0. We establish non-asymptotic bounds for the error of approximating the target distribution by the distribution obtained by the Langevin Monte Carlo method and its variants. We illustrate the effectiveness of the established guarantees with various experiments. Underlying our analysis are insights from the theory of continuous time diffusion processes, which may be of interest beyond the framework of log-concave densities that are considered in the present work.},
  jstor = {44681805},
  file = {/home/cbd/Zotero/storage/WF34I2P5/Dalalyan - 2017 - Theoretical guarantees for approximate sampling fr.pdf}
}

@article{dantoniSensitivityAnalysisUsing2013,
  title = {Sensitivity Analysis Using Type-Based Constraints},
  author = {D'antoni, Loris and Gaboardi, Marco and Arias, Emilio Jes{\'u}s Gallego and Haeberlen, Andreas and Pierce, Benjamin C.},
  year = {2013},
  journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
  pages = {43--50},
  doi = {10.1145/2505351.2505353},
  urldate = {2022-10-15},
  abstract = {Function sensitivity-how much the result of a function can change with respect to linear changes in the input-is a key concept in many research areas. For instance, in differential privacy, one of the most common mechanisms for turning a (possibly privacy-leaking) query into a differentially private one involves establishing a bound on its sensitivity. One approach to sensitivity analysis is to use a type-based approach, extending the Hindley-Milner type system with functional types capturing statically the sensitivity of a functional expression. This approach - based on affine logic - has been used in Fuzz, a language for differentially private queries. We describe an automatic typed-based analysis that infers and checks the sensitivity annotations for simple functional programs. We have implemented a prototype in Fuzz's compiler. The first component of the analysis extends the typechecker to generate nonlinear constraints over the positive real numbers extended with infinity, which are then checked by the Z3 SMT solver; a solution for them will provide an upper bound on the sensitivity annotations and ensure the correctness of the annotations. We also present a simple sensitivity minimization procedure and demonstrate the effectiveness of the approach by analyzing several examples. {\copyright} 2013 by the Association for Computing Machinery, Inc. (ACM).},
  isbn = {9781450323802},
  keywords = {Differential privacy,Linear types,Sensitivity analysis,SMT solver,Special purpose language,Special Purpose Language,Theory Keywords Sensitivity Analysis},
  file = {/home/cbd/Zotero/storage/JXGZ44IT/full-text.pdf}
}

@inproceedings{dawsonBayesianApproachBreaking2023,
  title = {A {{Bayesian}} Approach to Breaking Things: {{Efficiently}} Predicting and Repairing Failure Modes via Sampling},
  shorttitle = {A {{Bayesian}} Approach to Breaking Things},
  booktitle = {7th {{Annual Conference}} on {{Robot Learning}}},
  author = {Dawson, Charles and Fan, Chuchu},
  year = {2023},
  month = aug,
  urldate = {2023-09-21},
  abstract = {Before autonomous systems can be deployed in safety-critical applications, we must be able to understand and verify the safety of these systems. For cases where the risk or cost of real-world testing is prohibitive, we propose a simulation-based framework for a) predicting ways in which an autonomous system is likely to fail and b) automatically adjusting the system's design to preemptively mitigate those failures. We frame this problem through the lens of approximate Bayesian inference and use differentiable simulation for efficient failure case prediction and repair. We apply our approach on a range of robotics and control problems, including optimizing search patterns for robot swarms and reducing the severity of outages in power transmission networks. Compared to optimization-based falsification techniques, our method predicts a more diverse, representative set of failure modes, and we also find that our use of differentiable simulation yields solutions that have up to 10x lower cost and requires up to 2x fewer iterations to converge relative to gradient-free techniques.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/ZQRZGTQL/Dawson and Fan - 2023 - A Bayesian approach to breaking things efficientl.pdf}
}

@inproceedings{dawsonCertifiableRobotDesign2022,
  title = {Certifiable {{Robot Design Optimization}} Using {{Differentiable Programming}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVIII}}},
  author = {Dawson, Charles and Fan, Chuchu},
  year = {2022},
  month = jun,
  volume = {18},
  urldate = {2023-05-23},
  isbn = {978-0-9923747-8-5},
  file = {/home/cbd/Zotero/storage/LAWWYRS5/Dawson and Fan - 2022 - Certifiable Robot Design Optimization using Differ.pdf}
}

@article{dawsonLearningSafeGeneralizable2022,
  title = {Learning {{Safe}}, {{Generalizable Perception-Based Hybrid Control With Certificates}}},
  author = {Dawson, Charles and Lowenkamp, Bethany and Goff, Dylan and Fan, Chuchu},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {1904--1911},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3141657},
  abstract = {Many robotic tasks require high-dimensional sensors such as cameras and Lidar to navigate complex environments, but developing certifiably safe feedback controllers around these sensors remains a challenging open problem, particularly when learning is involved. Previous works have proved the safety of perception-feedback controllers by separating the perception and control subsystems and making strong assumptions on the abilities of the perception subsystem. In this work, we introduce a novel learning-enabled perception-feedback hybrid controller, where we use Control Barrier Functions (CBFs) and Control Lyapunov Functions (CLFs) to show the safety and liveness of a full-stack perception-feedback controller. We use neural networks to learn a CBF and CLF for the full-stack system directly in the observation space of the robot, without the need to assume a separate perception-based state estimator. Our hybrid controller, called LOCUS (Learning-enabled Observation-feedback Control Using Switching), can safely navigate unknown environments, consistently reach its goal, and generalizes safely to environments outside of the training dataset. We demonstrate LOCUS in experiments both in simulation and in hardware, where it successfully navigates a changing environment using feedback from a Lidar sensor.},
  keywords = {certificate learning,control barrier functions,Laser radar,Lyapunov methods,Navigation,Perception-based control,Robot kinematics,Robots,safe control,Safety,Sensors},
  file = {/home/cbd/Zotero/storage/MZE8ZZGJ/Dawson et al. - 2022 - Learning Safe, Generalizable Perception-Based Hybr.pdf}
}

@inproceedings{dawsonRobustCounterexampleguidedOptimization2022b,
  title = {Robust {{Counterexample-guided Optimization}} for {{Planning}} from {{Differentiable Temporal Logic}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Dawson, Charles and Fan, Chuchu},
  year = {2022},
  month = oct,
  pages = {7205--7212},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981382},
  abstract = {Signal temporal logic (STL) provides a powerful, flexible framework for specifying complex autonomy tasks; however, existing methods for planning based on STL specifications have difficulty scaling to long-horizon tasks and are not robust to external disturbances. In this paper, we present an algorithm for finding robust plans that satisfy STL specifications. Our method alternates between local optimization and local falsification, using automatically differentiable temporal logic to iteratively optimize its plan in response to counterexamples found during the falsification process. We benchmark our counterexample-guided planning method against state-of-the-art planning methods on two long-horizon satellite rendezvous missions, showing that our method finds high-quality plans that satisfy STL specifications despite adversarial disturbances. We find that our method consistently finds plans that are robust to adversarial disturbances and requires less than half the time of competing methods. We provide an implementation of our planner at https://github.com/MIT-REALM/architect.},
  keywords = {differentiable programming,formal methods,Human-robot interaction,Iterative algorithms,Model checking,Planning,Programming,Satellites,Source coding,temporal logic},
  file = {/home/cbd/Zotero/storage/QU2FYX4R/Dawson and Fan - 2022 - Robust Counterexample-guided Optimization for Plan.pdf;/home/cbd/Zotero/storage/LC8B3R72/9981382.html}
}

@article{dawsonSafeControlLearned2023,
  title = {Safe {{Control With Learned Certificates}}: {{A Survey}} of {{Neural Lyapunov}}, {{Barrier}}, and {{Contraction Methods}} for {{Robotics}} and {{Control}}},
  shorttitle = {Safe {{Control With Learned Certificates}}},
  author = {Dawson, Charles and Gao, Sicun and Fan, Chuchu},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--19},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3232542},
  abstract = {Learning-enabled control systems have demonstrated impressive empirical performance on challenging control problems in robotics, but this performance comes at the cost of reduced transparency and lack of guarantees on the safety or stability of the learned controllers. In recent years, new techniques have emerged to provide these guarantees by learning certificates alongside control policies---these certificates provide concise data-driven proofs that guarantee the safety and stability of the learned control system. These methods not only allow the user to verify the safety of a learned controller but also provide supervision during training, allowing safety and stability requirements to influence the training process itself. In this article, we provide a comprehensive survey of this rapidly developing field of certificate learning. We hope that this article will serve as an accessible introduction to the theory and practice of certificate learning, both to those who wish to apply these tools to practical robotics problems and to those who wish to dive more deeply into the theory of learning for control.},
  keywords = {Asymptotic stability,Deep learning in robotics and automation,formal methods in robotics and automation,Lyapunov methods,Measurement,neural certificates,robot safety,Robots,Safety,Trajectory,Trajectory tracking}
}

@inproceedings{dawsonSafeNonlinearControl2022,
  title = {Safe {{Nonlinear Control Using Robust Neural Lyapunov-Barrier Functions}}},
  booktitle = {Proceedings of the 5th {{Conference}} on {{Robot Learning}}},
  author = {Dawson, Charles and Qin, Zengyi and Gao, Sicun and Fan, Chuchu},
  year = {2022},
  month = jan,
  pages = {1724--1735},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-05-23},
  abstract = {Safety and stability are common requirements for robotic control systems; however, designing safe, stable controllers remains difficult for nonlinear and uncertain models. We develop a model-based learning approach to synthesize robust feedback controllers with safety and stability guarantees. We take inspiration from robust convex optimization and Lyapunov theory to define robust control Lyapunov barrier functions that generalize despite model uncertainty. We demonstrate our approach in simulation on problems including car trajectory tracking, nonlinear control with obstacle avoidance, satellite rendezvous with safety constraints, and flight control with a learned ground effect model. Simulation results show that our approach yields controllers that match or exceed the capabilities of robust MPC while reducing computational costs by an order of magnitude. We provide source code at github.com/dawsonc/neural\_clbf/.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/7575P8RM/Dawson et al. - 2022 - Safe Nonlinear Control Using Robust Neural Lyapuno.pdf}
}

@inproceedings{deasyConstrainingVariationalInference2020,
  title = {Constraining Variational Inference with Geometric Jensen-Shannon Divergence},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Deasy, Jacob and Simidjievski, Nikola and Li{\`o}, Pietro},
  year = {2020},
  month = dec,
  series = {{{NIPS}}'20},
  pages = {10647--10658},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  urldate = {2024-01-06},
  abstract = {We examine the problem of controlling divergences for latent space regularisation in variational autoencoders. Specifically, when aiming to reconstruct example x {$\in$} Rm via latent space z {$\in$} Rn(n {$\leq$} m), while balancing this against the need for generalisable latent representations. We present a regularisation mechanism based on the skew-geometric Jensen-Shannon divergence (JSG{$\alpha$}). We find a variation in JSG{$\alpha$}, motivated by limiting cases, which leads to an intuitive interpolation between forward and reverse KL in the space of both distributions and divergences. We motivate its potential benefits for VAEs through low-dimensional examples, before presenting quantitative and qualitative results. Our experiments demonstrate that skewing our variant of JSG{$\alpha$}, in the context of JSG{$\alpha$} -VAEs, leads to better reconstruction and generation when compared to several baseline VAEs. Our approach is entirely unsupervised and utilises only one hyperparameter which can be easily interpreted in latent space.},
  isbn = {978-1-71382-954-6},
  file = {/home/cbd/Zotero/storage/TP9NHJ7Y/Deasy et al. - 2020 - Constraining variational inference with geometric .pdf}
}

@inproceedings{decastroInterpretablePoliciesFormallySpecified2020,
  title = {Interpretable {{Policies}} from {{Formally-Specified Temporal Properties}}},
  booktitle = {{{IEEE Int}}. {{Conf}}. on {{Intelligent Transportation Systems}}},
  author = {Decastro, Jonathan and Leung, Karen and Ar{\'e}chiga, Nikos and Pavone, Marco},
  year = {2020},
  urldate = {2022-02-10},
  abstract = {We present an approach to interpret parame-terized policies through the lens of Signal Temporal Logic (STL). By providing a formally-specified description of desired behaviors we want the policy to produce, we can identify clusters in the parameter space of the policy that can produce the desired behavior. In the context of agent simulation for autonomous driving, this enables an automated way to target and produce challenging scenarios to stress-test the autonomous driving stack and hence accelerate validation and testing. Our approach leverages parametric signal temporal logic (pSTL) formulas to construct an interpretable view on the modeling parameters via a sequence of variational inference problems; one to solve for the pSTL parameters and another to construct a new parameterization satisfying the specification. We perform clustering on the new parameter space using a finite set of examples, either real or simulated, and combine computational graph learning and normalizing flows to form a relationship between these parameters and pSTL formulas either derived by hand or inferred from data. We illustrate the utility of our approach to model selection for validation of the safety properties of an autonomous driving system, using a learned generative model of the surrounding agents.},
  keywords = {inference,interpretability,STL},
  file = {/home/cbd/Zotero/storage/IICJRQPH/full-text.pdf}
}

@article{dekleerDiagnosingMultipleFaults1987,
  title = {Diagnosing Multiple Faults},
  author = {{de Kleer}, Johan and Williams, Brian C.},
  year = {1987},
  month = apr,
  journal = {Artificial Intelligence},
  volume = {32},
  number = {1},
  pages = {97--130},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(87)90063-4},
  urldate = {2023-01-04},
  abstract = {Diagnostic tasks require determining the differences between a model of an artifact and the artifact itself. The differences between the manifested behavior of the artifact and the predicted behavior of the model guide the search for the differences between the artifact and its model. The diagnostic procedure presented in this paper is model-based, inferring the behavior of the composite device from knowledge of the structure and function of the individual components comprising the device. The system (GDE---general diagnostic engine) has been implemented and tested on many examples in the domain of troubleshooting digital circuits. This research makes several novel contributions: First, the system diagnoses failures due to multiple faults. Second, failure candidates are represented and manipulated in terms of minimal sets of violated assumptions, resulting in an efficient diagnostic procedure. Third, the diagnostic procedure is incremental, exploiting the iterative nature of diagnosis. Fourth, a clear separation is drawn between diagnosis and behavior prediction, resulting in a domain (and inference procedure) independent diagnostic procedure. Fifth, GDE combines model-based prediction with sequential diagnosis to propose measurements to localize the faults. The normally required conditional probabilities are computed from the structure of the device and models of its components. This capability results from a novel way of incorporating probabilities and information theory into the context mechanism provided by assumption-based truth maintenance.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/7ALGF54E/de Kleer and Williams - 1987 - Diagnosing multiple faults.pdf;/home/cbd/Zotero/storage/253NPPUK/0004370287900634.html}
}

@inproceedings{deleckiModelbasedValidationProbabilistic2023a,
  title = {Model-Based {{Validation}} as {{Probabilistic Inference}}},
  booktitle = {Proceedings of {{The}} 5th {{Annual Learning}} for {{Dynamics}} and {{Control Conference}}},
  author = {Delecki, Harrison and Corso, Anthony and Kochenderfer, Mykel},
  year = {2023},
  month = jun,
  pages = {825--837},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-09-21},
  abstract = {Estimating the distribution over failures is a key step in validating autonomous systems. Existing approaches focus on finding failures for a small range of initial conditions or make restrictive assumptions about the properties of the system under test. We frame estimating the distribution over failure trajectories for sequential systems as Bayesian inference. Our model-based approach represents the distribution over failure trajectories using rollouts of system dynamics and computes trajectory gradients using automatic differentiation. Our approach is demonstrated in an inverted pendulum control system, an autonomous vehicle driving scenario, and a partially observable lunar lander. Sampling is performed using an off-the-shelf implementation of Hamiltonian Monte Carlo with multiple chains to capture multimodality and gradient smoothing for safe trajectories. In all experiments, we observed improvements in sample efficiency and parameter space coverage compared to black-box baseline approaches. This work is open sourced.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/3X7XIKS4/Delecki et al. - 2023 - Model-based Validation as Probabilistic Inference.pdf}
}

@article{dellaertFactorGraphsExploiting2021,
  title = {Factor {{Graphs}}: {{Exploiting Structure}} in {{Robotics}}},
  shorttitle = {Factor {{Graphs}}},
  author = {Dellaert, Frank},
  year = {2021},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {4},
  number = {1},
  pages = {141--166},
  doi = {10.1146/annurev-control-061520-010504},
  urldate = {2023-06-07},
  abstract = {Many estimation, planning, and optimal control problems in robotics have an optimization problem at their core. In most of these optimization problems, the objective to be maximized or minimized is composed of many different factors or terms that are local in nature---that is, they depend only on a small subset of the variables. A particularly insightful way of modeling this locality structure is to use the concept of factor graphs, a bipartite graphical model in which factors represent functions on subsets of variables. Factor graphs can represent a wide variety of problems across robotics, expose opportunities to improve computational performance, and are beneficial in designing and thinking about how to model a problem, even aside from performance considerations. I discuss each of these three aspects in detail and review several state-of-the-art robotics applications in which factor graphs have been used with great success.},
  keywords = {estimation,factor graphs,graphical models,motion planning,simultaneous localization and mapping,SLAM},
  file = {/home/cbd/Zotero/storage/3Y3CWU2L/Dellaert - 2021 - Factor Graphs Exploiting Structure in Robotics.pdf}
}

@article{demagalhaescarvalhoSecurityConstrainedOptimalPower2018,
  title = {Security-{{Constrained Optimal Power Flow}} via {{Cross-Entropy Method}}},
  author = {{de Magalh{\~a}es Carvalho}, Leonel and {Leite da Silva}, Armando Martins and Miranda, Vladimiro},
  year = {2018},
  month = nov,
  journal = {IEEE Transactions on Power Systems},
  volume = {33},
  number = {6},
  pages = {6621--6629},
  issn = {1558-0679},
  doi = {10.1109/TPWRS.2018.2847766},
  abstract = {This paper proposes a new optimization tool based on the cross-entropy (CE) method to assess security-constrained optimal power flow (SCOPF) solutions. First, the corresponding SCOPF stochastic problem is defined so that the optimum solution is interpreted as a rare event to be reached by a random search. Second, the CE method solves this new problem efficiently by making adaptive changes to the probability density function according to the Kullback-Leibler distance, creating a sequence of density functions that guides the search in the direction of the theoretically degenerate density at the optimal point. Different types of density functions are tested in order to cope with discrete variables present in the SCOPF problem. Two test systems, namely the IEEE 57 bus and the IEEE 300 bus, are used to evaluate the effectiveness of the proposed method in terms of solution quality and computational effort. Comparisons carried out with reference algorithms in the literature demonstrate that the CE method is capable of finding better solutions for the SCOPF problem with fewer evaluations.},
  keywords = {Cross-entropy method,Load flow,Monte Carlo methods,Monte Carlo simulation,Optimization,rare event simulation,security-constrained optimal power flow,Simulation},
  file = {/home/cbd/Zotero/storage/D9PLZRY8/de Magalhes Carvalho et al. - 2018 - Security-Constrained Optimal Power Flow via Cross-.pdf;/home/cbd/Zotero/storage/B58TW3DK/8386709.html}
}

@book{demboLargeDeviationsTechniques2010,
  title = {Large {{Deviations Techniques}} and {{Applications}}},
  author = {Dembo, Amir and Zeitouni, Ofer},
  year = {2010},
  series = {Stochastic {{Modelling}} and {{Applied Probability}}},
  volume = {38},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-03311-7},
  urldate = {2024-02-01},
  isbn = {978-3-642-03310-0 978-3-642-03311-7},
  keywords = {Area,convergence,DEX,DNA,electrical engineering,field,large deviations,mathematics,mechanics,probability,Rang,Sharp,statistics,techniques,tool},
  file = {/home/cbd/Zotero/storage/U4C8FI3Q/Dembo and Zeitouni - 2010 - Large Deviations Techniques and Applications.pdf}
}

@inproceedings{dengOpenFWILargescaleMultistructural2022,
  title = {{{OpenFWI}}: {{Large-scale Multi-structural Benchmark Datasets}} for {{Full Waveform Inversion}}},
  shorttitle = {{{OpenFWI}}},
  booktitle = {Thirty-Sixth {{Conference}} on {{Neural Information Processing Systems Datasets}} and {{Benchmarks Track}}},
  author = {Deng, Chengyuan and Feng, Shihang and Wang, Hanchen and Zhang, Xitong and Jin, Peng and Feng, Yinan and Zeng, Qili and Chen, Yinpeng and Lin, Youzuo},
  year = {2022},
  month = jun,
  urldate = {2024-01-17},
  abstract = {Full waveform inversion (FWI) is widely used in geophysics to reconstruct high-resolution velocity maps from seismic data. The recent success of data-driven FWI methods results in a rapidly increasing demand for open datasets to serve the geophysics community. We present OpenFWI, a collection of large-scale multi-structural benchmark datasets, to facilitate diversified, rigorous, and reproducible research on FWI. In particular, OpenFWI consists of \$12\$ datasets (\$2.1\$TB in total) synthesized from multiple sources. It encompasses diverse domains in geophysics (interface, fault, CO\$\_2\$ reservoir, etc.), covers different geological subsurface structures (flat, curve, etc.), and contain various amounts of data samples (2K - 67K). It also includes a dataset for 3D FWI. Moreover, we use OpenFWI to perform benchmarking over four deep learning methods, covering both supervised and unsupervised learning regimes. Along with the benchmarks, we implement additional experiments, including physics-driven methods, complexity analysis, generalization study, uncertainty quantification, and so on, to sharpen our understanding of datasets and methods. The studies either provide valuable insights into the datasets and the performance, or uncover their current limitations. We hope OpenFWI supports prospective research on FWI and inspires future open-source efforts on AI for science. All datasets and related information can be accessed through our website at https://openfwi-lanl.github.io/},
  langid = {english},
  file = {/home/cbd/Zotero/storage/36ZI679G/Deng et al. - 2022 - OpenFWI Large-scale Multi-structural Benchmark Da.pdf}
}

@article{deshmukhStochasticLocalSearch2015,
  title = {Stochastic Local Search for Falsification of Hybrid Systems},
  author = {Deshmukh, Jyotirmoy and Jin, Xiaoqing and Kapinski, James and Maler, Oded},
  year = {2015},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {9364},
  pages = {500--517},
  publisher = {{Springer Verlag}},
  issn = {16113349},
  doi = {10.1007/978-3-319-24953-7_35/FIGURES/2},
  urldate = {2022-10-18},
  abstract = {Falsification techniques for models of embedded control systems automate the process of testing models to find bugs by searching for model-inputs that violate behavioral specifications given by logical and quantitative correctness requirements. A recent advance in falsification is to encode property satisfaction as a cost function based on a finite parameterization of the (bounded-time) input signal, which allows formulating bug-finding as an optimization problem. In this paper, we present a falsification technique that uses a local search technique called Tabu search to search for optimal inputs. The key idea is to discretize the space of input signals and use the Tabu list to avoid revisiting previously encountered input signals. As local search techniques may converge to local optima, we introduce stochastic aspects such as random restarts, sampling and probabilistically picking suboptimal inputs to guide the technique towards a global optimum. Picking the right parameterization of the input space is often challenging for designers, so we allow dynamic refinement of the input space as the search progresses. We implement the technique in a tool called sitar, and show scalability of the technique by using it to falsify requirements on an early prototype of an industrial-sized automotive powertrain control design.},
  isbn = {9783319249520},
  file = {/home/cbd/Zotero/storage/R9DAP8VB/full-text.pdf}
}

@inproceedings{dingLearningCollideAdaptive2020a,
  title = {Learning to {{Collide}}: {{An Adaptive Safety-Critical Scenarios Generating Method}}},
  shorttitle = {Learning to {{Collide}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Ding, Wenhao and Chen, Baiming and Xu, Minjun and Zhao, Ding},
  year = {2020},
  month = oct,
  pages = {2243--2250},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9340696},
  abstract = {Long-tail and rare event problems become crucial when autonomous driving algorithms are applied in the real world. For the purpose of evaluating systems in challenging settings, we propose a generative framework to create safety-critical scenarios for evaluating specific task algorithms. We first represent the traffic scenarios with a series of autoregressive building blocks and generate diverse scenarios by sampling from the joint distribution of these blocks. We then train the generative model as an agent (or a generator) to search the risky scenario parameters for a given driving algorithm. We treat the driving algorithm as an environment that returns high reward to the agent when a risky scenario is generated. The whole process is optimized by the policy gradient reinforcement learning method. Through the experiments conducted on several scenarios in the simulation, we demonstrate that the proposed framework generates safety-critical scenarios more efficiently than grid search or human design methods. Another advantage of this method is its adaptiveness to the routes and parameters.},
  keywords = {00-read,00-relevant,Adaptation models,Generators,Intelligent robots,Probability distribution,Reinforcement learning,Task analysis,Training},
  file = {/home/cbd/Zotero/storage/2YEBTSB3/Ding et al. - 2020 - Learning to Collide An Adaptive Safety-Critical S.pdf;/home/cbd/Zotero/storage/56SQFKSQ/9340696.html}
}

@article{dingMultimodalSafetyCriticalScenarios2021,
  title = {Multimodal {{Safety-Critical Scenarios Generation}} for {{Decision-Making Algorithms Evaluation}}},
  author = {Ding, Wenhao and Chen, Baiming and Li, Bo and Eun, Kim Ji and Zhao, Ding},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {1551--1558},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3058873},
  abstract = {Existing neural network-based autonomous systems are shown to be vulnerable against adversarial attacks, therefore sophisticated evaluation of their robustness is of great importance. However, evaluating the robustness under the worst-case scenarios based on known attacks is not comprehensive, not to mention that some of them even rarely occur in the real world. Also, the distribution of safety-critical data is usually multimodal, while most traditional attacks and evaluation methods focus on a single modality. To solve the above challenges, we propose a flow-based multimodal safety-critical scenario generator for evaluating decision-making algorithms. The proposed generative model is optimized with weighted likelihood maximization and a gradient-based sampling procedure is integrated to improve the sampling efficiency. The safety-critical scenarios are generated by efficiently querying the task algorithms and a simulator. Experiments on a self-driving task demonstrate our advantages in terms of testing efficiency and multimodal modeling capability. We evaluate six Reinforcement Learning algorithms with our generated traffic scenarios and provide empirical conclusions about their robustness.},
  keywords = {Adaptation models,Data models,Decision making,Generators,reinforcement learning,Robot safety,Robustness,semantic scene understanding,Task analysis,Training}
}

@misc{dingSurveySafetyCriticalDriving2022,
  title = {A {{Survey}} on {{Safety-Critical Driving Scenario Generation}} -- {{A Methodological Perspective}}},
  author = {Ding, Wenhao and Xu, Chejian and Arief, Mansur and Lin, Haohong and Li, Bo and Zhao, Ding},
  year = {2022},
  month = oct,
  number = {arXiv:2202.02215},
  eprint = {2202.02215},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2202.02215},
  urldate = {2023-03-14},
  abstract = {Autonomous driving systems have witnessed a significant development during the past years thanks to the advance in machine learning-enabled sensing and decision-making algorithms. One critical challenge for their massive deployment in the real world is their safety evaluation. Most existing driving systems are still trained and evaluated on naturalistic scenarios collected from daily life or heuristically-generated adversarial ones. However, the large population of cars, in general, leads to an extremely low collision rate, indicating that the safety-critical scenarios are rare in the collected real-world data. Thus, methods to artificially generate scenarios become crucial to measure the risk and reduce the cost. In this survey, we focus on the algorithms of safety-critical scenario generation in autonomous driving. We first provide a comprehensive taxonomy of existing algorithms by dividing them into three categories: data-driven generation, adversarial generation, and knowledge-based generation. Then, we discuss useful tools for scenario generation, including simulation platforms and packages. Finally, we extend our discussion to five main challenges of current works -- fidelity, efficiency, diversity, transferability, controllability -- and research opportunities lighted up by these challenges.},
  archiveprefix = {arxiv},
  keywords = {00-read,00-relevant},
  file = {/home/cbd/Zotero/storage/9C2253BS/Ding et al. - 2022 - A Survey on Safety-Critical Driving Scenario Gener.pdf;/home/cbd/Zotero/storage/XJ2GVP5M/2202.html}
}

@inproceedings{dontiAdversariallyRobustLearning2021,
  title = {Adversarially Robust Learning for Security-Constrained Optimal Power Flow},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Donti, Priya and Agarwal, Aayushya and Bedmutha, Neeraj Vijay and Pileggi, Larry and Kolter, J. Zico},
  year = {2021},
  volume = {34},
  pages = {28677--28689},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-12-04},
  file = {/home/cbd/Zotero/storage/LMF3AMPX/Donti et al. - 2021 - Adversarially robust learning for security-constra.pdf}
}

@misc{dontiDC3LearningMethod2021,
  title = {{{DC3}}: {{A}} Learning Method for Optimization with Hard Constraints},
  shorttitle = {{{DC3}}},
  author = {Donti, Priya L. and Rolnick, David and Kolter, J. Zico},
  year = {2021},
  month = apr,
  number = {arXiv:2104.12225},
  eprint = {2104.12225},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2104.12225},
  urldate = {2022-12-17},
  abstract = {Large optimization problems with hard constraints arise in many settings, yet classical solvers are often prohibitively slow, motivating the use of deep networks as cheap "approximate solvers." Unfortunately, naive deep learning approaches typically cannot enforce the hard constraints of such problems, leading to infeasible solutions. In this work, we present Deep Constraint Completion and Correction (DC3), an algorithm to address this challenge. Specifically, this method enforces feasibility via a differentiable procedure, which implicitly completes partial solutions to satisfy equality constraints and unrolls gradient-based corrections to satisfy inequality constraints. We demonstrate the effectiveness of DC3 in both synthetic optimization tasks and the real-world setting of AC optimal power flow, where hard constraints encode the physics of the electrical grid. In both cases, DC3 achieves near-optimal objective values while preserving feasibility.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/6WQEN5VD/Donti et al. - 2021 - DC3 A learning method for optimization with hard .pdf;/home/cbd/Zotero/storage/JYNWG3DI/2104.html}
}

@article{donzeBreachToolboxVerification2010,
  title = {Breach, {{A Toolbox}} for {{Verification}} and {{Parameter Synthesis}} of {{Hybrid Systems}}},
  author = {Donz{\'e}, Alexandre},
  year = {2010},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {6174 LNCS},
  pages = {167--170},
  publisher = {{Springer, Berlin, Heidelberg}},
  issn = {03029743},
  doi = {10.1007/978-3-642-14295-6_17},
  urldate = {2022-02-18},
  abstract = {We describe Breach, a Matlab/C++ toolbox providing a coherent set of simulation-based techniques aimed at the analysis of deterministic models of hybrid dynamical systems. The primary feature of Breach is to facilitate the computation and the property investigation of large sets of trajectories. It relies on an efficient numerical solver of ordinary differential equations that can also provide information about sensitivity with respect to parameters variation. The latter is used to perform approximate reachability analysis and parameter synthesis. A major novel feature is the robust monitoring of metric interval temporal logic (MITL) formulas. The application domain of Breach ranges from embedded systems design to the analysis of complex non-linear models from systems biology. {\copyright} 2010 Springer-Verlag.},
  isbn = {364214294X},
  keywords = {stl},
  file = {/home/cbd/Zotero/storage/U8WM7W4P/full-text.pdf}
}

@inproceedings{donzeEfficientRobustMonitoring2013a,
  title = {Efficient {{Robust Monitoring}} for {{STL}}},
  booktitle = {Computer {{Aided Verification}}},
  author = {Donz{\'e}, Alexandre and Ferr{\`e}re, Thomas and Maler, Oded},
  editor = {Sharygina, Natasha and Veith, Helmut},
  year = {2013},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {264--279},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-39799-8_19},
  abstract = {Monitoring transient behaviors of real-time systems plays an important role in model-based systems design. Signal Temporal Logic (STL) emerges as a convenient and powerful formalism for continuous and hybrid systems. This paper presents an efficient algorithm for computing the robustness degree in which a piecewise-continuous signal satisfies or violates an STL formula. The algorithm, by leveraging state-of-the-art streaming algorithms from Signal Processing, is linear in the size of the signal and its implementation in the Breach tool is shown to outperform alternative implementations.},
  isbn = {978-3-642-39799-8},
  langid = {english},
  file = {/home/cbd/Zotero/storage/3KEPVCTB/Donz et al. - 2013 - Efficient Robust Monitoring for STL.pdf}
}

@article{donzeParameterSynthesisHybrid2009,
  title = {Parameter {{Synthesis}} for {{Hybrid Systems}} with an {{Application}} to {{Simulink Models}}},
  author = {Donz{\'e}, Alexandre and Krogh, Bruce and Rajhans, Akshay},
  year = {2009},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {5469},
  pages = {165--179},
  publisher = {{Springer, Berlin, Heidelberg}},
  issn = {03029743},
  doi = {10.1007/978-3-642-00602-9_12},
  urldate = {2022-02-18},
  abstract = {This paper addresses a parameter synthesis problem for nonlinear hybrid systems. Considering a set of uncertain parameters and a safety property, we give an algorithm that returns a partition of the set of parameters into subsets classified as safe, unsafe, or uncertain, depending on whether respectively all, none, or some of their behaviors satisfy the safety property. We make use of sensitivity analysis to compute approximations of reachable sets and an error control mechanism to determine the size of the partition elements in order to obtain the desired precision. We apply the technique to Simulink models by combining generated code with a numerical solver that can compute sensitivities to parameter variations. We present experimental results on a non-trivial Simulink model of a quadrotor helicopter.},
  isbn = {9783642006012},
  keywords = {to_read},
  file = {/home/cbd/Zotero/storage/4PXP2E3A/full-text.pdf}
}

@article{donzeSystematicSimulationUsing2007,
  title = {Systematic {{Simulation Using Sensitivity Analysis}}},
  author = {Donz{\'e}, Alexandre and Maler, Oded},
  year = {2007},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {4416 LNCS},
  pages = {174--189},
  publisher = {{Springer, Berlin, Heidelberg}},
  issn = {16113349},
  doi = {10.1007/978-3-540-71493-4_16},
  urldate = {2022-02-18},
  abstract = {In this paper we propose a new technique for verification by simulation of continuous and hybrid dynamical systems with uncertain initial conditions. We provide an algorithmic methodology that can, in most cases, verify that the system avoids a set of bad states by conducting a finite number of simulation runs starting from a finite subset of the set of possible initial conditions. The novelty of our approach consists in the use of sensitivity analysis, developed and implemented in the context of numerical integration, to efficiently characterize the coverage of sampling trajectories. {\copyright} Springer-Verlag Berlin Heidelberg 2007.},
  isbn = {9783540714927},
  keywords = {stl,to_read},
  file = {/home/cbd/Zotero/storage/I93FY5EG/full-text.pdf}
}

@inproceedings{Dosovitskiy17,
  title = {{{CARLA}}: {{An}} Open Urban Driving Simulator},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  author = {Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
  year = {2017},
  pages = {1--16}
}

@misc{DOTPenalizesSouthwest,
  title = {{{DOT Penalizes Southwest Airlines}} \$140 {{Million}} for 2022 {{Holiday Meltdown}} {\textbar} {{US Department}} of {{Transportation}}},
  urldate = {2024-01-03}
}

@article{doucetTutorialParticleFiltering2008,
  title = {A {{Tutorial}} on {{Particle Filtering}} and {{Smoothing}}: {{Fifteen}} Years Later},
  author = {Doucet, A. and Johansen, A. M.},
  year = {2008},
  journal = {undefined},
  urldate = {2022-10-16},
  file = {/home/cbd/Zotero/storage/URK3SSZ3/doucet-johansen.pdf}
}

@misc{drake,
  title = {Drake: {{Model-based}} Design and Verification for Robotics},
  author = {Tedrake, Russ and Team, the Drake Development},
  year = {2019}
}

@article{dritsasBuildingRoboticsDesign2018,
  title = {Building Robotics Design for Construction},
  author = {Dritsas, Stylianos and Gim, {$\cdot$} and Soh, Song},
  year = {2018},
  month = aug,
  journal = {Construction Robotics 2018 3:1},
  volume = {3},
  number = {1},
  pages = {1--10},
  publisher = {{Springer}},
  issn = {2509-8780},
  doi = {10.1007/S41693-018-0010-1},
  urldate = {2022-02-02},
  abstract = {We present the design process parameters and considerations relevant to developing robotic systems for building construction. Three strategies for integrating industrial robotics are identified: (a) prefabrication systems for off-site operations; (b) mobile platforms for on-site operations; and (c) embedded designs for adaptive integration onsite. In this paper, we focus on the design of our mobile systems. We highlight the challenges pertaining the design of those systems and offer recommendations that may support improved future designs and wider adoption of robotics in the architecture, engineering, and the construction industry. Overall, if we are to address applications in the building construction, we need first to overcome current limitations of industrial-oriented robotic systems. This implies higher flexibility and rapid adaptation to varied tasks performed potentially under volatile environmental conditions. Our work aims to create building blocks and case studies, including hardware and software components, towards a new way of end-production which will sooner than later transform the way we think and produce architectural design.},
  isbn = {0123456789},
  keywords = {Civil Engineering,construction,Engineering Design,Robotics and Automation},
  file = {/home/cbd/Zotero/storage/CJJA569X/full-text.pdf}
}

@article{du2016computational,
  title = {Computational Multicopter Design},
  author = {Du, Tao and Schulz, Adriana and Zhu, Bo and Bickel, Bernd and Matusik, Wojciech},
  year = {2016},
  journal = {ACM Transactions on Graphics (TOG)},
  volume = {35},
  number = {6},
  pages = {227},
  publisher = {{ACM}}
}

@article{du2021underwater,
  title = {Underwater Soft Robot Modeling and Control with Differentiable Simulation},
  author = {Du, Tao and Hughes, Josie and Wah, Sebastien and Matusik, Wojciech and Rus, Daniela},
  year = {2021},
  journal = {IEEE Robotics and Automation Letters},
  publisher = {{IEEE}}
}

@article{dunlapComparingRunTime2022,
  title = {Comparing {{Run Time Assurance Approaches}} for {{Safe Spacecraft Docking}}},
  author = {Dunlap, Kyle and Hibbard, Michael and Mote, Mark and Hobbs, Kerianne},
  year = {2022},
  journal = {IEEE Control Systems Letters},
  volume = {6},
  pages = {1849--1854},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {24751456},
  doi = {10.1109/LCSYS.2021.3135260},
  urldate = {2022-02-14},
  abstract = {Run Time Assurance (RTA) systems are online safety verification techniques that filter the output of a primary controller to assure safety. RTA approaches are used in safety-critical control to intervene when a performance-driven primary controller would cause the system to violate safety constraints. This letter presents four categories of RTA approaches based on their membership to explicit or implicit monitoring and switching or optimization interventions. To validate the feasibility of each approach and compare computation time, four RTAs are defined for a three-dimensional spacecraft docking example with safety constraints on velocity.},
  keywords = {Aerospace,constrained control,optimization,rta},
  file = {/home/cbd/Zotero/storage/BTP7VMD5/full-text.pdf}
}

@incollection{durkanNeuralSplineFlows2019,
  title = {Neural Spline Flows},
  booktitle = {Proceedings of the 33rd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
  year = {2019},
  month = dec,
  number = {675},
  pages = {7511--7522},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  urldate = {2024-01-12},
  abstract = {A normalizing flow models a complex probability density as an invertible transformation of a simple base density. Flows based on either coupling or autoregressive transforms both offer exact density evaluation and sampling, but rely on the parameterization of an easily invertible elementwise transformation, whose choice determines the flexibility of these models. Building upon recent work, we propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the flexibility of both coupling and autoregressive transforms while retaining analytic invertibility. We demonstrate that neural spline flows improve density estimation, variational inference, and generative modeling of images.},
  file = {/home/cbd/Zotero/storage/EEA7LLWJ/Durkan et al. - 2019 - Neural spline flows.pdf}
}

@article{durmusSamplingStronglyLogconcave2016,
  title = {Sampling from a Strongly Log-Concave Distribution with the {{Unadjusted Langevin Algorithm}}},
  author = {Durmus, Alain and Moulines, {\'E}},
  year = {2016},
  month = apr,
  journal = {arXiv: Statistics Theory},
  urldate = {2023-05-06},
  abstract = {We consider in this paper the problem of sampling a probability distribution {$\pi$} having a density w.r.t. the Lebesgue measure on \${\textbackslash}mathbb\{R\}\^{}d\$, known up to a normalisation factor \$x {\textbackslash}mapsto {\textbackslash}mathrm\{e\}\^{}\{-U (x)\} / {\textbackslash}int\_\{{\textbackslash}mathbb\{R\}\^{}d\} {\textbackslash}mathrm\{e\}\^{}\{-U (y)\}{\textbackslash}mathrm\{d\}y\$. Under the assumption that \$U\$ is continuously differentiable, \${\textbackslash}nabla U\$ is globally Lipshitz and \$U\$ is strongly convex, we obtain non-asymptotic bounds for the convergence to stationarity in Wasserstein distances of the sampling method based on the Euler discretization of the Langevin stochastic differential equation for both constant and decreasing step sizes. The dependence on the dimension of the state space of the obtained bounds is studied to demonstrate the applicability of this method in the high dimensional setting. The convergence of an appropriately weighted empirical measure is also investigated and bounds for the mean square error and exponential deviation inequality for Lipschitz functions are reported. Some numerical results are presented to illustrate our findings.}
}

@article{erikssonScalingGaussianProcess2018,
  title = {Scaling {{Gaussian Process Regression}} with {{Derivatives}}},
  author = {Eriksson, David and Lee, Eric Hans and Dong, Kun and Bindel, David and Wilson, Andrew Gordon},
  year = {2018},
  month = oct,
  journal = {Advances in Neural Information Processing Systems},
  volume = {2018-December},
  eprint = {1810.12283},
  pages = {6867--6877},
  publisher = {{Neural information processing systems foundation}},
  issn = {10495258},
  doi = {10.48550/arxiv.1810.12283},
  urldate = {2022-10-18},
  abstract = {Gaussian processes (GPs) with derivatives are useful in many applications, including Bayesian optimization, implicit surface reconstruction, and terrain reconstruction. Fitting a GP to function values and derivatives at \$n\$ points in \$d\$ dimensions requires linear solves and log determinants with an \$\{n(d+1) {\textbackslash}times n(d+1)\}\$ positive definite matrix -- leading to prohibitive \${\textbackslash}mathcal\{O\}(n\^{}3d\^{}3)\$ computations for standard direct methods. We propose iterative solvers using fast \${\textbackslash}mathcal\{O\}(nd)\$ matrix-vector multiplications (MVMs), together with pivoted Cholesky preconditioning that cuts the iterations to convergence by several orders of magnitude, allowing for fast kernel learning and prediction. Our approaches, together with dimensionality reduction, enables Bayesian optimization with derivatives to scale to high-dimensional problems and large evaluation budgets.},
  archiveprefix = {arxiv},
  file = {/home/cbd/Zotero/storage/N4CGJ9AD/full-text.pdf}
}

@inproceedings{eykholtPhysicalAdversarialExamples2018,
  title = {Physical Adversarial Examples for Object Detectors},
  booktitle = {Proceedings of the 12th {{USENIX Conference}} on {{Offensive Technologies}}},
  author = {Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Tram{\`e}r, Florian and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
  year = {2018},
  month = aug,
  series = {{{WOOT}}'18},
  pages = {1},
  publisher = {{USENIX Association}},
  address = {{USA}},
  urldate = {2023-03-17},
  abstract = {Deep neural networks (DNNs) are vulnerable to adversarial examples--maliciously crafted inputs that cause DNNs to make incorrect predictions. Recent work has shown that these attacks generalize to the physical domain, to create perturbations on physical objects that fool image classifiers under a variety of real-world conditions. Such attacks pose a risk to deep learning models used in safety-critical cyber-physical systems. In this work, we extend physical attacks to more challenging object detection models, a broader class of deep learning algorithms widely used to detect and label multiple objects within a scene. Improving upon a previous physical attack on image classifiers, we create perturbed physical objects that are either ignored or mislabeled by object detection models. We implement a Disappearance Attack, in which we cause a Stop sign to "disappear" according to the detector--either by covering the sign with an adversarial Stop sign poster, or by adding adversarial stickers onto the sign. In a video recorded in a controlled lab environment, the state-of-the-art YOLO v2 detector failed to recognize these adversarial Stop signs in over 85\% of the video frames. In an outdoor experiment, YOLO was fooled by the poster and sticker attacks in 72.5\% and 63.5\% of the video frames respectively. We also use Faster R-CNN, a different object detection model, to demonstrate the transferability of our adversarial perturbations. The created poster perturbation is able to fool Faster R-CNN in 85.9\% of the video frames in a controlled lab environment, and 40.2\% of the video frames in an outdoor environment. Finally, we present preliminary results with a new Creation Attack, wherein innocuous physical stickers fool a model into detecting nonexistent objects.},
  keywords = {00-read}
}

@article{facchineiGeneralizedNashEquilibrium2007,
  title = {Generalized {{Nash}} Equilibrium Problems},
  author = {Facchinei, Francisco and Kanzow, Christian},
  year = {2007},
  month = sep,
  journal = {4OR 2007 5:3},
  volume = {5},
  number = {3},
  pages = {173--210},
  publisher = {{Springer}},
  issn = {1614-2411},
  doi = {10.1007/S10288-007-0054-4},
  urldate = {2022-02-27},
  abstract = {The Generalized Nash equilibrium problem is an important model that has its roots in the economic sciences but is being fruitfully used in many different fields. In this survey paper we aim at discussing its main properties and solution algorithms, pointing out what could be useful topics for future research in the field.},
  keywords = {Industrial and Production Engineering,Nikaido-Isoda-function,Operations Research/Decision Theory,Optimization,Quasi-variational inequality,to_read,Variational inequality},
  file = {/home/cbd/Zotero/storage/2ME4F9S3/full-text.pdf}
}

@inproceedings{fan_c2e2,
  title = {Automatic Reachability Analysis for Nonlinear Hybrid Models with {{C2E2}}},
  booktitle = {Computer Aided Verification},
  author = {Fan, Chuchu and Qi, Bolun and Mitra, Sayan and Viswanathan, Mahesh and Duggirala, Parasara Sridhar},
  editor = {Chaudhuri, Swarat and Farzan, Azadeh},
  year = {2016},
  pages = {531--538},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  isbn = {978-3-319-41528-4}
}

@inproceedings{fan_dryvr,
  title = {{{DryVR}}: {{Data-driven}} Verification and Compositional Reasoning for Automotive Systems},
  booktitle = {Computer Aided Verification},
  author = {Fan, Chuchu and Qi, Bolun and Mitra, Sayan and Viswanathan, Mahesh},
  editor = {Majumdar, Rupak and Kun{\v c}ak, Viktor},
  year = {2017},
  pages = {441--461},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {We present the DryVR framework for verifying hybrid control systems that are described by a combination of a black-box simulator for trajectories and a white-box transition graph specifying mode switches. The framework includes (a) a probabilistic algorithm for learning sensitivity of the continuous trajectories from simulation data, (b) a bounded reachability analysis algorithm that uses the learned sensitivity, and (c) reasoning techniques based on simulation relations and sequential composition, that enable verification of complex systems under long switching sequences, from the reachability analysis of a simpler system under shorter sequences. We demonstrate the utility of the framework by verifying a suite of automotive benchmarks that include powertrain control, automatic transmission, and several autonomous and ADAS features like automatic emergency braking, lane-merge, and auto-passing controllers.},
  isbn = {978-3-319-63387-9}
}

@inproceedings{fazlyab2019efficient,
  title = {Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems ({{NeurIPS}})},
  author = {Fazlyab, Mahyar and Robey, Alexander and Hassani, Hamed and Morari, Manfred and Pappas, George J},
  year = {2019}
}

@inproceedings{finlayHowTrainYour2020,
  title = {How to Train Your Neural {{ODE}}: {{The}} World of {{Jacobian}} and {{Kinetic}} Regularization},
  shorttitle = {How to Train Your Neural {{ODE}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Finlay, Chris and Jacobsen, J{\"o}rn-Henrik and Nurbekyan, Levon and Oberman, Adam M},
  year = {2020},
  month = jul,
  series = {{{ICML}}'20},
  volume = {119},
  pages = {3154--3164},
  publisher = {{JMLR.org}},
  urldate = {2024-01-25},
  abstract = {Training neural ODEs on large datasets has not been tractable due to the necessity of allowing the adaptive numerical ODE solver to refine its step size to very small values. In practice this leads to dynamics equivalent to many hundreds or even thousands of layers. In this paper, we overcome this apparent difficulty by introducing a theoretically-grounded combination of both optimal transport and stability regularizations which encourage neural ODEs to prefer simpler dynamics out of all the dynamics that solve a problem well. Simpler dynamics lead to faster convergence and to fewer discretizations of the solver, considerably decreasing wall-clock time without loss in performance. Our approach allows us to train neural ODE-based generative models to the same performance as the unregularized dynamics, with significant reductions in training time. This brings neural ODEs closer to practical relevance in large-scale applications.},
  file = {/home/cbd/Zotero/storage/BHXAB3AY/Finlay et al. - 2020 - How to train your neural ODE the world of Jacobia.pdf}
}

@article{fischlerRandomSampleConsensus1981,
  title = {Random Sample Consensus: {{A}} Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  shorttitle = {Random Sample Consensus},
  author = {Fischler, Martin A. and Bolles, Robert C.},
  year = {1981},
  month = jun,
  journal = {Communications of the ACM},
  volume = {24},
  number = {6},
  pages = {381--395},
  issn = {0001-0782},
  doi = {10.1145/358669.358692},
  urldate = {2024-01-30},
  abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
  keywords = {automated cartography,camera calibration,image matching,location determination,model fitting,scene analysis},
  file = {/home/cbd/Zotero/storage/KPXASYXG/Fischler and Bolles - 1981 - Random sample consensus a paradigm for model fitt.pdf}
}

@article{garrettIntegratedTaskMotion2021,
  title = {Integrated {{Task}} and {{Motion Planning}}},
  author = {Garrett, Caelan Reed and Chitnis, Rohan and Holladay, Rachel and Kim, Beomjoon and Silver, Tom and Kaelbling, Leslie Pack and {Lozano-P{\'e}rez}, Tom{\'a}s},
  year = {2021},
  month = may,
  journal = {https://doi.org/10.1146/annurev-control-091420-084139},
  volume = {4},
  number = {1},
  eprint = {2010.01083},
  pages = {265--293},
  publisher = {{Annual Reviews}},
  issn = {2573-5144},
  doi = {10.1146/ANNUREV-CONTROL-091420-084139},
  urldate = {2022-02-07},
  abstract = {The problem of planning for a robot that operates in environments containing a large number of objects, taking actions to move itself through the world as well as to change the state of the objects...},
  archiveprefix = {arxiv},
  keywords = {automated planning,manipulation planning,motion planning,robotics,survey,tamp,task and motion planning},
  file = {/home/cbd/Zotero/storage/LIZRQ47F/full-text.pdf}
}

@inproceedings{gehrAI2SafetyRobustness2018,
  title = {{{AI2}}: {{Safety}} and {{Robustness Certification}} of {{Neural Networks}} with {{Abstract Interpretation}}},
  shorttitle = {{{AI2}}},
  booktitle = {2018 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  author = {Gehr, Timon and Mirman, Matthew and {Drachsler-Cohen}, Dana and Tsankov, Petar and Chaudhuri, Swarat and Vechev, Martin},
  year = {2018},
  month = may,
  pages = {3--18},
  issn = {2375-1207},
  doi = {10.1109/SP.2018.00058},
  abstract = {We present AI2, the first sound and scalable analyzer for deep neural networks. Based on overapproximation, AI2 can automatically prove safety properties (e.g., robustness) of realistic neural networks (e.g., convolutional neural networks). The key insight behind AI2 is to phrase reasoning about safety and robustness of neural networks in terms of classic abstract interpretation, enabling us to leverage decades of advances in that area. Concretely, we introduce abstract transformers that capture the behavior of fully connected and convolutional neural network layers with rectified linear unit activations (ReLU), as well as max pooling layers. This allows us to handle real-world neural networks, which are often built out of those types of layers. We present a complete implementation of AI2 together with an extensive evaluation on 20 neural networks. Our results demonstrate that: (i) AI2 is precise enough to prove useful specifications (e.g., robustness), (ii) AI2 can be used to certify the effectiveness of state-of-the-art defenses for neural networks, (iii) AI2 is significantly faster than existing analyzers based on symbolic analysis, which often take hours to verify simple fully connected networks, and (iv) AI2 can handle deep convolutional networks, which are beyond the reach of existing methods.},
  keywords = {Abstract Interpretation,Biological neural networks,Cats,Neural Networks,Neurons,Perturbation methods,Reliable Machine Learning,Robustness,Safety},
  file = {/home/cbd/Zotero/storage/RCC5PYIK/Gehr et al. - 2018 - AI2 Safety and Robustness Certification of Neural.pdf}
}

@book{geyerIntroductionMarkovChain2011,
  title = {Introduction to {{Markov Chain Monte Carlo}}},
  author = {Geyer, Charles},
  year = {2011},
  month = may,
  pages = {29--74},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b10905-6},
  urldate = {2022-12-16},
  abstract = {Despite a few notable uses of simulation of random processes in the pre-computer era (Hammersley and Handscomb, 1964, Section 1.2; Stigler, 2002, Chapter 7), practical widespread use of simulation had to await the invention of computers. Almost as soon as computers were invented, they were used for simulation (Hammersley and Handscomb, 1964, Section 1.2). The name ``Monte Carlo'' started as cuteness-gambling was then (around 1950) illegal in most places, and the casino at Monte Carlo was the most famous in the world-but it soon became a colorless technical term for simulation of random processes. Markov chain Monte Carlo (MCMC) was invented soon after ordinary Monte Carlo atLos Alamos, one of the few places where computers were available at the time. Metropolis et al. (1953){$\ast$} simulated a liquid in equilibrium with its gas phase. The obvious way to find out about the thermodynamic equilibrium is to simulate the dynamics of the system, and let it run until it reaches equilibrium. The tour de force was their realization that they did not need to simulate the exact dynamics; they only needed to simulate someMarkov chain having the same equilibrium distribution. Simulations following the scheme of Metropolis et al. (1953) are said to use the Metropolis algorithm. As computers became more widely available, the Metropolis algorithm was widely used by chemists and physicists, but it did not become widely known among statisticians until after 1990. Hastings (1970) generalized the Metropolis algorithm, and simulations following his scheme are said to use the Metropolis-Hastings algorithm. A special case of the Metropolis-Hastings algorithm was introduced by Geman and Geman (1984), apparently without knowledge of earlier work. Simulations following their scheme are said to use the Gibbs sampler. Much of Geman and Geman (1984) discusses optimization to find the posterior mode rather than simulation, and it took some time for it to be understood in the spatial statistics community that the Gibbs sampler simulated the posterior distribution, thus enabling full Bayesian inference of all kinds. Amethodology that was later seen to be very similar to the Gibbs sampler was introduced by Tanner and Wong (1987), again apparently without knowledge of earlier work. To this day, some refer to the Gibbs sampler as ``data augmentation'' following these authors. Gelfand and Smith (1990)made thewider Bayesian community aware of theGibbs sampler, which up to that time had been known only in the spatial statistics community. Then it took off; as of this writing, a search for Gelfand and Smith (1990) on Google Scholar yields 4003 links to other works. It was rapidly realized that most Bayesian inference couldresearchers to properly understand the theory of MCMC (Geyer, 1992; Tierney, 1994) and that all of the aforementionedworkwas a special case of the notion ofMCMC. Green (1995) generalized theMetropolis-Hastings algorithm, asmuch as it can be generalized.Although this terminology is not widely used, we say that simulations following his scheme use the Metropolis-Hastings-Green algorithm. MCMC is not used only for Bayesian inference. Likelihood inference in caseswhere the likelihood cannot be calculated explicitly due tomissing data or complex dependence can also useMCMC (Geyer, 1994, 1999; Geyer and Thompson, 1992, 1995, and references cited therein).},
  isbn = {978-0-429-13850-8},
  langid = {english},
  file = {/home/cbd/Zotero/storage/VBKJH7IQ/2011 - Introduction to Markov Chain Monte Carlo.pdf}
}

@inproceedings{ghaiGeneratingAdversarialDisturbances2021,
  title = {Generating {{Adversarial Disturbances}} for {{Controller Verification}}},
  booktitle = {Proceedings of the 3rd {{Conference}} on {{Learning}} for {{Dynamics}} and {{Control}}},
  author = {Ghai, Udaya and Snyder, David and Majumdar, Anirudha and Hazan, Elad},
  year = {2021},
  month = may,
  pages = {1192--1204},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-03-19},
  abstract = {We consider the problem of generating maximally adversarial disturbances for a given controller assuming only blackbox access to it. We propose an online learning approach to this problem that adaptively generates disturbances based on control inputs chosen by the controller. The goal of the disturbance generator is to minimize regret versus a benchmark disturbance-generating policy class, i.e., to maximize the cost incurred by the controller as well as possible compared to the best possible disturbance generator in hindsight (chosen from a benchmark policy class). In the setting where the dynamics are linear and the costs are quadratic, we formulate our problem as an online trust region (OTR) problem with memory and present a new online learning algorithm (MOTR) for this problem. We prove that this method competes with the best disturbance generator in hindsight (chosen from a rich class of benchmark policies that includes linear-dynamical disturbance generating policies). We demonstrate our approach on two simulated examples: (i) synthetically generated linear systems, and (ii) generating wind disturbances for the popular PX4 controller in the AirSim simulator. On these examples, we demonstrate that our approach outperforms several baseline approaches (including H-infinity disturbance generation and gradient-based methods).},
  langid = {english},
  keywords = {00-read,00-relevant,online}
}

@misc{goodfellowExplainingHarnessingAdversarial2015,
  title = {Explaining and {{Harnessing Adversarial Examples}}},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  year = {2015},
  month = mar,
  number = {arXiv:1412.6572},
  eprint = {1412.6572},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1412.6572},
  urldate = {2023-03-17},
  abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
  archiveprefix = {arxiv},
  keywords = {00-read,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{gouveiaBayesianSeismicWaveform1998,
  title = {Bayesian Seismic Waveform Inversion: {{Parameter}} Estimation and Uncertainty Analysis},
  shorttitle = {Bayesian Seismic Waveform Inversion},
  author = {Gouveia, Wences P. and Scales, John A.},
  year = {1998},
  journal = {Journal of Geophysical Research: Solid Earth},
  volume = {103},
  number = {B2},
  pages = {2759--2779},
  issn = {2156-2202},
  doi = {10.1029/97JB02933},
  urldate = {2024-01-19},
  abstract = {The goal of geophysical inversion is to make quantitative inferences about the Earth from remote observations. Because the observations are finite in number and subject to uncertainty, these inferences are inherently probabilistic. A key step is to define what it means for an Earth model to fit the data. This requires estimation of the uncertainties in the data, both those due to random noise and those due to theoretical errors. But the set of models that fit the data usually contains unrealistic models; i.e., models that violate our a priori prejudices, other data, or theoretical considerations. One strategy for eliminating such unreasonable models is to define an a priori probability density on the space of models, then use Bayes theorem to combine this probability with the data misfit function into a final a posteriori probability density reflecting both data fit and model reasonableness. We show here a case study of the application of the Bayesian strategy to inversion of surface seismic field data. Assuming that all uncertainties can be described by multidimensional Gaussian probability densities, we incorporate into the calculation information about ambient noise, discretization errors, theoretical errors, and a priori information about the set of layered Earth models derived from in situ petrophysical measurements. The result is a probability density on the space of models that takes into account all of this information. Inferences on model parameters can be derived by integration of this function. We begin by estimating the parameters of the Gaussian probability densities assumed to describe the data and model uncertainties. These are combined via Bayes theorem. The a posteriori probability is then optimized via a nonlinear conjugate gradient procedure to find the maximum a posteriori model. Uncertainty analysis is performed by making a Gaussian approximation of the a posteriori distribution about this peak model. We present the results of this analysis in three different forms: the maximum a posteriori model bracketed by one standard deviation error bars, pseudo-random simulations of the a posteriori probability (showing the range of typical subsurface models), and marginals of this probability at selected depths in the subsurface. The models we compute are consistent both with the surface seismic data and the borehole measurements, even though the latter are well below the resolution of the former. We also contrast the Bayesian maximum a posteriori model with the Occam model, which is the smoothest model that fits the surface seismic data alone.},
  copyright = {Copyright 1998 by the American Geophysical Union.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/56REYYJZ/Gouveia and Scales - 1998 - Bayesian seismic waveform inversion Parameter est.pdf}
}

@inproceedings{grathwohlFFJORDFreeFormContinuous2018,
  title = {{{FFJORD}}: {{Free-Form Continuous Dynamics}} for {{Scalable Reversible Generative Models}}},
  shorttitle = {{{FFJORD}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Grathwohl, Will and Chen, Ricky T. Q. and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
  year = {2018},
  month = sep,
  urldate = {2024-01-21},
  abstract = {A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/RWFIDPQ3/Grathwohl et al. - 2018 - FFJORD Free-Form Continuous Dynamics for Scalable.pdf}
}

@article{grettonKernelTwoSampleTest2012,
  title = {A {{Kernel Two-Sample Test}}},
  author = {Gretton, Arthur and Borgwardt, Karsten M. and Rasch, Malte J. and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  year = {2012},
  journal = {Journal of Machine Learning Research},
  volume = {13},
  number = {25},
  pages = {723--773},
  issn = {1533-7928},
  urldate = {2024-01-24},
  abstract = {We propose a framework for analyzing and comparing distributions, which we use to construct statistical tests to determine if two samples are drawn from different distributions. Our test statistic is the largest difference in expectations over functions in the unit ball of a reproducing kernel Hilbert space (RKHS), and is called the maximum mean discrepancy (MMD). We present two distribution-free tests based on large deviation bounds for the MMD, and a third test based on the asymptotic distribution of this statistic. The MMD can be computed in quadratic time, although efficient linear time approximations are available. Our statistic is an instance of an integral probability metric, and various classical metrics on distributions are obtained when alternative function classes are used in place of an RKHS. We apply our two-sample tests to a variety of problems, including attribute matching for databases using the Hungarian marriage method, where they perform strongly. Excellent performance is also obtained when comparing distributions over graphs, for which these are the first such tests.},
  file = {/home/cbd/Zotero/storage/6UZ4P5ZU/Gretton et al. - 2012 - A Kernel Two-Sample Test.pdf}
}

@article{guConvergenceMonteCarlo,
  title = {On the {{Convergence}} of {{Monte Carlo Methods}} with {{Stochastic Gradients}}},
  author = {Gu, Quanquan},
  langid = {english},
  file = {/home/cbd/Zotero/storage/BF6ZR7ST/Gu - On the Convergence of Monte Carlo Methods with Sto.pdf}
}

@misc{hanna2014_stochastic_optimization_notes,
  title = {Computational Statistics Lecture Notes on Stochastic Optimization},
  author = {Hanna, Lauren},
  year = {2014},
  month = apr,
  publisher = {{Columbia University}}
}

@inproceedings{hanselmannKINGGeneratingSafetyCritical2022a,
  title = {{{KING}}: {{Generating Safety-Critical Driving Scenarios}} for {{Robust Imitation}} via {{Kinematics Gradients}}},
  shorttitle = {{{KING}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2022: 17th {{European Conference}}, {{Tel Aviv}}, {{Israel}}, {{October}} 23--27, 2022, {{Proceedings}}, {{Part XXXVIII}}},
  author = {Hanselmann, Niklas and Renz, Katrin and Chitta, Kashyap and Bhattacharyya, Apratim and Geiger, Andreas},
  year = {2022},
  month = oct,
  pages = {335--352},
  publisher = {{Springer-Verlag}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-031-19839-7_20},
  urldate = {2023-09-15},
  abstract = {Simulators offer the possibility of safe, low-cost development of self-driving systems. However, current driving simulators exhibit na\"{\i}ve behavior models for background traffic. Hand-tuned scenarios are typically added during simulation to induce safety-critical situations. An alternative approach is to adversarially perturb the background traffic trajectories. In this paper, we study this approach to safety-critical driving scenario generation using the CARLA simulator. We use a kinematic bicycle model as a proxy to the simulator's true dynamics and observe that gradients through this proxy model are sufficient for optimizing the background traffic trajectories. Based on this finding, we propose KING, which generates safety-critical driving scenarios with a 20\% higher success rate than black-box optimization. By solving the scenarios generated by KING using a privileged rule-based expert algorithm, we obtain training data for an imitation learning policy. After fine-tuning on this new data, we show that the policy becomes better at avoiding collisions. Importantly, our generated data leads to reduced collisions on both held-out scenarios generated via KING as well as traditional hand-crafted scenarios, demonstrating improved robustness.},
  isbn = {978-3-031-19838-0},
  file = {/home/cbd/Zotero/storage/QYCPFP4W/Hanselmann et al. - 2022 - KING Generating Safety-Critical Driving Scenarios.pdf}
}

@article{hastingsMonteCarloSampling1970,
  title = {Monte {{Carlo}} Sampling Methods Using {{Markov}} Chains and Their Applications},
  author = {Hastings, W. K.},
  year = {1970},
  month = apr,
  journal = {Biometrika},
  volume = {57},
  number = {1},
  pages = {97--109},
  issn = {0006-3444},
  doi = {10.1093/biomet/57.1.97},
  urldate = {2023-09-22},
  abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
  file = {/home/cbd/Zotero/storage/4VZ3LPNW/284580.html}
}

@inproceedings{hazanGraduatedOptimizationStochastic2016,
  title = {On {{Graduated Optimization}} for {{Stochastic Non-Convex Problems}}},
  booktitle = {Proceedings of {{The}} 33rd {{International Conference}} on {{Machine Learning}}},
  author = {Hazan, Elad and Levy, Kfir Yehuda and {Shalev-Shwartz}, Shai},
  year = {2016},
  month = jun,
  pages = {1833--1841},
  publisher = {{PMLR}},
  issn = {1938-7228},
  urldate = {2024-01-03},
  abstract = {The graduated optimization approach, also known as the continuation method, is a popular heuristic to solving non-convex problems that has received renewed interest over the last decade.Despite being popular, very little is known in terms of its theoretical convergence analysis. In this paper we describe a new first-order algorithm based on graduated optimization and analyze its performance. We characterize a family of non-convex functions for which this algorithm provably converges to a global optimum. In particular, we prove that the algorithm converges to an {$\varepsilon$}-approximate solution within O(1 / {$\varepsilon$}\^{}2) gradient-based steps. We extend our algorithm and analysis to the setting of stochastic non-convex optimization with noisy gradient feedback, attaining the same convergence rate. Additionally, we discuss the setting of ``zero-order optimization", and devise a variant of our algorithm which converges at rate of O(d\^{}2/ {$\varepsilon$}\^{}4).},
  langid = {english},
  file = {/home/cbd/Zotero/storage/KH8ATV2R/Hazan et al. - 2016 - On Graduated Optimization for Stochastic Non-Conve.pdf}
}

@inproceedings{heiden2021neuralsim,
  title = {{{NeuralSim}}: {{Augmenting}} Differentiable Simulators with Neural Networks},
  booktitle = {Proceedings of the {{IEEE}} International Conference on Robotics and Automation ({{ICRA}})},
  author = {Heiden, Eric and Millard, David and Coumans, Erwin and Sheng, Yizhou and Sukhatme, Gaurav S},
  year = {2021}
}

@article{heidenProbabilisticInferenceSimulation2021,
  title = {Probabilistic {{Inference}} of {{Simulation Parameters}} via {{Parallel Differentiable Simulation}}},
  author = {Heiden, Eric and Denniston, Christopher E. and Millard, David and Ramos, Fabio and Sukhatme, Gaurav S.},
  year = {2021},
  month = sep,
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  eprint = {2109.08815},
  pages = {3638--3645},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {10504729},
  doi = {10.48550/arxiv.2109.08815},
  urldate = {2022-09-26},
  abstract = {To accurately reproduce measurements from the real world, simulators need to have an adequate model of the physical system and require the parameters of the model be identified. We address the latter problem of estimating parameters through a Bayesian inference approach that approximates a posterior distribution over simulation parameters given real sensor measurements. By extending the commonly used Gaussian likelihood model for trajectories via the multiple-shooting formulation, our chosen particle-based inference algorithm Stein Variational Gradient Descent is able to identify highly nonlinear, underactuated systems. We leverage GPU code generation and differentiable simulation to evaluate the likelihood and its gradient for many particles in parallel. Our algorithm infers non-parametric distributions over simulation parameters more accurately than comparable baselines and handles constraints over parameters efficiently through gradient-based optimization. We evaluate estimation performance on several physical experiments. On an underactuated mechanism where a 7-DOF robot arm excites an object with an unknown mass configuration, we demonstrate how our inference technique can identify symmetries between the parameters and provide highly accurate predictions. Project website: https://uscresl.github.io/prob-diff-sim},
  archiveprefix = {arxiv},
  isbn = {9781728196817},
  file = {/home/cbd/Zotero/storage/BRFGVLIA/full-text.pdf}
}

@inproceedings{heidlaufVerificationChallengesF162018,
  title = {Verification {{Challenges}} in {{F-16 Ground Collision Avoidance}} and {{Other Automated Maneuvers}}},
  booktitle = {{{EPiC Series}} in {{Computing}}},
  author = {Heidlauf, Peter and Collins, Alexander and Bolender, Michael and Bak, Stanley},
  year = {2018},
  month = sep,
  volume = {54},
  pages = {208--217},
  publisher = {{EasyChair}},
  issn = {2398-7340},
  doi = {10.29007/91x9},
  urldate = {2023-08-09},
  langid = {american},
  file = {/home/cbd/Zotero/storage/EFCWDKYZ/Heidlauf et al. - 2018 - Verification Challenges in F-16 Ground Collision A.pdf}
}

@inproceedings{heMaskRCNN2017,
  title = {Mask {{R-CNN}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  year = {2017},
  month = oct,
  pages = {2980--2988},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2017.322},
  urldate = {2023-09-28},
  abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.},
  file = {/home/cbd/Zotero/storage/DNWPKP3Q/He et al. - 2017 - Mask R-CNN.pdf;/home/cbd/Zotero/storage/ALHY7UCF/8237584.html}
}

@inproceedings{hendrycksDeepAnomalyDetection2018,
  title = {Deep {{Anomaly Detection}} with {{Outlier Exposure}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  year = {2018},
  month = sep,
  urldate = {2024-01-30},
  abstract = {It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/EPKSIV54/Hendrycks et al. - 2018 - Deep Anomaly Detection with Outlier Exposure.pdf}
}

@inproceedings{higginsBetaVAELearningBasic2016,
  title = {Beta-{{VAE}}: {{Learning Basic Visual Concepts}} with a {{Constrained Variational Framework}}},
  shorttitle = {Beta-{{VAE}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  year = {2016},
  month = nov,
  urldate = {2024-01-08},
  abstract = {Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artificial intelligence that is able to learn and reason in the same way that humans do. We introduce beta-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modification of the variational autoencoder (VAE) framework. We introduce an adjustable hyperparameter beta that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that beta-VAE with appropriately tuned beta {$>$} 1 qualitatively outperforms VAE (beta = 1), as well as state of the art unsupervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also significantly outperforms all baselines quantitatively. Unlike InfoGAN, beta-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter, which can be directly optimised through a hyper parameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/YEXWYU6S/Higgins et al. - 2016 - beta-VAE Learning Basic Visual Concepts with a Co.pdf}
}

@misc{hoDenoisingDiffusionProbabilistic2020,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  year = {2020},
  month = dec,
  number = {arXiv:2006.11239},
  eprint = {2006.11239},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.11239},
  urldate = {2023-03-21},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{hoeffding,
  title = {Probability Inequalities for Sums of Bounded Random Variables},
  author = {{Wassily Hoeffding}},
  year = {1963},
  journal = {Journal of the American Statistical Association},
  volume = {58},
  number = {301},
  eprint = {https://www.tandfonline.com/doi/pdf/10.1080/01621459.1963.10500830},
  pages = {13--30},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/01621459.1963.10500830}
}

@article{hongNKConstrainedComposite2017,
  title = {N-{{K Constrained Composite Generation}} and {{Transmission Expansion Planning With Interval Load}}},
  author = {Hong, Shaoyun and Cheng, Haozhong and Zeng, Pingliang},
  year = {2017},
  journal = {IEEE access : practical innovations, open solutions},
  volume = {5},
  pages = {2779--2789},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2017.2664804},
  abstract = {The uncertainties of the predicted load demand and N-K contingencies are very significant aspects to composite generation and transmission expansion planning (CGTEP). In this paper, multi-contingency constrained CGTEP with load uncertainty was analyzed from stringent mathematical view and formulated as a tri-level optimization model. To effectively solve the tri-level optimization, the entire problem is formulated as two problems using Benders' decomposition: master problem with expansion planning and the sub-problem with the worst case load shedding. The sub-problem is a bi-level optimization problem which can be solved mathematically using strong duality theory and linearization method. CGTEP with the tri-level optimization can endure the disturbances of interval load and N-K contingencies. A benchmark test system is simulated to validate the effectiveness of the proposed approach. Furthermore, for Bender's decomposition with many sub-problems of worst load shedding, the numerically comparable results of a special case demonstrate that all sub-problems of composite contingencies must be validated at each iteration even if certain contingency meets the standard of load shedding at the previous iteration.},
  keywords = {Analytical models,Benders' decomposition,generation and transmission expansion planning,Generators,interval load,Load modeling,Mathematical model,minimum load shedding,N-K contingency,Optimization,Planning,transmission expansion planning,Uncertainty},
  file = {/home/cbd/Zotero/storage/SE63RDLI/Hong et al. - 2017 - N-K Constrained Composite Generation and Transmiss.pdf}
}

@article{howelllecleach2022,
  title = {Dojo: {{A}} Differentiable Simulator for Robotics},
  author = {Howell, Taylor and Le Cleac'h, Simon and Kolter, Zico and Schwager, Mac and Manchester, Zachary},
  year = {2022},
  journal = {arXiv preprint arXiv:2203.00806},
  eprint = {2203.00806},
  archiveprefix = {arxiv}
}

@inproceedings{huangNeuralAutoregressiveFlows2018,
  title = {Neural {{Autoregressive Flows}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},
  year = {2018},
  month = jul,
  pages = {2078--2087},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-21},
  abstract = {Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows (MAF) (Papamakarios et al., 2017), and to accelerate state-of-the-art WaveNet-based speech synthesis to 20x faster than real-time (Oord et al., 2017), via Inverse Autoregressive Flows (IAF) (Kingma et al., 2016). We unify and generalize these approaches, replacing the (conditionally) affine univariate transformations of MAF/IAF with a more general class of invertible univariate transformations expressed as monotonic neural networks. We demonstrate that the proposed neural autoregressive flows (NAF) are universal approximators for continuous probability distributions, and their greater expressivity allows them to better capture multimodal target distributions. Experimentally, NAF yields state-of-the-art performance on a suite of density estimation tasks and outperforms IAF in variational autoencoders trained on binarized MNIST.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/83MIRYJX/Huang et al. - 2018 - Neural Autoregressive Flows.pdf;/home/cbd/Zotero/storage/ZPIFWEY5/Huang et al. - 2018 - Neural Autoregressive Flows.pdf}
}

@article{huangNewAnalogProtocol2021,
  title = {The New Analog: {{A}} Protocol for Linking Design and Construction Intent with Algorithmic Planning for Robotic Assembly of Complex Structures},
  author = {Huang, Yijiang and Leung Pok Yin, Victor and Garrett, Caelan and Gramazio, Fabio and Kohler, Matthias and Mueller, Caitlin},
  year = {2021},
  month = oct,
  journal = {SCF '21: Symposium on Computational Fabrication},
  pages = {1--17},
  publisher = {{Association for Computing Machinery (ACM)}},
  doi = {10.1145/3485114.3485122},
  urldate = {2022-01-30},
  abstract = {Construction robotics are increasingly popular in the architectural fabrication community due to their accuracy and flexibility. Because of their high degree of motion freedom, these tools are able to assemble complex structures with irregular designs, which advances architectural aesthetics and structural performance. However, automated task and motion planning (TAMP) for a robot to assemble non-repetitive objects can be challenging due to (1) a non-repetitive assembly pattern (2) the need for a continuous robotic motion throughout a sequence of movement (3) a congested construction scene and (4) occasional robot configuration constraints due to taught positions. Recent work has already begun to address these challenges for repetitive assembly processes, where the robot repeats a pattern of primitive behaviors (e.g. brick stacking or spatial extrusion). Yet, there are many assembly processes that can benefit from a non-repetitive pattern. For example, processes can change tools on an element-by-element level to accommodate a wider range of geometry. Our work is motivated by the necessity of robotic modeling and planning for a recently published timber assembly process which utilizes distributed robotic clamps to press together interlocking joints. In addition to pick-And-place operations, the robot needs to move numerous tools within the construction scene, similar to a tool-change operation. In order to facilitate an agile process for architectural design, construction process design, and TAMP, we introduce a flowchart-based specification language which allows various designers to describe their design and construction intent and knowledge. A compiler can then translate the assembly description, sequence, process flowchart, and robotic setup into a plan skeleton. Additionally, we present a linear and a non-linear solving algorithm that can solve the plan skeleton for a full sequence of robot motions. This algorithm can be customized to take into account designer intuition, which can speed up the planning process. We provide a comparison of the two algorithms using the timber assembly process as our case study. We validate our results by robotically executing and constructing a large-scale real-world timber structure. Finally, we demonstrate the flexibility of our flowchart by showing how custom assembly actions are modeled in our case study. We also demonstrate how other recently published robotic assembly processes can be formulated using our flowcharts to demonstrate generalizability.},
  isbn = {9781450390903},
  keywords = {construction,Digital Fabrication,Distributed Robotic Tools,Robotic Assembly,Spatial Timber Structure,systems,tamp,Task and Motion Planning},
  file = {/home/cbd/Zotero/storage/LHM4XZAX/full-text.pdf}
}

@article{huangRoboticAdditiveConstruction2021,
  title = {Robotic Additive Construction of Bar Structures: {{Unified}} Sequence and Motion Planning},
  author = {Huang, Yijiang and Garrett, Caelan R. and Ting, Ian and Parascho, Stefana and Mueller, Caitlin T.},
  year = {2021},
  month = jun,
  journal = {Construction Robotics},
  volume = {5},
  number = {2},
  eprint = {2105.11438},
  pages = {115--130},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {2509-811X},
  doi = {10.1007/S41693-021-00062-Z/FIGURES/12},
  urldate = {2022-01-30},
  abstract = {Additive robotic construction of building-scale discrete bar structures, such as trusses and space frames, is increasingly attractive due to the potential improvements in efficiency, safety, and design possibilities. However, programming complex robots, such as manipulators with seven degrees of freedom, to successfully complete construction tasks can be tedious, challenging, or impossible for a human to do manually. Namely, the structure must be constructed in a sequence that preserves structural properties, such as stiffness, at each step. At the same time, this sequence must allow for the robot to precisely manipulate elements within the in-progress structure while respecting geometric constraints that, for example, ensure the robot does not collide with what it has built. In this work, we present an automated and newly generalized planning approach for jointly finding a construction sequence and robot motion plan for additive construction that satisfies these requirements. Our approach can be applied in a variety of additive construction processes, and we demonstrate it specifically on spatial extrusion and discrete bar assembly in this paper. We demonstrate the effectiveness of our approach on several simulated and real-world extrusion and assembly tasks, including a human-scale physical prototype, for which our algorithm is deployed for the first time to plan the assembly of a complicated double tangent bar system design.},
  archiveprefix = {arxiv},
  keywords = {Civil Engineering,construction,done,Engineering Design,Robotics and Automation,tamp},
  file = {/home/cbd/Zotero/storage/5XLT6JG2/full-text.pdf}
}

@inproceedings{huDiffTaichiDifferentiableProgramming2019,
  title = {{{DiffTaichi}}: {{Differentiable Programming}} for {{Physical Simulation}}},
  shorttitle = {{{DiffTaichi}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Hu, Yuanming and Anderson, Luke and Li, Tzu-Mao and Sun, Qi and Carr, Nathan and {Ragan-Kelley}, Jonathan and Durand, Fredo},
  year = {2019},
  month = dec,
  urldate = {2023-05-15},
  abstract = {We present DiffTaichi, a new differentiable programming language tailored for building high-performance differentiable physical simulators. Based on an imperative programming language, DiffTaichi generates gradients of simulation steps using source code transformations that preserve arithmetic intensity and parallelism. A light-weight tape is used to record the whole simulation program structure and replay the gradient kernels in a reversed order, for end-to-end backpropagation. We demonstrate the performance and productivity of our language in gradient-based learning and optimization tasks on 10 different physical simulators. For example, a differentiable elastic object simulator written in our language is 4.2x shorter than the hand-engineered CUDA version yet runs as fast, and is 188x faster than the TensorFlow implementation. Using our differentiable programs, neural network controllers are typically optimized within only tens of iterations.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/XC7867DA/Hu et al. - 2019 - DiffTaichi Differentiable Programming for Physica.pdf}
}

@inproceedings{hughesSemiSupervisedPredictionConstrainedTopic2018,
  title = {Semi-{{Supervised Prediction-Constrained Topic Models}}},
  booktitle = {Proceedings of the {{Twenty-First International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Hughes, Michael and Hope, Gabriel and Weiner, Leah and McCoy, Thomas and Perlis, Roy and Sudderth, Erik and {Doshi-Velez}, Finale},
  year = {2018},
  month = mar,
  pages = {1067--1076},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-06},
  abstract = {Supervisory signals can help topic models discover low-dimensional data representations which are useful for a specific prediction task. We propose a framework for training supervised latent Dirichlet allocation that balances two goals: faithful generative explanations of high-dimensional data and accurate prediction of associated class labels. Existing approaches fail to balance these goals by not properly handling a fundamental asymmetry: the intended application is always predicting labels from data, not data from labels. Our new prediction-constrained objective for training generative models coherently integrates supervisory signals even when only a small fraction of training examples are labeled. We demonstrate improved prediction quality compared to previous supervised topic models, achieving results competitive with high-dimensional logistic regression on text analysis and electronic health records tasks while simultaneously learning interpretable topics.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/7VCDRJHX/Hughes et al. - 2018 - Semi-Supervised Prediction-Constrained Topic Model.pdf;/home/cbd/Zotero/storage/VD7FXW7R/Hughes et al. - 2018 - Semi-Supervised Prediction-Constrained Topic Model.pdf}
}

@article{huModelBasedAnnealingRandom2014,
  title = {Model-{{Based Annealing Random Search}} with {{Stochastic Averaging}}},
  author = {Hu, Jiaqiao and Zhou, Enlu and Fan, Qi},
  year = {2014},
  month = nov,
  journal = {ACM Transactions on Modeling and Computer Simulation},
  volume = {24},
  number = {4},
  pages = {21:1--21:23},
  issn = {1049-3301},
  doi = {10.1145/2641565},
  urldate = {2023-03-14},
  abstract = {The model-based methods have recently found widespread applications in solving hard nondifferentiable optimization problems. These algorithms are population-based and typically require hundreds of candidate solutions to be sampled at each iteration. In addition, recent convergence analysis of these algorithms also stipulates a sample size that increases polynomially with the number of iterations. In this article, we aim to improve the efficiency of model-based algorithms by reducing the number of candidate solutions generated per iteration. This is carried out through embedding a stochastic averaging procedure within these methods to make more efficient use of the past sampling information. This procedure not only can potentially reduce the number of function evaluations needed to obtain high-quality solutions, but also makes the underlying algorithms more amenable for parallel computation. The detailed implementation of our approach is demonstrated through an exemplary algorithm instantiation called Model-based Annealing Random Search with Stochastic Averaging (MARS-SA), which maintains the per iteration sample size at a small constant value. We establish the global convergence property of MARS-SA and provide numerical examples to illustrate its performance.},
  keywords = {00-read,Global optimization,model-based algorithms,stochastic approximation},
  file = {/home/cbd/Zotero/storage/G5W8K427/Hu et al. - 2014 - Model-Based Annealing Random Search with Stochasti.pdf}
}

@article{iglesiasEnsembleKalmanFilter2012,
  title = {The {{Ensemble Kalman Filter}} for {{Inverse Problems}}},
  author = {Iglesias, Marco A. and Law, Kody J. H. and Stuart, Andrew M.},
  year = {2012},
  month = sep,
  number = {i},
  eprint = {1209.2736},
  doi = {10.48550/arxiv.1209.2736},
  urldate = {2022-10-17},
  abstract = {The Ensemble Kalman filter (EnKF) was introduced by Evensen in 1994 [10] as a novel method for data assimilation: state estimation for noisily observed time-dependent problems. Since that time it has had enormous impact in many application domains because of its robustness and ease of implementation, and numerical evidence of its accuracy. In this paper we propose the application of an iterative ensemble Kalman method for the solution of a wide class of inverse problems. In this context we show that the estimate of the unknown function that we obtain with the ensemble Kalman method lies in a subspace A spanned by the initial ensemble. Hence the resulting error may be bounded above by the error found from the best approximation in this subspace. We provide numerical experiments which compare the error incurred by the ensemble Kalman method for inverse problems with the error of the best approximation in A, and with variants on traditional least-squares approaches, restricted to the subspace A. In so doing we demonstrate that the the ensemble Kalman method for inverse problems provides a derivative-free optimization method with comparable accuracy to that achieved by traditional least-squares approaches. Furthermore, we also demonstrate that the accuracy is of the same order of magnitude as that achieved by the best approximation. Three examples are used to demonstrate these assertions: inversion of a compact linear operator; inversion of piezometric head to determine hydraulic conductivity in a Darcy model of groundwater flow; and inversion of Eulerian velocity measurements at positive times to determine the initial condition in an incompressible fluid.},
  archiveprefix = {arxiv},
  file = {/home/cbd/Zotero/storage/VHLZRBUK/full-text.pdf}
}

@misc{illinoiscenterforasmarterelectricgridIEEE57BusSystem,
  title = {{{IEEE}} 57-{{Bus System}}},
  author = {{Illinois Center for a Smarter Electric Grid}},
  urldate = {2023-06-07},
  langid = {english},
  file = {/home/cbd/Zotero/storage/2D2RTT5C/ieee-57-bus-system.html}
}

@misc{innesTestingRareDownstream2023,
  title = {Testing {{Rare Downstream Safety Violations}} via {{Upstream Adaptive Sampling}} of {{Perception Error Models}}},
  author = {Innes, Craig and Ramamoorthy, Subramanian},
  year = {2023},
  month = feb,
  number = {arXiv:2209.09674},
  eprint = {2209.09674},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2209.09674},
  urldate = {2023-03-18},
  abstract = {Testing black-box perceptual-control systems in simulation faces two difficulties. Firstly, perceptual inputs in simulation lack the fidelity of real-world sensor inputs. Secondly, for a reasonably accurate perception system, encountering a rare failure trajectory may require running infeasibly many simulations. This paper combines perception error models -- surrogates for a sensor-based detection system -- with state-dependent adaptive importance sampling. This allows us to efficiently assess the rare failure probabilities for real-world perceptual control systems within simulation. Our experiments with an autonomous braking system equipped with an RGB obstacle-detector show that our method can calculate accurate failure probabilities with an inexpensive number of simulations. Further, we show how choice of safety metric can influence the process of learning proposal distributions capable of reliably sampling high-probability failures.},
  archiveprefix = {arxiv},
  keywords = {00-read,00-relevant,importance sampling}
}

@article{jacksonFormalVerificationUnknown,
  title = {Formal Verification of Unknown Dynamical Systems via {{Gaussian}} Process Regression},
  author = {Jackson, John and Laurenti, Luca and Frew, Eric and Lahijanian, Morteza},
  journal = {Artificial Intelligence},
  volume = {Under review},
  abstract = {Leveraging autonomous systems in safety-critical scenarios requires verifying their behaviors in the presence of uncertainties and black-box components that influence the system dynamics. In this article, we develop a framework for verifying partially-observable, discrete-time dynamical systems with unmodelled dynamics against temporal logic specifications from a given input-output dataset. The verification framework employs Gaussian process (GP) regression to learn the unknown dynamics from the dataset and abstract the continuous-space system as a finite-state, uncertain Markov decision process (MDP). This abstraction relies on space discretization and transition probability intervals that capture the uncertainty due to the error in GP regression by using reproducible kernel Hilbert space analysis as well as the uncertainty induced by discretization. The framework utilizes existing model checking tools for verification of the uncertain MDP abstraction against a given temporal logic specification. We establish the correctness of extending the verification results on the abstraction to the underlying partially-observable system. We show that the computational complexity of the framework is polynomial in the size of the dataset and discrete abstraction. The complexity analysis illustrates a trade-off between the quality of the verification results and the computational burden to handle larger datasets and finer abstractions. Finally, we demonstrate the efficacy of our learning and verification framework on several case studies with linear, nonlinear, and switched dynamical systems. Abstract Leveraging autonomous systems in safety-critical scenarios requires verifying their behaviors in the presence of uncertainties and black-box components that influence the system dynamics. In this article, we develop a framework for verifying partially-observable, discrete-time dynami-cal systems with unmodelled dynamics against temporal logic specifications from a given input-output dataset. The verification framework employs Gaussian process (GP) regression to learn the unknown dynamics from the dataset and abstract the continuous-space system as a finite-state, uncertain Markov decision process (MDP). This abstraction relies on space discretization and transition probability intervals that capture the uncertainty due to the error in GP regression by using reproducible kernel Hilbert space analysis as well as the uncertainty induced by discretization. The framework utilizes existing model checking tools for verification of the uncertain MDP abstraction against a given temporal logic specification. We establish the correctness of extending the verification results on the abstraction to the underlying partially-observable system. We show that the computational complexity of the framework is polynomial in the size of the dataset and discrete abstraction. The complexity analysis illustrates a trade-off between the quality of the verification results and the computational burden to handle larger datasets and finer abstractions. Finally, we demonstrate the efficacy of our learning and verification framework on several case studies with linear, nonlinear, and switched dynamical systems.},
  keywords = {Data-driven verification,Formal verification,Gaussian processes,Gaussian Processes,review,Temporal logics,Temporal logics Keywords: Data-driven verification},
  file = {/home/cbd/Zotero/storage/U3939RSJ/ARTINT-D-22-00006_reviewer.pdf}
}

@article{jacksonORCHIDOptimisationRobotic2021,
  title = {{{ORCHID}}: {{Optimisation}} of {{Robotic Control}} and {{Hardware In Design}} Using {{Reinforcement Learning}}},
  author = {Jackson, Lucy and Walters, Celyn and Eckersley, Steve and Senior, Pete and Hadfield, Simon},
  year = {2021},
  month = dec,
  pages = {4911--4917},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  doi = {10.1109/IROS51168.2021.9635865},
  urldate = {2022-02-14},
  abstract = {The successful performance of any system is dependant on the hardware of the agent, which is typically immutable during RL training. In this work, we present ORCHID (Optimisation of Robotic Control and Hardware In Design) which allows for truly simultaneous optimisation of hardware and control parameters in an RL pipeline. We show that by forming a complex differential path through a trajectory rollout we can leverage a vast amount of information from the system that was previously lost in the 'black-box' environment. Combining this with a novel hardware-conditioned critic network minimises variance during training and ensures stable updates are made. This allows for refinements to be made to both the morphology and control parameters simultaneously. The result is an efficient and versatile approach to holistic robot design, that brings the final system nearer to true optimality. We show improvements in performance across 4 different test environments with two different control algorithms-in all experiments the maximum performance achieved with ORCHID is shown to be unattainable using only policy updates with the default design. We also show how redesigning a robot using ORCHID in simulation, transfers to a vast improvement in the performance of a real-world robot.},
  keywords = {autodiff,optimization,rl},
  file = {/home/cbd/Zotero/storage/XTRYZ8X3/full-text.pdf}
}

@misc{jainAnalyzingImprovingNeural2020,
  title = {Analyzing and {{Improving Neural Networks}} by {{Generating Semantic Counterexamples}} through {{Differentiable Rendering}}},
  author = {Jain, Lakshya and Chandrasekaran, Varun and Jang, Uyeong and Wu, Wilson and Lee, Andrew and Yan, Andy and Chen, Steven and Jha, Somesh and Seshia, Sanjit A.},
  year = {2020},
  month = jul,
  number = {arXiv:1910.00727},
  eprint = {1910.00727},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1910.00727},
  urldate = {2023-03-17},
  abstract = {Even as deep neural networks (DNNs) have achieved remarkable success on vision-related tasks, their performance is brittle to transformations in the input. Of particular interest are semantic transformations that model changes that have a basis in the physical world, such as rotations, translations, changes in lighting or camera pose. In this paper, we show how differentiable rendering can be utilized to generate images that are informative, yet realistic, and which can be used to analyze DNN performance and improve its robustness through data augmentation. Given a differentiable renderer and a DNN, we show how to use off-the-shelf attacks from adversarial machine learning to generate semantic counterexamples -- images where semantic features are changed as to produce misclassifications or misdetections. We validate our approach on DNNs for image classification and object detection. For classification, we show that semantic counterexamples, when used to augment the dataset, (i) improve generalization performance (ii) enhance robustness to semantic transformations, and (iii) transfer between models. Additionally, in comparison to sampling-based semantic augmentation, our technique generates more informative data in a sample efficient manner.},
  archiveprefix = {arxiv},
  keywords = {00-read,00-relevant,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/X7PCNC4E/1910.html}
}

@article{Jakob2020DrJit,
  title = {Dr.{{Jit}}: {{A}} Just-in-Time Compiler for Differentiable Rendering},
  author = {Jakob, Wenzel and Speierer, S{\'e}bastien and Roussel, Nicolas and Vicini, Delio},
  year = {2022},
  month = jul,
  journal = {Transactions on Graphics (Proceedings of SIGGRAPH)},
  volume = {41},
  number = {4},
  doi = {10.1145/3528223.3530099}
}

@unpublished{jasourRiskAwareRobust,
  title = {Risk {{Aware}} and {{Robust Nonlinear Planning}}},
  author = {Jasour, Ashkan},
  urldate = {2022-12-19},
  file = {/home/cbd/Zotero/storage/RBLP9EQ7/Lectures-Codes.html}
}

@misc{jax2018github,
  title = {{{JAX}}: Composable Transformations of {{Python}}+{{NumPy}} Programs},
  author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and {Wanderman-Milne}, Skye and Zhang, Qiao},
  year = {2018}
}

@article{jewisonSpacecraftBenchmarkProblem2016,
  title = {A Spacecraft Benchmark Problem for Hybrid Control and Estimation},
  author = {Jewison, Christopher and Erwin, R. Scott},
  year = {2016},
  month = dec,
  journal = {2016 IEEE 55th Conference on Decision and Control, CDC 2016},
  pages = {3300--3305},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/CDC.2016.7798765},
  urldate = {2022-02-15},
  abstract = {The development of autonomous systems is a growing area of importance across a wide range of commercial, government, and civil applications. A number of new technical tools for the design and analysis of complex autonomous systems have been proposed in the literature, including the use of hybrid systems modeling and analysis. This paper develops an exemplar autonomous system problem, namely an autonomous spacecraft rendezvous, proximity operations, and docking (ARPOD) mission, as a benchmark problem for hybrid systems analysis and control techniques. The paper provides a complete mathematical description of the ARPOD hybrid dynamics/control problem, as well as providing details on variants that can be included to emphasize different elements of the hybrid system and to increase or decrease the complexity of the problem. Some baseline results are provided for comparison.},
  isbn = {9781509018376},
  keywords = {application},
  file = {/home/cbd/Zotero/storage/LZKS2NXW/full-text.pdf}
}

@inproceedings{jothimuruganCompositionalReinforcementLearning2021,
  title = {Compositional {{Reinforcement Learning}} from {{Logical Specifications}}},
  booktitle = {Neural {{Information Processing Systems}} ({{NeurIPS}})},
  author = {Jothimurugan, Kishor and Bansal, Suguman and Bastani, Osbert and Alur, Rajeev},
  year = {2021},
  urldate = {2022-02-08},
  abstract = {We study the problem of learning control policies for complex tasks given by logical specifications. Recent approaches automatically generate a reward function from a given specification and use a suitable reinforcement learning algorithm to learn a policy that maximizes the expected reward. These approaches, however, scale poorly to complex tasks that require high-level planning. In this work, we develop a compositional learning approach, called DIRL, that interleaves high-level planning and reinforcement learning. First, DIRL encodes the specification as an abstract graph; intuitively, vertices and edges of the graph correspond to regions of the state space and simpler sub-tasks, respectively. Our approach then incorporates reinforcement learning to learn neural network policies for each edge (sub-task) within a Dijkstra-style planning algorithm to compute a high-level plan in the graph. An evaluation of the proposed approach on a set of challenging control benchmarks with continuous state and action spaces demonstrates that it outperforms state-of-the-art baselines.},
  keywords = {rl,stl},
  file = {/home/cbd/Zotero/storage/J9EHGIPY/full-text.pdf}
}

@inproceedings{jothimuruganSpecificationGuidedLearningNash2021,
  title = {Specification-{{Guided Learning}} of {{Nash Equilibria}} with {{High Social Welfare}}},
  booktitle = {Workshop on {{Safe}} and {{Robust Control}} of {{Uncertain Systems}} ({{SafeRL}})},
  author = {Jothimurugan, Kishor and Bansal, Suguman and Bastani, Osbert and Alur, Rajeev},
  year = {2021},
  urldate = {2022-02-08},
  abstract = {Reinforcement learning has been shown to be an effective strategy for automatically training policies for challenging control problems. Focusing on non-cooperative multi-agent systems, we propose a novel reinforcement learning framework for training joint policies that form a Nash equilibrium. In our approach, rather than providing low-level reward functions, the user provides high-level specifications that encode the goal of each agent. Then, guided by the structure of the specifications , our algorithm searches over policies to identify one that provably forms an-Nash equilibrium (with high probability). Importantly, it prioritizes policies in a way that maximizes social welfare across all agents. Our empirical evaluation demonstrates that our algorithm computes equilibrium policies with high social welfare, whereas state-of-the-art baselines either fail to compute Nash equilibria or compute ones with comparatively lower social welfare.},
  file = {/home/cbd/Zotero/storage/M2FKZHQS/full-text.pdf}
}

@article{julianbresagCommentsGrenadierMiller1994,
  title = {Comments on {{U}}. {{Grenadier}}, {{M}}. {{Miller}}, "{{Representations}} of {{Knowledge}} in {{Complex Systems}}"},
  author = {Bresag, Julian},
  year = {1994},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {56},
  number = {4},
  pages = {549--603},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  urldate = {2023-05-15},
  jstor = {2346184},
  file = {/home/cbd/Zotero/storage/4ZBFY7M3/Grenander and Miller - 1994 - Representations of Knowledge in Complex Systems.pdf}
}

@article{julianCommentsRepresentationsKnowledge1994,
  title = {Comments on "{{Representations}} of {{Knowledge}} in {{Complex Systems}}"},
  author = {Julian, Bresag},
  year = {1994},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {56},
  number = {4},
  pages = {549--603},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  urldate = {2023-09-22},
  jstor = {2346184},
  file = {/home/cbd/Zotero/storage/HV4G2MY4/Grenander and Miller - 1994 - Representations of Knowledge in Complex Systems.pdf}
}

@book{kaipioStatisticalComputationalInverse2005,
  title = {Statistical and {{Computational Inverse Problems}}},
  author = {Kaipio, Jari P. and Somersalo, Erkki},
  editor = {Antman, S.S. and Marsden, J.E. and Sirovich, L.},
  year = {2005},
  series = {Applied {{Mathematical Sciences}}},
  volume = {160},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/b138659},
  urldate = {2024-01-02},
  isbn = {978-0-387-22073-4 978-0-387-27132-3},
  langid = {english},
  keywords = {biomedical engineering,complexity,construction,Markov,Measure,mechanics,model,modeling,optimization,Probability distribution,Random variable},
  file = {/home/cbd/Zotero/storage/IE4QMW6D/Kaipio and Somersalo - 2005 - Statistical and Computational Inverse Problems.pdf}
}

@article{kantaros20,
  title = {{{STyLuS}}*: {{A}} Temporal Logic Optimal Control Synthesis Algorithm for Large-Scale Multi-Robot Systems},
  author = {Kantaros, Yiannis and Zavlanos, Michael M},
  year = {2020},
  journal = {The International Journal of Robotics Research},
  volume = {39},
  number = {7},
  eprint = {https://doi.org/10.1177/0278364920913922},
  pages = {812--836},
  doi = {10.1177/0278364920913922}
}

@article{kapinskiSimulationBasedApproachesVerification2016,
  title = {Simulation-{{Based Approaches}} for {{Verification}} of {{Embedded Control Systems}}: {{An Overview}} of {{Traditional}} and {{Advanced Modeling}}, {{Testing}}, and {{Verification Techniques}}},
  shorttitle = {Simulation-{{Based Approaches}} for {{Verification}} of {{Embedded Control Systems}}},
  author = {Kapinski, James and Deshmukh, Jyotirmoy V. and Jin, Xiaoqing and Ito, Hisahiro and Butts, Ken},
  year = {2016},
  month = dec,
  journal = {IEEE Control Systems Magazine},
  volume = {36},
  number = {6},
  pages = {45--64},
  issn = {1941-000X},
  doi = {10.1109/MCS.2016.2602089},
  abstract = {Designers of industrial embedded control systems, such as automotive, aerospace, and medical-device control systems, use verification and testing activities to increase their confidence that performance requirements and safety standards are met. Since testing and verification tasks account for a significant portion of the development effort, increasing the efficiency of testing and verification will have a significant impact on the total development cost. Existing and emerging simulation-based approaches offer improved means of testing and, in some cases, verifying the correctness of control system designs.},
  keywords = {00-read,00-relevant,Aerospace safety,Automotive engineering,Complexity theory,Embedded systems,Medical devices,Numerical models,Performance evaluation,Process control,Testing,Verification}
}

@article{keipourALFADatasetUAV2021,
  title = {{{ALFA}}: {{A}} Dataset for {{UAV}} Fault and Anomaly Detection},
  shorttitle = {{{ALFA}}},
  author = {Keipour, Azarakhsh and Mousaei, Mohammadreza and Scherer, Sebastian},
  year = {2021},
  month = feb,
  journal = {The International Journal of Robotics Research},
  volume = {40},
  number = {2-3},
  pages = {515--520},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {0278-3649},
  doi = {10.1177/0278364920966642},
  urldate = {2024-01-16},
  abstract = {We present a dataset of several fault types in control surfaces of a fixed-wing unmanned aerial vehicle (UAV) for use in fault detection and isolation (FDI) and anomaly detection (AD) research. Currently, the dataset includes processed data for 47 autonomous flights with 23 sudden full engine failure scenarios and 24 scenarios for 7 other types of sudden control surface (actuator) faults, with a total of 66 minutes of flight under normal conditions and 13 minutes of post-fault flight time. It additionally includes many hours of raw data of fully autonomous, autopilot-assisted and manual flights with tens of fault scenarios. The ground truth of the time and type of faults is provided in each scenario to enable evaluation of the methods using the dataset. We have also provided the helper tools in several programming languages to load and work with the data and to help the evaluation of a detection method using the dataset. A set of metrics is proposed to help to compare different methods using the dataset. Most of the current fault detection methods are evaluated in simulation and, as far as we know, this dataset is the only one providing the real flight data with faults in such capacity. We hope it will help advance the state of the art in AD or FDI research for autonomous aerial vehicles and mobile robots to enhance the safety of autonomous and remote flight operations further. The dataset and the provided tools can be accessed from https://doi.org/10.1184/R1/12707963.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/9HSGM9PS/Keipour et al. - 2021 - ALFA A dataset for UAV fault and anomaly detectio.pdf}
}

@article{kellyNewInterpretationInformation1956,
  title = {A New Interpretation of Information Rate},
  author = {Kelly, J. L.},
  year = {1956},
  month = jul,
  journal = {The Bell System Technical Journal},
  volume = {35},
  number = {4},
  pages = {917--926},
  issn = {0005-8580},
  doi = {10.1002/j.1538-7305.1956.tb03809.x},
  urldate = {2024-01-06},
  abstract = {If the input symbols to a communication channel represent the outcomes of a chance event on which bets are available at odds consistent with their probabilities (i.e., ``fair'' odds), a gambler can use the knowledge given him by the received symbols to cause his money to grow exponentially. The maximum exponential rate of growth of the gambler's capital is equal to the rate of transmission of information over the channel. This result is generalized to include the case of arbitrary odds. Thus we find a situation in which the transmission rate is significant even though no coding is contemplated. Previously this quantity was given significance only by a theorem of Shannon's which asserted that, with suitable encoding, binary digits could be transmitted over the channel at this rate with an arbitrarily small probability of error.},
  file = {/home/cbd/Zotero/storage/R8LIV2M9/Kelly - 1956 - A new interpretation of information rate.pdf;/home/cbd/Zotero/storage/4FIKK3X5/6771227.html}
}

@misc{kidgerNeuralDifferentialEquations2022,
  title = {On {{Neural Differential Equations}}},
  author = {Kidger, Patrick},
  year = {2022},
  month = feb,
  number = {arXiv:2202.02435},
  eprint = {2202.02435},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2202.02435},
  urldate = {2024-02-20},
  abstract = {The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Classical Analysis and ODEs,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/THKM72SC/Kidger - 2022 - On Neural Differential Equations.pdf;/home/cbd/Zotero/storage/P9IY2ISP/2202.html}
}

@incollection{Kim2015_saa_guide,
  title = {A Guide to Sample Average Approximation},
  booktitle = {Handbook of Simulation Optimization},
  author = {Kim, Sujin and Pasupathy, Raghu and Henderson, Shane G.},
  editor = {Fu, Michael C},
  year = {2015},
  pages = {207--243},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-1384-8_8},
  abstract = {This chapter reviews the principles of sample average approximation (SAA) for solving simulation optimization problems. We provide an accessible overview of the area and survey interesting recent developments. We explain when one might want to use SAA and when one might expect it to provide good-quality solutions. We also review some of the key theoretical properties of the solutions obtained through SAA. We contrast SAA with stochastic approximation (SA) methods in terms of the computational effort required to obtain solutions of a given quality, explaining why SA ``wins'' asymptotically. However, an extension of SAA known as retrospective optimization can match the asymptotic convergence rate of SA, at least up to a multiplicative constant.},
  isbn = {978-1-4939-1384-8}
}

@misc{kingmaAutoEncodingVariationalBayes2014,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  year = {2014},
  month = may,
  number = {arXiv:1312.6114},
  eprint = {1312.6114},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1312.6114},
  urldate = {2024-01-04},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/FHM76FDR/Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf;/home/cbd/Zotero/storage/LEBLKK88/1312.html}
}

@inproceedings{kirichenkoWhyNormalizingFlows2020,
  title = {Why {{Normalizing Flows Fail}} to {{Detect Out-of-Distribution Data}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kirichenko, Polina and Izmailov, Pavel and Wilson, Andrew G},
  year = {2020},
  volume = {33},
  pages = {20578--20589},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2024-01-30},
  abstract = {Detecting out-of-distribution (OOD) data is crucial for robust machine learning systems. Normalizing flows are flexible deep generative models that often surprisingly fail to distinguish between in- and out-of-distribution data: a flow trained on pictures of clothing assigns higher likelihood to handwritten digits. We investigate why normalizing flows perform poorly for OOD detection. We demonstrate that flows learn local pixel correlations and generic image-to-latent-space transformations which are not specific to the target image datasets, focusing on flows based on coupling layers. We show that by modifying the architecture of flow coupling layers we can bias the flow towards learning the semantic structure of the target data, improving OOD detection. Our investigation reveals that properties that enable flows to generate high-fidelity images can have a detrimental effect on OOD detection.},
  file = {/home/cbd/Zotero/storage/GGE599CR/Kirichenko et al. - 2020 - Why Normalizing Flows Fail to Detect Out-of-Distri.pdf}
}

@article{knuthPlanningLearnedDynamics2021,
  title = {Planning with {{Learned Dynamics}}: {{Probabilistic Guarantees}} on {{Safety}} and {{Reachability}} via {{Lipschitz Constants}}},
  author = {Knuth, Craig and Chou, Glen and Ozay, Necmiye and Berenson, Dmitry},
  year = {2021},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  eprint = {2010.08993},
  pages = {5129--5136},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {23773766},
  doi = {10.1109/LRA.2021.3068889},
  urldate = {2022-02-22},
  abstract = {We present a method for feedback motion planning of systems with unknown dynamics which provides probabilistic guarantees on safety, reachability, and goal stability. To find a domain in which a learned control-affine approximation of the true dynamics can be trusted, we estimate the Lipschitz constant of the difference between the true and learned dynamics, and ensure the estimate is valid with a given probability. Provided the system has at least as many controls as states, we also derive existence conditions for a one-step feedback law which can keep the real system within a small bound of a nominal trajectory planned with the learned dynamics. Our method imposes the feedback law existence as a constraint in a sampling-based planner, which returns a feedback policy around a nominal plan ensuring that, if the Lipschitz constant estimate is valid, the true system is safe during plan execution, reaches the goal, and is ultimately invariant in a small set about the goal. We demonstrate our approach by planning using learned models of a 6D quadrotor and a 7DOF Kuka arm. We show that a baseline which plans using the same learned dynamics without considering the error bound or the existence of the feedback law can fail to stabilize around the plan and become unsafe.},
  archiveprefix = {arxiv},
  keywords = {machine learning for robot control,Motion and path planning,robot safety,to_read},
  file = {/home/cbd/Zotero/storage/TRK5FT22/full-text.pdf}
}

@book{kochenderfer_wheeler_2019,
  title = {Algorithms for Optimization},
  author = {Kochenderfer, Mykel J. and Wheeler, Tim A.},
  year = {2019},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}}
}

@article{korenAdaptiveStressTesting2020,
  title = {The {{Adaptive Stress Testing Formulation}}},
  author = {Koren, Mark and Corso, Anthony and Kochenderfer, Mykel J.},
  year = {2020},
  month = apr,
  eprint = {2004.04293},
  doi = {10.48550/arxiv.2004.04293},
  urldate = {2022-10-18},
  abstract = {Validation is a key challenge in the search for safe autonomy. Simulations are often either too simple to provide robust validation, or too complex to tractably compute. Therefore, approximate validation methods are needed to tractably find failures without unsafe simplifications. This paper presents the theory behind one such black-box approach: adaptive stress testing (AST). We also provide three examples of validation problems formulated to work with AST.},
  archiveprefix = {arxiv},
  isbn = {2004.04293v1},
  file = {/home/cbd/Zotero/storage/ILHACYSI/full-text.pdf}
}

@inproceedings{korenEfficientAutonomyValidation2019,
  title = {Efficient {{Autonomy Validation}} in {{Simulation}} with {{Adaptive Stress Testing}}},
  booktitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  author = {Koren, Mark and Kochenderfer, Mykel J.},
  year = {2019},
  month = oct,
  pages = {4178--4183},
  doi = {10.1109/ITSC.2019.8917403},
  abstract = {During the development of autonomous systems such as driverless cars, it is important to characterize the scenarios that are most likely to result in failure. Adaptive Stress Testing (AST) provides a way to search for the most-likely failure scenario as a Markov decision process (MDP). Our previous work used a deep reinforcement learning (DRL) solver to identify likely failure scenarios. However, the solver's use of a feed-forward neural network with a discretized space of possible initial conditions poses two major problems. First, the system is not treated as a black box, in that it requires analyzing the internal state of the system, which leads to considerable implementation complexities. Second, in order to simulate realistic settings, a new instance of the solver needs to be run for each initial condition. Running a new solver for each initial condition not only significantly increases the computational complexity, but also disregards the underlying relationship between similar initial conditions. We provide a solution to both problems by employing a recurrent neural network that takes a set of initial conditions from a continuous space as input. This approach enables robust and efficient detection of failures because the solution generalizes across the entire space of initial conditions. By simulating an instance where an autonomous car drives while a pedestrian is crossing a road, we demonstrate the solver is now capable of finding solutions for problems that would have previously been intractable.},
  keywords = {00-read,00-relevant,rl},
  file = {/home/cbd/Zotero/storage/VQ5DV5A5/Koren and Kochenderfer - 2019 - Efficient Autonomy Validation in Simulation with A.pdf;/home/cbd/Zotero/storage/7DBJSZ8L/8917403.html}
}

@article{kress-gazitSynthesisRobotsGuarantees2018,
  title = {Synthesis for {{Robots}}: {{Guarantees}} and {{Feedback}} for {{Robot Behavior}}},
  shorttitle = {Synthesis for {{Robots}}},
  author = {{Kress-Gazit}, Hadas and Lahijanian, Morteza and Raman, Vasumathi},
  year = {2018},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {1},
  number = {1},
  pages = {211--236},
  doi = {10.1146/annurev-control-060117-104838},
  urldate = {2023-02-07},
  abstract = {Robot control for tasks such as moving around obstacles or grasping objects has advanced significantly in the last few decades. However, controlling robots to perform complex tasks is still accomplished largely by highly trained programmers in a manual, time-consuming, and error-prone process that is typically validated only through extensive testing. Formal methods are mathematical techniques for reasoning about systems, their requirements, and their guarantees. Formal synthesis for robotics refers to frameworks for specifying tasks in a mathematically precise language and automatically transforming these specifications into correct-by-construction robot controllers or into a proof that the task cannot be done. Synthesis allows users to reason about the task specification rather than its implementation, reduces implementation error, and provides behavioral guarantees for the resulting controller. This article reviews the current state of formal synthesis for robotics and surveys the landscape of abstractions, specifications, and synthesis algorithms that enable it.},
  keywords = {control,formal methods,high-level specifications,robotics,synthesis},
  file = {/home/cbd/Zotero/storage/4PLF29BX/Kress-Gazit et al. - 2018 - Synthesis for Robots Guarantees and Feedback for .pdf}
}

@inproceedings{krishnapriyanCharacterizingPossibleFailure2021,
  title = {Characterizing Possible Failure Modes in Physics-Informed Neural Networks},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krishnapriyan, Aditi and Gholami, Amir and Zhe, Shandian and Kirby, Robert and Mahoney, Michael W},
  year = {2021},
  volume = {34},
  pages = {26548--26560},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-15},
  abstract = {Recent work in scientific machine learning has developed so-called physics-informed neural network (PINN) models. The typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. We demonstrate that, while existing PINN methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. In particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. We provide evidence that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. Importantly, we show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN's setup makes the loss landscape very hard to optimize. We then describe two promising solutions to address these failure modes. The first approach is to use curriculum regularization, where the PINN's loss term starts from a simple PDE regularization, and becomes progressively more complex as the NN gets trained. The second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. Extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular PINN training.}
}

@article{kwiatkowskaProbabilisticModelChecking2021,
  title = {Probabilistic {{Model Checking}} and {{Autonomy}}},
  author = {Kwiatkowska, Marta and Norman, Gethin and Parker, David},
  year = {2021},
  month = dec,
  journal = {https://doi.org/10.1146/annurev-control-042820-010947},
  volume = {5},
  number = {1},
  eprint = {2111.10630},
  pages = {23--24},
  publisher = {{Annual Reviews}},
  issn = {2573-5144},
  doi = {10.1146/ANNUREV-CONTROL-042820-010947},
  urldate = {2022-02-07},
  abstract = {The design and control of autonomous systems that operate in uncertain or adversarial environments can be facilitated by formal modeling and analysis. Probabilistic model checking is a technique to...},
  archiveprefix = {arxiv},
  keywords = {equilibria,formal methods,model checking,probabilistic model checking,probabilistic modeling,stochastic games,strategy synthesis,temporal logic},
  file = {/home/cbd/Zotero/storage/ZI4S7X5K/full-text.pdf}
}

@article{lecun2010mnist,
  title = {{{MNIST}} Handwritten Digit Database},
  author = {LeCun, Yann and Cortes, Corinna and Burges, {\relax CJ}},
  year = {2010},
  journal = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume = {2}
}

@article{leeSignalTemporalLogic2021,
  title = {Signal {{Temporal Logic Synthesis}} as {{Probabilistic Inference}}},
  author = {Lee, Ki Myung Brian and Yoo, Chanyeol and Fitch, Robert},
  year = {2021},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  volume = {2021-May},
  eprint = {2105.06121},
  pages = {5483--5489},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {10504729},
  doi = {10.1109/ICRA48506.2021.9560929},
  urldate = {2022-07-17},
  abstract = {We reformulate the signal temporal logic (STL) synthesis problem as a maximum a-posteriori (MAP) inference problem. To this end, we introduce the notion of random STL (RSTL), which extends deterministic STL with random predicates. This new probabilistic extension naturally leads to a synthesis-as-inference approach. The proposed method allows for differentiable, gradient-based synthesis while extending the class of possible uncertain semantics. We demonstrate that the proposed framework scales well with GPU-acceleration, and present realistic applications of uncertain semantics in robotics that involve target tracking and the use of occupancy grids.},
  archiveprefix = {arxiv},
  isbn = {9781728190778},
  file = {/home/cbd/Zotero/storage/HXXV87WH/Signal_Temporal_Logic_Synthesis_as_Probabilistic_Inference.pdf}
}

@article{leeSmoothnessAnalysisProbabilistic2022,
  title = {Smoothness {{Analysis}} for {{Probabilistic Programs}} with {{Application}} to {{Optimised Variational Inference}}},
  author = {Lee, Wonyeol and Rival, Xavier and Yang, Hongseok},
  year = {2022},
  month = aug,
  eprint = {2208.10530},
  doi = {10.48550/arxiv.2208.10530},
  urldate = {2022-10-15},
  abstract = {We present a static analysis for discovering differentiable or more generally smooth parts of a given probabilistic program, and show how the analysis can be used to improve the pathwise gradient estimator, one of the most popular methods for posterior inference and model learning. Our improvement increases the scope of the estimator from differentiable models to non-differentiable ones without requiring manual intervention of the user; the improved estimator automatically identifies differentiable parts of a given probabilistic program using our static analysis, and applies the pathwise gradient estimator to the identified parts while using a more general but less efficient estimator, called score estimator, for the rest of the program. Our analysis has a surprisingly subtle soundness argument, partly due to the misbehaviours of some target smoothness properties when viewed from the perspective of program analysis designers. For instance, some smoothness properties are not preserved by function composition, and this makes it difficult to analyse sequential composition soundly without heavily sacrificing precision. We formulate five assumptions on a target smoothness property, prove the soundness of our analysis under those assumptions, and show that our leading examples satisfy these assumptions. We also show that by using information from our analysis, our improved gradient estimator satisfies an important differentiability requirement and thus, under a mild regularity condition, computes the correct estimate on average, i.e., it returns an unbiased estimate. Our experiments with representative probabilistic programs in the Pyro language show that our static analysis is capable of identifying smooth parts of those programs accurately, and making our improved pathwise gradient estimator exploit all the opportunities for high performance in those programs.},
  archiveprefix = {arxiv},
  keywords = {probabilistic programming,smoothness,static analysis,variational inference},
  file = {/home/cbd/Zotero/storage/2DVE8L4R/full-text.pdf}
}

@article{leeVerifiedStochasticVariational2020,
  title = {Towards Verified Stochastic Variational Inference for Probabilistic Programs},
  author = {Lee, Wonyeol and Yu, Hangyeol and Rival, Xavier and Yang, Hongseok},
  year = {2020},
  month = jan,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {4},
  number = {POPL},
  eprint = {1907.08827},
  pages = {16},
  publisher = {{Association for Computing Machinery}},
  issn = {24751421},
  doi = {10.1145/3371084},
  urldate = {2022-10-15},
  abstract = {Probabilistic programming is the idea of writing models from statistics and machine learning using program notations and reasoning about these models using generic inference engines. Recently its combination with deep learning has been explored intensely, which led to the development of so called deep probabilistic programming languages, such as Pyro, Edward and ProbTorch. At the core of this development lie inference engines based on stochastic variational inference algorithms. When asked to find information about the posterior distribution of a model written in such a language, these algorithms convert this posterior-inference query into an optimisation problem and solve it approximately by a form of gradient ascent or descent. In this paper, we analyse one of the most fundamental and versatile variational inference algorithms, called score estimator or REINFORCE, using tools from denotational semantics and program analysis. We formally express what this algorithm does on models denoted by programs, and expose implicit assumptions made by the algorithm on the models. The violation of these assumptions may lead to an undefined optimisation objective or the loss of convergence guarantee of the optimisation process. We then describe rules for proving these assumptions, which can be automated by static program analyses. Some of our rules use nontrivial facts from continuous mathematics, and let us replace requirements about integrals in the assumptions, such as integrability of functions defined in terms of programs' denotations, by conditions involving differentiation or boundedness, which are much easier to prove automatically (and manually). Following our general methodology, we have developed a static program analysis for the Pyro programming language that aims at discharging the assumption about what we call model-guide support match. Our analysis is applied to the eight representative model-guide pairs from the Pyro webpage, which include sophisticated neural network models such as AIR. It finds a bug in one of these cases, reveals a non-standard use of an inference engine in another, and shows that the assumptions are met in the remaining six cases.},
  archiveprefix = {arxiv},
  keywords = {Correctness,Probabilistic programming,Semantics,Static analysis},
  file = {/home/cbd/Zotero/storage/4SAJ3SWY/full-text.pdf}
}

@inproceedings{lelidecDifferentiableRenderingPerturbed2021,
  title = {Differentiable Rendering with Perturbed Optimizers},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Le Lidec, Quentin and Laptev, Ivan and Schmid, Cordelia and Carpentier, Justin},
  year = {2021},
  volume = {34},
  pages = {20398--20409},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-15},
  abstract = {Reasoning about 3D scenes from their 2D image projections is one of the core problems in computer vision. Solutions to this inverse and ill-posed problem typically involve a search for models that best explain observed image data. Notably, images depend both on the properties of observed scenes and on the process of image formation. Hence, if optimization techniques should be used to explain images, it is crucial to design differentable functions for the projection of 3D scenes into images, also known as differentiable rendering. Previous approaches to differentiable rendering typically replace non-differentiable operations by smooth approximations, impacting the subsequent 3D estimation. In this paper, we take a more general approach and study differentiable renderers through the prism of randomized optimization and the related notion of perturbed optimizers. In particular, our work highlights the link between some well-known differentiable renderer formulations and randomly smoothed optimizers, and introduces differentiable perturbed renderers. We also propose a variance reduction mechanism to alleviate the computational burden inherent to perturbed optimizers and introduce an adaptive scheme to automatically adjust the smoothing parameters of the rendering process. We apply our method to 3D scene reconstruction and demonstrate its advantages on the tasks of 6D pose estimation and 3D mesh reconstruction. By providing informative gradients that can be used as a strong supervisory signal, we demonstrate the benefits of perturbed renderers to obtain more accurate solutions when compared to the state-of-the-art alternatives using smooth gradient approximations.},
  keywords = {00-read}
}

@inproceedings{leungBackPropagationSignalTemporal2021,
  title = {Back-{{Propagation Through Signal Temporal Logic Specifications}}: {{Infusing Logical Structure}} into {{Gradient-Based Methods}}},
  shorttitle = {Back-{{Propagation Through Signal Temporal Logic Specifications}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XIV}}},
  author = {Leung, Karen and Arechiga, Nikos and Pavone, Marco},
  editor = {LaValle, Steven M. and Lin, Ming and Ojala, Timo and Shell, Dylan and Yu, Jingjin},
  year = {2021},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {432--449},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-66723-8_26},
  abstract = {This paper presents a technique, named stlcg, to compute the quantitative semantics of Signal Temporal Logic (STL) formulas using computation graphs. stlcg provides a platform which enables the incorporation of logical specifications into robotics problems that benefit from gradient-based solutions. Specifically, STL is a powerful and expressive formal language that can specify spatial and temporal properties of signals generated by both continuous and hybrid systems. The quantitative semantics of STL provide a robustness metric, i.e., how much a signal satisfies or violates an STL specification. In this work, we devise a systematic methodology for translating STL robustness formulas into computation graphs. With this representation, and by leveraging off-the-shelf automatic differentiation tools, we are able to back-propagate through STL robustness formulas and hence enable a natural and easy-to-use integration with many gradient-based approaches used in robotics. We demonstrate, through examples stemming from various robotics applications, that stlcg is versatile, computationally efficient, and capable of injecting human-domain knowledge into the problem formulation.},
  isbn = {978-3-030-66723-8},
  langid = {english},
  keywords = {Back-propagation,Computation graph,Logical structure,Robustness,Signal temporal logic},
  file = {/home/cbd/Zotero/storage/STZCYLR8/Leung et al. - 2021 - Back-Propagation Through Signal Temporal Logic Spe.pdf}
}

@misc{levineReinforcementLearningControl2018a,
  title = {Reinforcement {{Learning}} and {{Control}} as {{Probabilistic Inference}}: {{Tutorial}} and {{Review}}},
  shorttitle = {Reinforcement {{Learning}} and {{Control}} as {{Probabilistic Inference}}},
  author = {Levine, Sergey},
  year = {2018},
  month = may,
  number = {arXiv:1805.00909},
  eprint = {1805.00909},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1805.00909},
  urldate = {2023-06-06},
  abstract = {The framework of reinforcement learning or optimal control provides a mathematical formalization of intelligent decision making that is powerful and broadly applicable. While the general form of the reinforcement learning problem enables effective reasoning about uncertainty, the connection between reinforcement learning and inference in probabilistic models is not immediately obvious. However, such a connection has considerable value when it comes to algorithm design: formalizing a problem as probabilistic inference in principle allows us to bring to bear a wide array of approximate inference tools, extend the model in flexible and powerful ways, and reason about compositionality and partial observability. In this article, we will discuss how a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. We will present a detailed derivation of this framework, overview prior work that has drawn on this and related ideas to propose new reinforcement learning and control algorithms, and describe perspectives on future research.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/IQDUHGHM/Levine - 2018 - Reinforcement Learning and Control as Probabilisti.pdf;/home/cbd/Zotero/storage/2TW8SI8H/1805.html}
}

@inproceedings{liAdversarialAttacksBlack2021,
  title = {Adversarial {{Attacks}} on {{Black Box Video Classifiers}}: {{Leveraging}} the {{Power}} of {{Geometric Transformations}}},
  shorttitle = {Adversarial {{Attacks}} on {{Black Box Video Classifiers}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Li, Shasha and Aich, Abhishek and Zhu, Shitong and Asif, Salman and Song, Chengyu and {Roy-Chowdhury}, Amit and Krishnamurthy, Srikanth},
  year = {2021},
  volume = {34},
  pages = {2085--2096},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-15},
  abstract = {When compared to the image classification models, black-box adversarial attacks against video classification models have been largely understudied. This could be possible because, with video, the temporal dimension poses significant additional challenges in gradient estimation. Query-efficient black-box attacks rely on effectively estimated gradients towards maximizing the probability of misclassifying the target video. In this work, we demonstrate that such effective gradients can be searched for by parameterizing the temporal structure of the search space with geometric transformations. Specifically, we design a novel iterative algorithm GEOmetric TRAnsformed Perturbations (GEO-TRAP), for attacking video classification models. GEO-TRAP employs standard geometric transformation operations to reduce the search space for effective gradients into searching for a small group of parameters that define these operations. This group of parameters describes the geometric progression of gradients, resulting in a reduced and structured search space. Our algorithm inherently leads to successful perturbations with surprisingly few queries. For example, adversarial examples generated from GEO-TRAP have better attack success rates with {\textasciitilde}73.55\% fewer queries compared to the state-of-the-art method for video adversarial attacks on the widely used Jester dataset. Overall, our algorithm exposes vulnerabilities of diverse video classification models and achieves new state-of-the-art results under black-box settings on two large datasets.},
  keywords = {00-read}
}

@misc{liangEnhancingReliabilityOutofdistribution2020,
  title = {Enhancing {{The Reliability}} of {{Out-of-distribution Image Detection}} in {{Neural Networks}}},
  author = {Liang, Shiyu and Li, Yixuan and Srikant, R.},
  year = {2020},
  month = aug,
  number = {arXiv:1706.02690},
  eprint = {1706.02690},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.02690},
  urldate = {2024-01-30},
  abstract = {We consider the problem of detecting out-of-distribution images in neural networks. We propose ODIN, a simple and effective method that does not require any change to a pre-trained neural network. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in- and out-of-distribution images, allowing for more effective detection. We show in a series of experiments that ODIN is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach by a large margin, establishing a new state-of-the-art performance on this task. For example, ODIN reduces the false positive rate from the baseline 34.7\% to 4.3\% on the DenseNet (applied to CIFAR-10) when the true positive rate is 95\%.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/T5YM56YT/Liang et al. - 2020 - Enhancing The Reliability of Out-of-distribution I.pdf;/home/cbd/Zotero/storage/2MZKVCNJ/1706.html}
}

@article{lindemannRobustMotionPlanning2017,
  title = {Robust Motion Planning Employing Signal Temporal Logic},
  author = {Lindemann, Lars and Dimarogonas, Dimos V.},
  year = {2017},
  month = jun,
  journal = {Proceedings of the American Control Conference},
  eprint = {1703.02075},
  pages = {2950--2955},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {07431619},
  doi = {10.23919/ACC.2017.7963399},
  urldate = {2022-03-01},
  abstract = {Motion planning classically concerns the problem of accomplishing a goal configuration while avoiding obstacles. However, the need for more sophisticated motion planning methodologies, taking temporal aspects into account, has emerged. To address this issue, temporal logics have recently been used to formulate such advanced specifications. This paper will consider Signal Temporal Logic in combination with Model Predictive Control. A robustness metric, called Discrete Average Space Robustness, is introduced and used to maximize the satisfaction of specifications which results in a natural robustness against noise. The comprised optimization problem is convex and formulated as a Linear Program.},
  archiveprefix = {arxiv},
  isbn = {9781509059928},
  keywords = {to_read},
  file = {/home/cbd/Zotero/storage/FQQRNVTI/full-text.pdf}
}

@inproceedings{linProbabilisticUnrollingScalable2023,
  title = {Probabilistic {{Unrolling}}: {{Scalable}}, {{Inverse-Free Maximum Likelihood Estimation}} for {{Latent Gaussian Models}}},
  shorttitle = {Probabilistic {{Unrolling}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Lin, Alexander and Tolooshams, Bahareh and Atchade, Yves and Ba, Demba E.},
  year = {2023},
  month = jul,
  pages = {21153--21181},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-03},
  abstract = {Latent Gaussian models have a rich history in statistics and machine learning, with applications ranging from factor analysis to compressed sensing to time series analysis. The classical method for maximizing the likelihood of these models is the expectation-maximization (EM) algorithm. For problems with high-dimensional latent variables and large datasets, EM scales poorly because it needs to invert as many large covariance matrices as the number of data points. We introduce probabilistic unrolling, a method that combines Monte Carlo sampling with iterative linear solvers to circumvent matrix inversion. Our theoretical analyses reveal that unrolling and backpropagation through the iterations of the solver can accelerate gradient estimation for maximum likelihood estimation. In experiments on simulated and real data, we demonstrate that probabilistic unrolling learns latent Gaussian models up to an order of magnitude faster than gradient EM, with minimal losses in model performance.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/LM8MQQ3R/Lin et al. - 2023 - Probabilistic Unrolling Scalable, Inverse-Free Ma.pdf}
}

@inproceedings{liReactiveTaskMotion2021,
  title = {Reactive {{Task}} and {{Motion Planning}} under {{Temporal Logic Specifications}}},
  booktitle = {{{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Li, Shen and Park, Daehyung and Sung, Yoonchang and Shah, Julie A. and Roy, Nicholas},
  year = {2021},
  month = mar,
  eprint = {2103.14464},
  pages = {12618--12624},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  doi = {10.1109/icra48506.2021.9561807},
  urldate = {2022-02-07},
  abstract = {We present a task-and-motion planning (TAMP) algorithm robust against a human operator's cooperative or adversarial interventions. Interventions often invalidate the current plan and require replanning on the fly. Replanning can be computationally expensive and often interrupts seamless task execution. We introduce a dynamically reconfigurable planning methodology with behavior tree-based control strategies toward reactive TAMP, which takes the advantage of previous plans and incremental graph search during temporal logic-based reactive synthesis. Our algorithm also shows efficient recovery functionalities that minimize the number of replanning steps. Finally, our algorithm produces a robust, efficient, and complete TAMP solution. Our experimental results show the algorithm results in superior manipulation performance in both simulated and real-world tasks.},
  archiveprefix = {arxiv},
  file = {/home/cbd/Zotero/storage/ZB4T2CAA/full-text.pdf}
}

@article{liuAlgorithmsVerifyingDeep2021,
  title = {Algorithms for {{Verifying Deep Neural Networks}}},
  author = {Liu, Changliu and Arnon, Tomer and Lazarus, Christopher and Strong, Christopher and Barrett, Clark and Kochenderfer, Mykel J.},
  year = {2021},
  month = feb,
  journal = {Foundations and Trends{\textregistered} in Optimization},
  volume = {4},
  number = {3-4},
  pages = {244--404},
  publisher = {{Now Publishers, Inc.}},
  issn = {2167-3888, 2167-3918},
  doi = {10.1561/2400000035},
  urldate = {2023-09-15},
  abstract = {Algorithms for Verifying Deep Neural Networks},
  langid = {english},
  file = {/home/cbd/Zotero/storage/TVC4KK47/Liu et al. - 2021 - Algorithms for Verifying Deep Neural Networks.pdf}
}

@misc{liuDelvingTransferableAdversarial2017,
  title = {Delving into {{Transferable Adversarial Examples}} and {{Black-box Attacks}}},
  author = {Liu, Yanpei and Chen, Xinyun and Liu, Chang and Song, Dawn},
  year = {2017},
  month = feb,
  number = {arXiv:1611.02770},
  eprint = {1611.02770},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1611.02770},
  urldate = {2023-03-17},
  abstract = {An intriguing property of deep neural networks is the existence of adversarial examples, which can transfer among different architectures. These transferable adversarial examples may severely hinder deep neural network-based applications. Previous works mostly study the transferability using small scale datasets. In this work, we are the first to conduct an extensive study of the transferability over large models and a large scale dataset, and we are also the first to study the transferability of targeted adversarial examples with their target labels. We study both non-targeted and targeted adversarial examples, and show that while transferable non-targeted adversarial examples are easy to find, targeted adversarial examples generated using existing approaches almost never transfer with their target labels. Therefore, we propose novel ensemble-based approaches to generating transferable adversarial examples. Using such approaches, we observe a large proportion of targeted adversarial examples that are able to transfer with their target labels for the first time. We also present some geometric studies to help understanding the transferable adversarial examples. Finally, we show that the adversarial examples generated using ensemble-based approaches can successfully attack Clarifai.com, which is a black-box image classification system.},
  archiveprefix = {arxiv},
  keywords = {00-read,Computer Science - Machine Learning}
}

@inproceedings{liuOptimizationAmortizedInverse2023,
  title = {Optimization for {{Amortized Inverse Problems}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Liu, Tianci and Yang, Tong and Zhang, Quan and Lei, Qi},
  year = {2023},
  month = jul,
  pages = {22289--22319},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-03},
  abstract = {Incorporating a deep generative model as the prior distribution in inverse problems has established substantial success in reconstructing images from corrupted observations. Notwithstanding, the existing optimization approaches use gradient descent largely without adapting to the non-convex nature of the problem and can be sensitive to initial values, impeding further performance improvement. In this paper, we propose an efficient amortized optimization scheme for inverse problems with a deep generative prior. Specifically, the optimization task with high degrees of difficulty is decomposed into optimizing a sequence of much easier ones. We provide a theoretical guarantee of the proposed algorithm and empirically validate it on different inverse problems. As a result, our approach outperforms baseline methods qualitatively and quantitatively by a large margin.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/TY2FI6HF/Liu et al. - 2023 - Optimization for Amortized Inverse Problems.pdf}
}

@inproceedings{liuProvablyEfficientBlackBox2021,
  title = {Provably {{Efficient Black-Box Action Poisoning Attacks Against Reinforcement Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Liu, Guanlin and Lai, Lifeng},
  year = {2021},
  volume = {34},
  pages = {12400--12410},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-14},
  abstract = {Due to the broad range of applications of reinforcement learning (RL), understanding the effects of adversarial attacks against RL model is essential for the safe applications of this model. Prior theoretical works on adversarial attacks against RL mainly focus on either reward poisoning attacks or environment poisoning attacks. In this paper, we introduce a new class of attacks named action poisoning attacks, where an adversary can change the action signal selected by the agent. Compared with existing attack models, the attacker's ability in the proposed action poisoning attack model is more restricted, which brings some design challenges. We study the action poisoning attack in both white-box and black-box settings. We introduce an adaptive attack scheme called LCB-H, which works for most RL agents in the black-box setting. We prove that LCB-H attack can force any efficient RL agent, whose dynamic regret scales sublinearly with the total number of steps taken, to choose actions according to a policy selected by the attacker very frequently, with only sublinear cost. In addition, we apply LCB-H attack against a very popular model-free RL algorithm: UCB-H. We show that, even in black-box setting, by spending only logarithm cost, the proposed LCB-H attack scheme can force the UCB-H agent to choose actions according to the policy selected by the attacker very frequently.},
  keywords = {00-read},
  file = {/home/cbd/Zotero/storage/Y46MYP22/Liu and LAI - 2021 - Provably Efficient Black-Box Action Poisoning Atta.pdf}
}

@inproceedings{liuSteinVariationalGradient2016a,
  title = {Stein {{Variational Gradient Descent}}: {{A General Purpose Bayesian Inference Algorithm}}},
  shorttitle = {Stein {{Variational Gradient Descent}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Liu, Qiang and Wang, Dilin},
  year = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-09-22},
  abstract = {We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein's identity and a recently proposed kernelized Stein discrepancy, which is of independent interest.},
  file = {/home/cbd/Zotero/storage/RI8Y36A5/Liu and Wang - 2016 - Stein Variational Gradient Descent A General Purp.pdf}
}

@article{ma2021diffaqua,
  title = {{{DiffAqua}}: {{A}} Differentiable Computational Design Pipeline for Soft Underwater Swimmers with Shape Interpolation},
  author = {Ma, Pingchuan and Du, Tao and Zhang, John Z and Wu, Kui and Spielberg, Andrew and Katzschmann, Robert K and Matusik, Wojciech},
  year = {2021},
  journal = {ACM Transactions on Graphics (TOG)},
  volume = {40},
  number = {4},
  pages = {132},
  publisher = {{ACM New York, NY, USA}}
}

@inproceedings{madryDeepLearningModels2018,
  title = {Towards {{Deep Learning Models Resistant}} to {{Adversarial Attacks}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  year = {2018},
  month = feb,
  urldate = {2023-09-15},
  abstract = {Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against a well-defined class of adversaries. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest robustness against a first-order adversary as a natural security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/6LMIJ3BT/Madry et al. - 2018 - Towards Deep Learning Models Resistant to Adversar.pdf}
}

@inproceedings{majumdarControlVerificationHighdimensional2014,
  title = {Control and Verification of High-Dimensional Systems with {{DSOS}} and {{SDSOS}} Programming},
  booktitle = {53rd {{IEEE Conference}} on {{Decision}} and {{Control}}},
  author = {Majumdar, Anirudha and Ahmadi, Amir Ali and Tedrake, Russ},
  year = {2014},
  month = dec,
  pages = {394--401},
  issn = {0191-2216},
  doi = {10.1109/CDC.2014.7039413},
  abstract = {In this paper, we consider linear programming (LP) and second order cone programming (SOCP) based alternatives to sum of squares (SOS) programming and apply this framework to high-dimensional problems arising in control applications. Despite the wide acceptance of SOS programming in the control and optimization communities, scalability has been a key challenge due to its reliance on semidefinite programming (SDP) as its main computational engine. While SDPs have many appealing features, current SDP solvers do not approach the scalability or numerical maturity of LP and SOCP solvers. Our approach is based on the recent work of Ahmadi and Majumdar [1], which replaces the positive semidefiniteness constraint inherent in the SOS approach with stronger conditions based on diagonal dominance and scaled diagonal dominance. This leads to the DSOS and SDSOS cones of polynomials, which can be optimized over using LP and SOCP respectively. We demonstrate this approach on four high dimensional control problems that are currently well beyond the reach of SOS programming: computing a region of attraction for a 22 dimensional system, analysis of a 50 node network of oscillators, searching for degree 3 controllers and degree 8 Lyapunov functions for an Acrobot system (with the resulting controller validated on a hardware platform), and a balancing controller for a 30 state and 14 control input model of the ATLAS humanoid robot. While there is additional conservatism introduced by our approach, extensive numerical experiments on smaller instances of our problems demonstrate that this conservatism can be small compared to SOS programming.},
  keywords = {Approximation methods,Lyapunov methods,Optimization,Polynomials,Programming,Scalability,Symmetric matrices},
  file = {/home/cbd/Zotero/storage/8X4M4NL3/Majumdar et al. - 2014 - Control and verification of high-dimensional syste.pdf;/home/cbd/Zotero/storage/J8CXEUY5/7039413.html}
}

@book{manipulation,
  title = {Robotic Manipulation. {{Perception}}, {{Planning}}, and {{Control}}},
  author = {Tedrake, Russ},
  year = {2023},
  howpublished = {Course Notes for MIT 6.421}
}

@inproceedings{marinoIterativeAmortizedInference2018,
  title = {Iterative {{Amortized Inference}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Marino, Joe and Yue, Yisong and Mandt, Stephan},
  year = {2018},
  month = jul,
  pages = {3403--3412},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-03},
  abstract = {Inference models are a key component in scaling variational inference to deep latent variable models, most notably as encoder networks in variational auto-encoders (VAEs). By replacing conventional optimization-based inference with a learned model, inference is amortized over data examples and therefore more computationally efficient. However, standard inference models are restricted to direct mappings from data to approximate posterior estimates. The failure of these models to reach fully optimized approximate posterior estimates results in an amortization gap. We aim toward closing this gap by proposing iterative inference models, which learn to perform inference optimization through repeatedly encoding gradients. Our approach generalizes standard inference models in VAEs and provides insight into several empirical findings, including top-down inference techniques. We demonstrate the inference optimization capabilities of iterative inference models and show that they outperform standard inference models on several benchmark data sets of images and text.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/QU6DF53U/Marino et al. - 2018 - Iterative Amortized Inference.pdf;/home/cbd/Zotero/storage/SB6LWAL6/Marino et al. - 2018 - Iterative Amortized Inference.pdf}
}

@article{Martins2013_mdo_survey,
  title = {Multidisciplinary Design Optimization: {{A}} Survey of Architectures},
  author = {Martins, Joaquim R. R. A. and Lambe, Andrew B.},
  year = {2013},
  month = sep,
  journal = {AIAA Journal},
  volume = {51},
  number = {9},
  pages = {2049--2075},
  doi = {10.2514/1.J051895}
}

@article{maSamplingCanBe2019,
  title = {Sampling Can Be Faster than Optimization},
  author = {Ma, Yi An and Chen, Yuansi and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I.},
  year = {2019},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {116},
  number = {42},
  eprint = {1811.08413},
  pages = {20881--20885},
  publisher = {{National Academy of Sciences}},
  issn = {10916490},
  doi = {10.1073/PNAS.1820003116/-/DCSUPPLEMENTAL},
  urldate = {2022-03-17},
  abstract = {Optimization algorithms and Monte Carlo sampling algorithms have provided the computational foundations for the rapid growth in applications of statistical machine learning in recent years. There is, however, limited theoretical understanding of the relationships between these 2 kinds of methodology, and limited understanding of relative strengths and weaknesses. Moreover, existing results have been obtained primarily in the setting of convex functions (for optimization) and log-concave functions (for sampling). In this setting, where local properties determine global properties, optimization algorithms are unsurprisingly more efficient computationally than sampling algorithms. We instead examine a class of nonconvex objective functions that arise in mixture modeling and multistable systems. In this nonconvex setting, we find that the computational complexity of sampling algorithms scales linearly with the model dimension while that of optimization algorithms scales exponentially.},
  archiveprefix = {arxiv},
  pmid = {31570618},
  keywords = {Computational complexity,Langevin Monte Carlo,Nonconvex optimization},
  file = {/home/cbd/Zotero/storage/CRW3WFHB/full-text.pdf}
}

@article{maSaSTLSpatialAggregation2020,
  title = {{{SaSTL}}: {{Spatial}} Aggregation Signal Temporal Logic for Runtime Monitoring in Smart Cities},
  author = {Ma, Meiyi and Bartocci, Ezio and Lifland, Eli and Stankovic, John and Feng, Lu},
  year = {2020},
  month = apr,
  journal = {Proceedings - 2020 ACM/IEEE 11th International Conference on Cyber-Physical Systems, ICCPS 2020},
  eprint = {1908.02366},
  pages = {51--62},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/ICCPS48487.2020.00013},
  urldate = {2022-03-17},
  abstract = {We present SaSTL - a novel Spatial Aggregation Signal Temporal Logic - for the efficient runtime monitoring of safety and performance requirements in smart cities. We first describe a study of over 1,000 smart city requirements, some of which can not be specified using existing logic such as Signal Temporal Logic (STL) and its variants. To tackle this limitation, we develop two new logical operators in SaSTL to augment STL for expressing spatial aggregation and spatial counting characteristics that are commonly found in real city requirements. We also develop efficient monitoring algorithms that can check a SaSTL requirement in parallel over multiple data streams (e.g., generated by multiple sensors distributed spatially in a city). We evaluate our SaSTL monitor by applying to two case studies with large-scale real city sensing data (e.g., up to 10,000 sensors in one requirement). The results show that SaSTL has a much higher coverage expressiveness than other spatialoral logics, and with a significant reduction of computation time for monitoring requirements. We also demonstrate that the SaSTL monitor can help improve the safety and performance of smart cities via simulated experiments.},
  archiveprefix = {arxiv},
  isbn = {9781728155012},
  keywords = {Requirement specification,Runtime monitoring,Smart cities,Spatial Temporal Logic,stl},
  file = {/home/cbd/Zotero/storage/2H3P9FQY/full-text.pdf}
}

@article{matniResilienceLargeScale2014,
  title = {Resilience in {{Large Scale Distributed Systems}}},
  author = {Matni, Nikolai and Leong, Yoke Peng and Wang, Yuh Shyang and You, Seungil and Horowitz, Matanya B. and Doyle, John C.},
  year = {2014},
  month = jan,
  journal = {Procedia Computer Science},
  volume = {28},
  pages = {285--293},
  publisher = {{Elsevier}},
  issn = {1877-0509},
  doi = {10.1016/J.PROCS.2014.03.036},
  urldate = {2022-02-02},
  abstract = {Distributed systems are comprised of multiple subsystems that interact in two distinct ways: (1) physical interactions and (2) cyber interactions; i.e. sensors, actuators and computers controlling these subsystems, and the network over which they communicate. A broad class of cyber-physical systems (CPS) are described by such interactions, such as the smart grid, platoons of autonomous vehicles and the sensorimotor system. This paper will survey recent progress in developing a coherent mathematical framework that describes the rich CPS "design space" of fundamental limits and tradeoffs between efficiency, robustness, adaptation, verification and scalability. Whereas most research treats at most one of these issues, we attempt a holistic approach in examining these metrics. In particular, we will argue that a control architecture that emphasizes scalability leads to improvements in robustness, adaptation, and verification, all the while having only minor effects on efficiency - i.e. through the choice of a new architecture, we believe that we are able to bring a system closer to the true fundamental hard limits of this complex design space. {\copyright} 2014 The Authors. Published by Elsevier B.V.},
  keywords = {control theory,Control theory,Convex optimization,Distributed,distributed systems,Fundamental limits,Large scale,Layered architecture,Resilient,Tradeoffs},
  file = {/home/cbd/Zotero/storage/JZS6VX3Q/full-text.pdf}
}

@article{mdo_ocean_robot,
  title = {An Application of Multidisciplinary Design Optimization to the Hydrodynamic Performances of Underwater Robots},
  author = {Luo, Weilin and Lyu, Wenjing},
  year = {2015},
  journal = {Ocean Engineering},
  volume = {104},
  pages = {686--697},
  issn = {0029-8018},
  doi = {10.1016/j.oceaneng.2015.06.011},
  abstract = {Multidisciplinary Design Optimization (MDO) is proposed for the design of the lines of an underwater robot. Hydrodynamic performances of the underwater robot are concerned about in the design, including the resistance and the manoeuvrability. A method of MDO, Collaborative Optimization (CO), is adopted. To improve the efficiency of optimization, approximate models are established in sub-disciplines. Also, an artificial intelligent technique, Particle Swarm Optimization (PSO), is incorporated into the CO framework. The optimization design of the lines of the underwater robot is carried out on an Isight platform, an automatic integration optimization platform. Through the platform, the optimization design of the lines and the analysis of the hydrodynamic performances can be achieved automatically with high efficiency. An autonomous underwater vehicle (AUV), SUBOFF, is taken as a verification model. For different lines, CFD calculation is performed to analyze the resistance and manoeuvrability. By comparison, the optimal lines of the hull and the fairwater are determined.},
  keywords = {Approximate model,Collaborative optimization,Hydrodynamic performance,Particle Swarm Optimization,Underwater robots}
}

@misc{metzGradientsAreNot2022,
  title = {Gradients Are {{Not All You Need}}},
  author = {Metz, Luke and Freeman, C. Daniel and Schoenholz, Samuel S. and Kachman, Tal},
  year = {2022},
  month = jan,
  number = {arXiv:2111.05803},
  eprint = {2111.05803},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2111.05803},
  urldate = {2023-05-15},
  abstract = {Differentiable programming techniques are widely used in the community and are responsible for the machine learning renaissance of the past several decades. While these methods are powerful, they have limits. In this short report, we discuss a common chaos based failure mode which appears in a variety of differentiable circumstances, ranging from recurrent neural networks and numerical physics simulation to training learned optimizers. We trace this failure to the spectrum of the Jacobian of the system under study, and provide criteria for when a practitioner might expect this failure to spoil their differentiation based optimization algorithms.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/4JVXKXLJ/Metz et al. - 2022 - Gradients are Not All You Need.pdf;/home/cbd/Zotero/storage/BW5X86GH/2111.html}
}

@misc{midgleyFlowAnnealedImportance2023,
  title = {Flow {{Annealed Importance Sampling Bootstrap}}},
  author = {Midgley, Laurence Illing and Stimper, Vincent and Simm, Gregor N. C. and Sch{\"o}lkopf, Bernhard and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2023},
  month = mar,
  number = {arXiv:2208.01893},
  eprint = {2208.01893},
  primaryclass = {cs, q-bio, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2208.01893},
  urldate = {2024-01-24},
  abstract = {Normalizing flows are tractable density models that can approximate complicated target distributions, e.g. Boltzmann distributions of physical systems. However, current methods for training flows either suffer from mode-seeking behavior, use samples from the target generated beforehand by expensive MCMC methods, or use stochastic losses that have high variance. To avoid these problems, we augment flows with annealed importance sampling (AIS) and minimize the mass-covering \${\textbackslash}alpha\$-divergence with \${\textbackslash}alpha=2\$, which minimizes importance weight variance. Our method, Flow AIS Bootstrap (FAB), uses AIS to generate samples in regions where the flow is a poor approximation of the target, facilitating the discovery of new modes. We apply FAB to multimodal targets and show that we can approximate them very accurately where previous methods fail. To the best of our knowledge, we are the first to learn the Boltzmann distribution of the alanine dipeptide molecule using only the unnormalized target density, without access to samples generated via Molecular Dynamics (MD) simulations: FAB produces better results than training via maximum likelihood on MD samples while using 100 times fewer target evaluations. After reweighting the samples, we obtain unbiased histograms of dihedral angles that are almost identical to the ground truth.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/7RFM2UFE/Midgley et al. - 2023 - Flow Annealed Importance Sampling Bootstrap.pdf;/home/cbd/Zotero/storage/ST2H6ZHJ/2208.html}
}

@article{mohaselafsharReflectionRefractionHamiltonian2015,
  title = {Reflection, {{Refraction}}, and {{Hamiltonian Monte Carlo}}},
  author = {Mohasel Afshar, Hadi and Domke, Justin},
  year = {2015},
  journal = {Advances in Neural Information Processing Systems},
  volume = {28},
  urldate = {2022-09-29},
  abstract = {Hamiltonian Monte Carlo (HMC) is a successful approach for sampling from continuous densities. However, it has difficulty simulating Hamiltonian dynamics with non-smooth functions, leading to poor performance. This paper is motivated by the behavior of Hamiltonian dynamics in physical systems like optics. We introduce a modification of the Leapfrog discretization of Hamiltonian dynamics on piecewise continuous energies, where intersections of the trajectory with disconti-nuities are detected, and the momentum is reflected or refracted to compensate for the change in energy. We prove that this method preserves the correct stationary distribution when boundaries are affine. Experiments show that by reducing the number of rejected samples, this method improves on traditional HMC.},
  file = {/home/cbd/Zotero/storage/H7JY7L3Y/full-text.pdf}
}

@inproceedings{molinaroNeuralInverseOperators2023,
  title = {Neural {{Inverse Operators}} for {{Solving PDE Inverse Problems}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Molinaro, Roberto and Yang, Yunan and Engquist, Bj{\"o}rn and Mishra, Siddhartha},
  year = {2023},
  month = jul,
  pages = {25105--25139},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2024-01-03},
  abstract = {A large class of inverse problems for PDEs are only well-defined as mappings from operators to functions. Existing operator learning frameworks map functions to functions and need to be modified to learn inverse maps from data. We propose a novel architecture termed Neural Inverse Operators (NIOs) to solve these PDE inverse problems. Motivated by the underlying mathematical structure, NIO is based on a suitable composition of DeepONets and FNOs to approximate mappings from operators to functions. A variety of experiments are presented to demonstrate that NIOs significantly outperform baselines and solve PDE inverse problems robustly, accurately and are several orders of magnitude faster than existing direct and PDE-constrained optimization methods.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/TBZZDXRM/Molinaro et al. - 2023 - Neural Inverse Operators for Solving PDE Inverse P.pdf}
}

@misc{mossBayesianSafetyValidation2023,
  title = {Bayesian {{Safety Validation}} for {{Black-Box Systems}}},
  author = {Moss, Robert J. and Kochenderfer, Mykel J. and Gariel, Maxime and Dubois, Arthur},
  year = {2023},
  month = may,
  number = {arXiv:2305.02449},
  eprint = {2305.02449},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.02449},
  urldate = {2023-06-12},
  abstract = {Accurately estimating the probability of failure for safety-critical systems is important for certification. Estimation is often challenging due to high-dimensional input spaces, dangerous test scenarios, and computationally expensive simulators; thus, efficient estimation techniques are important to study. This work reframes the problem of black-box safety validation as a Bayesian optimization problem and introduces an algorithm, Bayesian safety validation, that iteratively fits a probabilistic surrogate model to efficiently predict failures. The algorithm is designed to search for failures, compute the most-likely failure, and estimate the failure probability over an operating domain using importance sampling. We introduce a set of three acquisition functions that focus on reducing uncertainty by covering the design space, optimizing the analytically derived failure boundaries, and sampling the predicted failure regions. Mainly concerned with systems that only output a binary indication of failure, we show that our method also works well in cases where more output information is available. Results show that Bayesian safety validation achieves a better estimate of the probability of failure using orders of magnitude fewer samples and performs well across various safety validation metrics. We demonstrate the algorithm on three test problems with access to ground truth and on a real-world safety-critical subsystem common in autonomous flight: a neural network-based runway detection system. This work is open sourced and currently being used to supplement the FAA certification process of the machine learning components for an autonomous cargo aircraft.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Applications},
  file = {/home/cbd/Zotero/storage/RPNLLC2T/Moss et al. - 2023 - Bayesian Safety Validation for Black-Box Systems.pdf;/home/cbd/Zotero/storage/L6N2IUZA/2305.html}
}

@article{mrCausalityAidedFalsification2017,
  title = {Causality-{{Aided Falsification}}},
  author = {Akazaki, Takumi and Kumazawa, Yoshihiro and Hasuo, Ichiro},
  year = {2017},
  month = sep,
  journal = {Electronic Proceedings in Theoretical Computer Science},
  volume = {257},
  number = {Proc. FVAV 2017},
  pages = {3--18},
  publisher = {{Open Publishing Association}},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.257.2},
  urldate = {2022-11-14},
  abstract = {DOAJ is a unique and extensive index of diverse open access journals from around the world, driven by a growing community, committed to ensuring quality content is freely available online for everyone.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/IEDEFBV3/Mr et al. - 2017 - Causality-Aided Falsification.pdf}
}

@misc{MurrayTestimony,
  title = {Strengthening Airline Operations and Consumer Protections},
  author = {Murray, Casey},
  year = {2023},
  month = feb
}

@inproceedings{murthyGradSimDifferentiableSimulation2021,
  title = {{{gradSim}}: {{Differentiable}} Simulation for System Identification and Visuomotor Control},
  shorttitle = {{{gradSim}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Murthy, J. Krishna and Macklin, Miles and Golemo, Florian and Voleti, Vikram and Petrini, Linda and Weiss, Martin and Considine, Breandan and {Parent-L{\'e}vesque}, J{\'e}r{\^o}me and Xie, Kevin and Erleben, Kenny and Paull, Liam and Shkurti, Florian and Nowrouzezahrai, Derek and Fidler, Sanja},
  year = {2021},
  month = jan,
  urldate = {2023-05-15},
  abstract = {In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/Y22CTFBN/Murthy et al. - 2021 - gradSim Differentiable simulation for system iden.pdf}
}

@incollection{nealMCMCUsingHamiltonian2011,
  title = {{{MCMC Using Hamiltonian Dynamics}}},
  booktitle = {Handbook of {{Markov Chain Monte Carlo}}},
  author = {Neal, Radford M.},
  year = {2011},
  publisher = {{Chapman and Hall/CRC}},
  abstract = {Markov chain Monte Carlo (MCMC) originated with the classic paper of Metropolis et al. (1953), where it was used to simulate the distribution of states for a system of idealized molecules. Not long after, another approach tomolecular simulationwas introduced (Alder and Wainwright, 1959), in which the motion of the molecules was deterministic, following Newton's laws ofmotion,which have an elegant formalization asHamiltonian dynamics. For finding the properties of bulk materials, these approaches are asymptotically equivalent, since even in a deterministic simulation, each local region of the material experiences effectively random influences from distant regions. Despite the large overlap in their application areas, the MCMC and molecular dynamics approaches have continued to coexist in the following decades (see Frenkel and Smit, 1996). In 1987, a landmark paper by Duane, Kennedy, Pendleton, and Roweth united theMCMC and molecular dynamics approaches. They called their method ``hybrid Monte Carlo,'' which abbreviates to ``HMC,'' but the phrase ``Hamiltonian Monte Carlo,'' retaining the abbreviation, is more specific and descriptive, and I will use it here. Duane et al. applied HMC not to molecular simulation, but to lattice field theory simulations of quantum chromodynamics. Statistical applications of HMC began with my use of it for neural network models (Neal, 1996a). I also provided a statistically-oriented tutorial on HMC in a review of MCMC methods (Neal, 1993, Chapter 5). There have been other applications of HMC to statistical problems (e.g. Ishwaran, 1999; Schmidt, 2009) and statisticallyoriented reviews (e.g. Liu, 2001, Chapter 9), but HMC still seems to be underappreciated by statisticians, and perhaps also by physicists outside the lattice field theory community. This review begins by describing Hamiltonian dynamics. Despite terminology that maybe unfamiliar outside physics, the features of Hamiltonian dynamics that are needed for HMC are elementary. The differential equations of Hamiltonian dynamics must be discretized for computer implementation. The ``leapfrog'' scheme that is typically used is quite simple. Following this introduction to Hamiltonian dynamics, I describe how to use it to con-struct an MCMCmethod. The first step is to define a Hamiltonian function in terms of the probability distribution we wish to sample from. In addition to the variables we are interested in (the ``position'' variables), we must introduce auxiliary ``momentum'' variables, which typically have independent Gaussian distributions. The HMC method alternates simple updates for these momentum variables with Metropolis updates in which a new state is proposed by computing a trajectory according to Hamiltonian dynamics, implemented with the leapfrog method. A state proposed in this way can be distant from thethe exploration of the state space that occurs whenMetropolis updates are done using a simple random-walkproposal distribution. (Analternativewayof avoiding randomwalks is touse short trajectories but only partially replace the momentum variables between trajectories, so that successive trajectories tend to move in the same direction.) After presenting the basic HMCmethod, I discuss practical issues of tuning the leapfrogstepsize and number of leapfrog steps, as well as theoretical results on the scaling of HMC with dimensionality. I then present a number of variations on HMC. The acceptance rate for HMC can be increased for many problems by looking at ``windows'' of states at the beginning and end of the trajectory. For many statistical problems, approximate computation of trajectories (e.g. using subsets of the data) may be beneficial. Tuning of HMC can be made easier using a ``short-cut'' in which trajectories computed with a bad choice of stepsize take little computation time. Finally, ``tempering'' methods may be useful when multiple isolated modes exist.},
  isbn = {978-0-429-13850-8}
}

@misc{NeuralLanderStablea,
  title = {Neural {{Lander}}: {{Stable Drone Landing Control Using Learned Dynamics}} {\textbar} {{IEEE Conference Publication}} {\textbar} {{IEEE Xplore}}},
  urldate = {2024-01-22}
}

@inproceedings{NEURIPS2020_9332c513,
  title = {Instead of Rewriting Foreign Code for Machine Learning, Automatically Synthesize Fast Gradients},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Moses, William and Churavy, Valentin},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
  year = {2020},
  volume = {33},
  pages = {12472--12485},
  publisher = {{Curran Associates, Inc.}}
}

@article{nghiemMonteCarloTechniquesFalsification2010,
  title = {Monte-{{Carlo Techniques}} for {{Falsification}} of {{Temporal Properties}} of {{Non-Linear Hybrid Systems}}},
  author = {Nghiem, Truong and Sankaranarayanan, Sriram and Fainekos, Georgios and Gupta, Aarti and Pappas, George J},
  year = {2010},
  journal = {Proceedings of the 13th ACM international conference on Hybrid systems: computation and control - HSCC '10},
  publisher = {{ACM Press}},
  address = {{New York, New York, USA}},
  doi = {10.1145/1755952},
  urldate = {2022-10-18},
  abstract = {We present a Monte-Carlo optimization technique for finding inputs to a system that falsify a given Metric Temporal Logic (MTL) property. Our approach performs a random walk over the space of inputs guided by a robustness metric defined by the MTL property. Robustness can be used to guide our search for a falsifying trajec-tory by exploring trajectories with smaller robustness values. We show that the notion of robustness can be generalized to consider hybrid system trajectories. The resulting testing framework can be applied to non-linear hybrid systems with external inputs. We show through numerous experiments on complex systems that using our framework can help automatically falsify properties with more consistency as compared to other means such as uniform sampling.},
  isbn = {9781605589558},
  keywords = {G3 [Mathematics of Computing]: Probability and Statistics-Probabilistic algorithms (including Monte Carlo) General Terms Verification Keywords Hybrid Systems,Metric Temporal Logic,Robustness,Testing},
  file = {/home/cbd/Zotero/storage/JRPVHWYR/1755952.1755983.pdf}
}

@article{nishimuraDiscontinuousHamiltonianMonte2017,
  title = {Discontinuous {{Hamiltonian Monte Carlo}} for Discrete Parameters and Discontinuous Likelihoods},
  author = {Nishimura, Akihiko and Dunson, David and Lu, Jianfeng},
  year = {2017},
  month = may,
  journal = {Biometrika},
  volume = {107},
  number = {2},
  eprint = {1705.08510v5},
  pages = {365--380},
  publisher = {{Oxford University Press}},
  doi = {10.1093/biomet/asz083},
  urldate = {2022-09-29},
  abstract = {Hamiltonian Monte Carlo has emerged as a standard tool for posterior computation. In this article, we present an extension that can efficiently explore target distributions with discontinuous densities. Our extension in particular enables efficient sampling from ordinal parameters though embedding of probability mass functions into continuous spaces. We motivate our approach through a theory of discontinuous Hamiltonian dynamics and develop a corresponding numerical solver. The proposed solver is the first of its kind, with a remarkable ability to exactly preserve the Hamiltonian. We apply our algorithm to challenging posterior inference problems to demonstrate its wide applicability and competitive performance.},
  archiveprefix = {arxiv},
  keywords = {Bayesian inference,Geometric numerical integration,Markov chain Monte Carlo,Measure-valued differential equation},
  file = {/home/cbd/Zotero/storage/F3L2ICID/asz083.pdf;/home/cbd/Zotero/storage/RJDQIFCQ/1705.08510.pdf}
}

@misc{nist_ks,
  title = {Kolmogorov-Smirnov Goodness-of-Fit Test},
  publisher = {{NIST}}
}

@inproceedings{okellyScalableEndtoEndAutonomous2018,
  title = {Scalable {{End-to-End Autonomous Vehicle Testing}} via {{Rare-event Simulation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {O' Kelly, Matthew and Sinha, Aman and Namkoong, Hongseok and Tedrake, Russ and Duchi, John C},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-14},
  abstract = {While recent developments in autonomous vehicle (AV) technology highlight substantial progress, we lack tools for rigorous and scalable testing. Real-world testing, the de facto evaluation environment, places the public in danger, and, due to the rare nature of accidents, will require billions of miles in order to statistically validate performance claims. We implement a simulation framework that can test an entire modern autonomous driving system, including, in particular, systems that employ deep-learning perception and control algorithms. Using adaptive importance-sampling methods to accelerate rare-event probability evaluation, we estimate the probability of an accident under a base distribution governing standard traffic behavior. We demonstrate our framework on a highway scenario, accelerating system evaluation by 2-20 times over naive Monte Carlo sampling methods and 10-300P times (where P is the number of processors) over real-world testing.},
  keywords = {00-read,00-relevant},
  file = {/home/cbd/Zotero/storage/HX2GSLDL/O' Kelly et al. - 2018 - Scalable End-to-End Autonomous Vehicle Testing via.pdf}
}

@inproceedings{oldewageAdversarialAttacksAre2022,
  title = {Adversarial {{Attacks}} Are a {{Surprisingly Strong Baseline}} for {{Poisoning Few-Shot Meta-Learners}}},
  booktitle = {I {{Can}}'t {{Believe It}}'s {{Not Better Workshop}}: {{Understanding Deep Learning Through Empirical Falsification}}},
  author = {Oldewage, Elre Talea and Bronskill, John F. and Turner, Richard E.},
  year = {2022},
  month = dec,
  urldate = {2023-03-14},
  abstract = {This paper examines the robustness of deployed few-shot meta-learning systems when they are fed an imperceptibly perturbed few-shot dataset. We attack amortized meta-learners, which allows us to craft colluding sets of inputs that are tailored to fool the system's learning algorithm when used as training data. Jointly crafted adversarial inputs might be expected to synergistically manipulate a classifier, allowing for very strong data-poisoning attacks that would be hard to detect. We show that in a white box setting, these attacks are very successful and can cause the target model's predictions to become worse than chance. However, in opposition to the well-known transferability of adversarial examples in general, the colluding sets do not transfer well to different classifiers. We explore two hypotheses to explain this: 'overfitting' by the attack, and mismatch between the model on which the attack is generated and that to which the attack is transferred. Regardless of the mitigation strategies suggested by these hypotheses, the colluding inputs transfer no better than adversarial inputs that are generated independently in the usual way.},
  langid = {english},
  keywords = {00-read},
  file = {/home/cbd/Zotero/storage/3UVQLVBK/Oldewage et al. - 2022 - Adversarial Attacks are a Surprisingly Strong Base.pdf}
}

@inproceedings{olson2011tags,
  title = {{{AprilTag}}: {{A}} Robust and Flexible Visual Fiducial System},
  booktitle = {Proceedings of the {{IEEE}} International Conference on Robotics and Automation ({{ICRA}})},
  author = {Olson, Edwin},
  year = {2011},
  month = may,
  pages = {3400--3407},
  publisher = {{IEEE}},
  keywords = {ARToolkit,Robot navigation,SLAM,Visual Fiducial}
}

@article{omnesAdversarialTrainingContinuous2021,
  title = {Adversarial {{Training}} for a {{Continuous Robustness Control Problem}} in {{Power Systems}}},
  author = {Omnes, Loic and Marot, Antoine and Donnot, Benjamin},
  year = {2021},
  month = jun,
  journal = {2021 IEEE Madrid PowerTech, PowerTech 2021 - Conference Proceedings},
  eprint = {2012.11390},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/POWERTECH46648.2021.9494982},
  urldate = {2022-10-18},
  abstract = {We propose a new adversarial training approach for injecting robustness when designing controllers for upcoming cyber-physical power systems. Previous approaches relying deeply on simulations are not able to cope with the rising complexity and are too costly when used online in terms of computation budget. In comparison, our method proves to be computationally efficient online while displaying useful robustness properties. To do so we model an adversarial framework, propose the implementation of a fixed opponent policy and test it on a L2RPN (Learning to Run a Power Network) environment. This environment is a synthetic but realistic modeling of a cyber-physical system accounting for one third of the IEEE 118 grid. Using adversarial testing, we analyze the results of submitted trained agents from the robustness track of the L2RPN competition. We then further assess the performance of these agents in regards to the continuous N-1 problem through tailored evaluation metrics. We discover that some agents trained in an adversarial way demonstrate interesting preventive behaviors in that regard, which we discuss.},
  archiveprefix = {arxiv},
  isbn = {9781665435970},
  keywords = {adversarial,control,power system,robustness},
  file = {/home/cbd/Zotero/storage/BXKE2WWX/2012.11390.pdf}
}

@article{ongieDeepLearningTechniques2020,
  title = {Deep {{Learning Techniques}} for {{Inverse Problems}} in {{Imaging}}},
  author = {Ongie, Gregory and Jalal, Ajil and Metzler, Christopher A. and Baraniuk, Richard G. and Dimakis, Alexandros G. and Willett, Rebecca},
  year = {2020},
  month = may,
  journal = {IEEE Journal on Selected Areas in Information Theory},
  volume = {1},
  number = {1},
  pages = {39--56},
  issn = {2641-8770},
  doi = {10.1109/JSAIT.2020.2991563},
  urldate = {2024-01-04},
  abstract = {Recent work in machine learning shows that deep neural networks can be used to solve a wide variety of inverse problems arising in computational imaging. We explore the central prevailing themes of this emerging area and present a taxonomy that can be used to categorize different problems and reconstruction methods. Our taxonomy is organized along two central axes: (1) whether or not a forward model is known and to what extent it is used in training and testing, and (2) whether or not the learning is supervised or unsupervised, i.e., whether or not the training relies on access to matched ground truth image and measurement pairs. We also discuss the tradeoffs associated with these different reconstruction approaches, caveats and common failure modes, plus open problems and avenues for future work.},
  file = {/home/cbd/Zotero/storage/63V3NI6V/Ongie et al. - 2020 - Deep Learning Techniques for Inverse Problems in I.pdf}
}

@article{onkenOTFlowFastAccurate2021,
  title = {{{OT-Flow}}: {{Fast}} and {{Accurate Continuous Normalizing Flows}} via {{Optimal Transport}}},
  shorttitle = {{{OT-Flow}}},
  author = {Onken, Derek and Fung, Samy Wu and Li, Xingjian and Ruthotto, Lars},
  year = {2021},
  month = may,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {35},
  number = {10},
  pages = {9223--9232},
  issn = {2374-3468},
  doi = {10.1609/aaai.v35i10.17113},
  urldate = {2024-01-26},
  abstract = {A normalizing flow is an invertible mapping between an arbitrary probability distribution and a standard normal distribution; it can be used for density estimation and statistical inference. Computing the flow follows the change of variables formula and thus requires invertibility of the mapping and an efficient way to compute the determinant of its Jacobian. To satisfy these requirements, normalizing flows typically consist of carefully chosen components. Continuous normalizing flows (CNFs) are mappings obtained by solving a neural ordinary differential equation (ODE). The neural ODE's dynamics can be chosen almost arbitrarily while ensuring invertibility. Moreover, the log-determinant of the flow's Jacobian can be obtained by integrating the trace of the dynamics' Jacobian along the flow. Our proposed OT-Flow approach tackles two critical computational challenges that limit a more widespread use of CNFs. First, OT-Flow leverages optimal transport (OT) theory to regularize the CNF and enforce straight trajectories that are easier to integrate. Second, OT-Flow features exact trace computation with time complexity equal to trace estimators used in existing CNFs. On five high-dimensional density estimation and generative modeling tasks, OT-Flow performs competitively to state-of-the-art CNFs while on average requiring one-fourth of the number of weights with an 8x speedup in training time and 24x speedup in inference.},
  copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {Neural Generative Models & Autoencoders},
  file = {/home/cbd/Zotero/storage/XZYIMU3I/Onken et al. - 2021 - OT-Flow Fast and Accurate Continuous Normalizing .pdf}
}

@article{pantazidesSatelliteMissionPlanning2022,
  title = {Satellite {{Mission Planning}} with {{Signal Temporal Logic Specifications}}},
  author = {Pantazides, Athanasios and Aksaray, Derya and {Gebre-egziabher}, Demoz},
  year = {2022},
  month = jan,
  publisher = {{American Institute of Aeronautics and Astronautics (AIAA)}},
  doi = {10.2514/6.2022-1091},
  urldate = {2022-02-14},
  abstract = {Satellites in low-Earth orbit have complex missions involving various time-dependent attitude requirements. For instance, a satellite must point an antenna toward a ground station to communicate with Earth and point its solar panels toward the Sun to collect power. At the same time, the mission of a satellite may make certain attitudes desirable or unacceptable. These complex constraints on a satellite's control design can be dealt with succinctly by Signal Temporal Logic (STL) specifications. In this work, we leverage the robustness degree metric on STL expressions---quantifying the degree to which an STL specification is satisfied by a signal--- and formulate an optimization problem that maximizes the robustness degree to generate control trajectories for the small satellite IMPRESS. We utilize the smooth approximation of robustness degree and use a gradient-based optimization framework to generate these control trajectories. The proposed approach is validated on simulated data for a mission scenario involving communication with ground stations and maintaining onboard power.},
  isbn = {9781624106316},
  keywords = {control,optimization,stl},
  file = {/home/cbd/Zotero/storage/DQHKBFIU/full-text.pdf}
}

@article{pantFlybyLogicControlMultiDrone2018,
  title = {Fly-by-{{Logic}}: {{Control}} of {{Multi-Drone Fleets}} with {{Temporal Logic Objectives}}},
  author = {Pant, Yash Vardhan and Abbas, Houssam and Quaye, Rhudii A. and Mangharam, Rahul},
  year = {2018},
  month = aug,
  journal = {Proceedings - 9th ACM/IEEE International Conference on Cyber-Physical Systems, ICCPS 2018},
  pages = {186--197},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/ICCPS.2018.00026},
  urldate = {2022-02-14},
  abstract = {The problem of safe planning and control for multi-drone systems across a variety of missions is of critical importance, as the scope of tasks assigned to such systems increases. In this paper, we present an approach to solve this problem for multi-quadrotor missions. Given a mission expressed in Signal Temporal Logic (STL), our controller maximizes robustness to generate trajectories for the quadrotors that satisfy the STL specification in continuous-time. We also show that the constraints on our optimization guarantees that these trajectories can be tracked nearly perfectly by lower level off-the-shelf position and attitude controllers. Our approach avoids the oversimplifying abstractions found in many planning methods, while retaining the expressiveness of missions encoded in STL allowing us to handle complex spatial, temporal and reactive requirements. Through experiments, both in simulation and on actual quadrotors, we show the performance, scalability and real-time applicability of our method.},
  isbn = {9781538653012},
  keywords = {crazyflie,Mulit drone missions,optimization,predictive control,robustness maximization,signal temporal logic,stl,to_read},
  file = {/home/cbd/Zotero/storage/Y9H7734I/full-text.pdf}
}

@article{pantSmoothOperatorControl2017,
  title = {Smooth {{Operator}}: {{Control}} Using the {{Smooth Robustness}} of {{Temporal Logic}}},
  author = {Pant, Yash Vardhan and Abbas, Houssam and Mangharam, Rahul},
  year = {2017},
  month = aug,
  journal = {IEEE Conference on Control Technology and Applications, 2017},
  urldate = {2022-02-28},
  keywords = {stl},
  file = {/home/cbd/Zotero/storage/EWN2EUNS/Smooth Operator Control using the Smooth Robustness of Temporal.pdf}
}

@article{papamakariosNormalizingFlowsProbabilistic2021,
  title = {Normalizing Flows for Probabilistic Modeling and Inference},
  author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  year = {2021},
  month = jan,
  journal = {The Journal of Machine Learning Research},
  volume = {22},
  number = {1},
  pages = {57:2617--57:2680},
  issn = {1532-4435},
  abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
  keywords = {generative models,invertible neural networks,normalizing flows,probabilistic inference,probabilistic modeling},
  file = {/home/cbd/Zotero/storage/48PU34EA/Papamakarios et al. - 2021 - Normalizing flows for probabilistic modeling and i.pdf}
}

@misc{papernotTransferabilityMachineLearning2016,
  title = {Transferability in {{Machine Learning}}: {{From Phenomena}} to {{Black-Box Attacks}} Using {{Adversarial Samples}}},
  shorttitle = {Transferability in {{Machine Learning}}},
  author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian},
  year = {2016},
  month = may,
  number = {arXiv:1605.07277},
  eprint = {1605.07277},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1605.07277},
  urldate = {2023-03-17},
  abstract = {Many machine learning models are vulnerable to adversarial examples: inputs that are specially crafted to cause a machine learning model to produce an incorrect output. Adversarial examples that affect one model often affect another model, even if the two models have different architectures or were trained on different training sets, so long as both models were trained to perform the same task. An attacker may therefore train their own substitute model, craft adversarial examples against the substitute, and transfer them to a victim model, with very little information about the victim. Recent work has further developed a technique that uses the victim model as an oracle to label a synthetic training set for the substitute, so the attacker need not even collect a training set to mount the attack. We extend these recent techniques using reservoir sampling to greatly enhance the efficiency of the training procedure for the substitute model. We introduce new transferability attacks between previously unexplored (substitute, victim) pairs of machine learning model classes, most notably SVMs and decision trees. We demonstrate our attacks on two commercial machine learning classification systems from Amazon (96.19\% misclassification rate) and Google (88.94\%) using only 800 queries of the victim model, thereby showing that existing machine learning approaches are in general vulnerable to systematic black-box attacks regardless of their structure.},
  archiveprefix = {arxiv},
  keywords = {00-read,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@inproceedings{patacchiolaBayesianMetaLearningFewShot2020,
  title = {Bayesian {{Meta-Learning}} for the {{Few-Shot Setting}} via {{Deep Kernels}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Patacchiola, Massimiliano and Turner, Jack and Crowley, Elliot J. and O' Boyle, Michael and Storkey, Amos J},
  year = {2020},
  volume = {33},
  pages = {16108--16118},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2024-01-30},
  abstract = {Recently, different machine learning methods have been introduced to tackle the challenging few-shot learning scenario that is, learning from a small labeled dataset related to a specific task. Common approaches have taken the form of meta-learning: learning to learn on the new problem given the old. Following the recognition that meta-learning is implementing learning in a multi-level model, we present a Bayesian treatment for the meta-learning inner loop through the use of deep kernels. As a result we can learn a kernel that transfers to new tasks; we call this Deep Kernel Transfer (DKT). This approach has many advantages: is straightforward to implement as a single optimizer, provides uncertainty quantification, and does not require estimation of task-specific parameters. We empirically demonstrate that DKT outperforms several state-of-the-art algorithms in few-shot classification, and is the state of the art for cross-domain adaptation and regression. We conclude that complex meta-learning routines can be replaced by a simpler Bayesian model without loss of accuracy.},
  file = {/home/cbd/Zotero/storage/8FV752T4/Patacchiola et al. - 2020 - Bayesian Meta-Learning for the Few-Shot Setting vi.pdf}
}

@article{plakuMotionPlanningTemporallogic2016,
  title = {Motion Planning with Temporal-Logic Specifications: {{Progress}} and Challenges},
  author = {Plaku, Erion and Karaman, Sertac},
  year = {2016},
  month = jan,
  journal = {AI Communications},
  volume = {29},
  number = {1},
  pages = {151--162},
  publisher = {{IOS Press}},
  issn = {0921-7126},
  doi = {10.3233/AIC-150682},
  urldate = {2022-02-07},
  abstract = {Integrating task and motion planning is becoming increasingly important due to the recognition that a growing number of robotics applications in navigation, search-and-rescue missions, manipulation, and medicine involve reasoning with both discrete abstractions and continuous motions. The problem poses unique computational challenges: a vast hybrid discrete/continuous space must be searched while accounting for complex geometries, motion dynamics, collision avoidance and temporal goals. This paper takes the position that continued progress relies on integrative approaches that bring together techniques from robotics and AI. In this context, the paper examines robot motion planning with temporal-logic specifications and discusses open challenges and directions for future research. The paper aims to promote a continuing dialog between robotics and AI communities.},
  keywords = {discrete search,motion planning,sampling-based algorithm,stl,survey,tamp,Task planning,temporal logic},
  file = {/home/cbd/Zotero/storage/HKWY2P3Q/PaperAICom15.pdf}
}

@article{posadaEA22002Autopilot,
  title = {{{EA}} 22-002: {{Autopilot}} \& {{First Responder Scenes}}},
  author = {Posada, Steven},
  journal = {US DOT NHTSA}
}

@misc{ProbabilistsZuko2024,
  title = {Probabilists/{{Zuko}}},
  year = {2024},
  month = jan,
  urldate = {2024-02-01},
  abstract = {Normalizing flows in PyTorch},
  copyright = {MIT},
  howpublished = {The Probabilists},
  keywords = {deep-learning,density-estimation,generative-model,normalizing-flows,probability,torch}
}

@article{pyrgiotisModellingDelayPropagation2013,
  title = {Modelling Delay Propagation within an Airport Network},
  author = {Pyrgiotis, Nikolas and Malone, Kerry M. and Odoni, Amedeo},
  year = {2013},
  month = feb,
  journal = {Transportation Research Part C: Emerging Technologies},
  series = {Selected Papers from the {{Seventh Triennial Symposium}} on {{Transportation Analysis}} ({{TRISTAN VII}})},
  volume = {27},
  pages = {60--75},
  issn = {0968-090X},
  doi = {10.1016/j.trc.2011.05.017},
  urldate = {2024-01-20},
  abstract = {We describe an analytical queuing and network decomposition model developed to study the complex phenomenon of the propagation of delays within a large network of major airports. The Approximate Network Delays (AND) model computes the delays due to local congestion at individual airports and captures the ``ripple effect'' that leads to the propagation of these delays. The model operates by iterating between its two main components: a queuing engine (QE) that computes delays at individual airports and a delay propagation algorithm (DPA) that updates flight schedules and demand rates at all the airports in the model in response to the local delays computed by the QE. The QE is a stochastic and dynamic queuing model that treats each airport in the network as a M(t)/Ek(t)/1 queuing system. The AND model is very fast computationally, thus making possible the exploration at a macroscopic level of the impacts of a large number of scenarios and policy alternatives on system-wide delays. It has been applied to a network consisting of the 34 busiest airports in the continental United States and provides insights into the interactions through which delays propagate through the network and the often-counterintuitive consequences. Delay propagation tends to ``smoothen'' daily airport demand profiles and push more demands into late evening hours. Such phenomena are especially evident at hub airports, where some flights may benefit considerably (by experiencing reduced delays) from the changes that occur in the scheduled demand profile as a result of delays and delay propagation.},
  keywords = {Airport delays,Delay propagation,Network of airports}
}

@incollection{pytorch,
  title = {{{PyTorch}}: {{An}} Imperative Style, High-Performance Deep Learning Library},
  booktitle = {Advances in Neural Information Processing Systems 32},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and {dAlch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  pages = {8024--8035},
  publisher = {{Curran Associates, Inc.}}
}

@inproceedings{qiDryVRToolVerification2018,
  title = {{{DryVR}} 2.0: {{A}} Tool for Verification and Controller Synthesis of Black-Box Cyber-Physical Systems},
  shorttitle = {{{DryVR}} 2.0},
  booktitle = {Proceedings of the 21st {{International Conference}} on {{Hybrid Systems}}: {{Computation}} and {{Control}} (Part of {{CPS Week}})},
  author = {Qi, Bolun and Fan, Chuchu and Jiang, Minghao and Mitra, Sayan},
  year = {2018},
  month = apr,
  series = {{{HSCC}} '18},
  pages = {269--270},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3178126.3187008},
  urldate = {2023-02-07},
  abstract = {We present a demo of DryVR 2.0, a framework for verification and controller synthesis of cyber-physical systems composed of black-box simulators and white-box automata. For verification, DryVR 2.0 takes as input a black-box simulator, a white-box transition graph, a time bound and a safety specification. As output it generates over-approximations of the reachable states and returns "Safe" if the system meets the given bounded safety specification, or it returns "Unsafe" with a counter-example. For controller synthesis, DryVR 2.0 takes as input black-box simulator(s) and a reach-avoid specification, and uses RRTs to find a transition graph such that the combined system satisfies the given specification.},
  isbn = {978-1-4503-5642-8},
  file = {/home/cbd/Zotero/storage/KTHITQ7E/Qi et al. - 2018 - DryVR 2.0 A tool for verification and controller .pdf}
}

@article{qinStatisticalVerificationCyberPhysical2022,
  title = {Statistical {{Verification}} of {{Cyber-Physical Systems}} Using {{Surrogate Models}} and {{Conformal Inference}}},
  author = {Qin, Xin and Xian, Yuan and Zutshi, Aditya and Fan, Chuchu and Deshmukh, Jyotirmoy V.},
  year = {2022},
  journal = {Proceedings - 13th ACM/IEEE International Conference on Cyber-Physical Systems, ICCPS 2022},
  pages = {116--126},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/ICCPS54341.2022.00017},
  urldate = {2022-10-03},
  abstract = {Uncertainty in safety-critical cyber-physical systems can be modeled using a finite number of parameters or input signals. Given a system specification in Signal Temporal Logic (STL), we would like to verify that for all (infinite) values of the model parameters/input signals, the system satisfies its specification. Unfortunately, this problem is undecidable in general. Statistical model checking (SMC) offers a solution by providing guarantees on the correctness of CPS models by statistically reasoning on model simulations. We propose a new approach for statistical verification of CPS models for user-provided distribution on the model parameters. Our technique uses model simulations to learn surrogate models, and uses conformal inference to provide probabilistic guarantees on the satisfaction of a given STL property. Additionally, we can provide prediction intervals containing the quantitative satisfaction values of the given STL property for any user-specified confidence level. We also propose a refinement procedure based on Gaussian Process (GP)-based surrogate models for obtaining fine-grained probabilistic guarantees over sub-regions in the parameter space. This in turn enables the CPS designer to choose assured validity domains in the parameter space for safety-critical applications. Finally, we demonstrate the efficacy of our technique on several CPS models.},
  isbn = {9781665409674},
  file = {/home/cbd/Zotero/storage/46ED2QSV/full-text.pdf}
}

@article{rahimianDistributionallyRobustOptimization2022,
  title = {Distributionally {{Robust Optimization}}: {{A Review}}},
  shorttitle = {Distributionally {{Robust Optimization}}},
  author = {Rahimian, Hamed and Mehrotra, Sanjay},
  year = {2022},
  month = jul,
  journal = {Open Journal of Mathematical Optimization},
  volume = {3},
  eprint = {1908.05659},
  primaryclass = {cs, math, stat},
  pages = {1--85},
  issn = {2777-5860},
  doi = {10.5802/ojmo.15},
  urldate = {2023-08-08},
  abstract = {The concepts of risk-aversion, chance-constrained optimization, and robust optimization have developed significantly over the last decade. Statistical learning community has also witnessed a rapid theoretical and applied growth by relying on these concepts. A modeling framework, called distributionally robust optimization (DRO), has recently received significant attention in both the operations research and statistical learning communities. This paper surveys main concepts and contributions to DRO, and its relationships with robust optimization, risk-aversion, chance-constrained optimization, and function regularization.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/W4H37753/Rahimian and Mehrotra - 2022 - Distributionally Robust Optimization A Review.pdf;/home/cbd/Zotero/storage/HSK97XE6/1908.html}
}

@inproceedings{raman15,
  title = {Reactive Synthesis from Signal Temporal Logic Specifications},
  booktitle = {Proceedings of the 18th International Conference on Hybrid Systems: {{Computation}} and Control},
  author = {Raman, Vasumathi and Donz{\'e}, Alexandre and Sadigh, Dorsa and Murray, Richard M. and Seshia, Sanjit A.},
  year = {2015},
  series = {{{HSCC}} '15},
  pages = {239--248},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2728606.2728628},
  abstract = {We present a counterexample-guided inductive synthesis approach to controller synthesis for cyber-physical systems subject to signal temporal logic (STL) specifications, operating in potentially adversarial nondeterministic environments. We encode STL specifications as mixed integer-linear constraints on the variables of a discrete-time model of the system and environment dynamics, and solve a series of optimization problems to yield a satisfying control sequence. We demonstrate how the scheme can be used in a receding horizon fashion to fulfill properties over unbounded horizons, and present experimental results for reactive controller synthesis for case studies in building climate control and autonomous driving.},
  isbn = {978-1-4503-3433-4}
}

@inproceedings{ramdasDecreasingPowerKernel2015,
  title = {On the Decreasing Power of Kernel and Distance Based Nonparametric Hypothesis Tests in High Dimensions},
  booktitle = {Proceedings of the {{Twenty-Ninth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Ramdas, Aaditya and Reddi, Sashank J. and P{\'o}czos, Barnab{\'a}s and Singh, Aarti and Wasserman, Larry},
  year = {2015},
  month = jan,
  series = {{{AAAI}}'15},
  pages = {3571--3577},
  publisher = {{AAAI Press}},
  address = {{Austin, Texas}},
  urldate = {2024-01-24},
  abstract = {This paper is about two related decision theoretic problems, nonparametric two-sample testing and independence testing. There is a belief that two recently proposed solutions, based on kernels and distances between pairs of points, behave well in high-dimensional settings. We identify different sources of misconception that give rise to the above belief. Specifically, we differentiate the hardness of estimation of test statistics from the hardness of testing whether these statistics are zero or not, and explicitly discuss a notion of "fair" alternative hypotheses for these problems as dimension increases. We then demonstrate that the power of these tests actually drops polynomially with increasing dimension against fair alternatives. We end with some theoretical insights and shed light on the median heuristic for kernel bandwidth selection. Our work advances the current understanding of the power of modern nonpara-metric hypothesis tests in high dimensions.},
  isbn = {978-0-262-51129-2}
}

@article{randomized_smoothing_1,
  title = {Randomized Smoothing for Stochastic Optimization},
  author = {Duchi, John C. and Bartlett, Peter L. and Wainwright, Martin J.},
  year = {2012},
  journal = {SIAM Journal on Optimization},
  volume = {22},
  number = {2},
  pages = {674--701},
  doi = {10.1137/110831659}
}

@inproceedings{rempeGeneratingUsefulAccidentProne2022,
  title = {Generating {{Useful Accident-Prone Driving Scenarios}} via a {{Learned Traffic Prior}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Rempe, Davis and Philion, Jonah and Guibas, Leonidas J. and Fidler, Sanja and Litany, Or},
  year = {2022},
  pages = {17305--17315},
  urldate = {2023-03-14},
  langid = {english},
  keywords = {00-read,00-relevant,gradient-based optimization,proxy models},
  file = {/home/cbd/Zotero/storage/ZZXEHKZF/Rempe et al. - 2022 - Generating Useful Accident-Prone Driving Scenarios.pdf}
}

@inproceedings{rezendeStochasticBackpropagationApproximate2014,
  title = {Stochastic {{Backpropagation}} and {{Approximate Inference}} in {{Deep Generative Models}}},
  booktitle = {Proceedings of the 31st {{International Conference}} on {{Machine Learning}}},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  year = {2014},
  month = jun,
  pages = {1278--1286},
  publisher = {{PMLR}},
  issn = {1938-7228},
  urldate = {2024-01-04},
  abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent an approximate posterior distribution and uses this for optimisation of a variational lower bound. We develop stochastic backpropagation -- rules for gradient backpropagation through stochastic variables -- and derive an algorithm that allows for joint optimisation of the parameters of both the generative and recognition models. We demonstrate on several real-world data sets that by using stochastic backpropagation and variational inference, we obtain models that are able to generate realistic samples of data, allow for accurate imputations of missing data, and provide a useful tool for high-dimensional data visualisation.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/ZYZ7A6V8/Rezende et al. - 2014 - Stochastic Backpropagation and Approximate Inferen.pdf}
}

@inproceedings{rezendeVariationalInferenceNormalizing2015,
  title = {Variational Inference with Normalizing Flows},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{International Conference}} on {{Machine Learning}} - {{Volume}} 37},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
  year = {2015},
  month = jul,
  series = {{{ICML}}'15},
  pages = {1530--1538},
  publisher = {{JMLR.org}},
  address = {{Lille, France}},
  urldate = {2024-01-06},
  abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.}
}

@misc{richardsonDeepwave2023,
  title = {Deepwave},
  author = {Richardson, Alan},
  year = {2023},
  month = sep,
  doi = {10.5281/zenodo.8381177},
  urldate = {2024-01-17},
  abstract = {Deepwave provides wave propagation modules for PyTorch, for applications such as seismic imaging/inversion. You can use it to perform forward modelling and backpropagation, so it can simulate wave propagation to generate synthetic data, invert for the scattering potential (RTM/LSRTM), other model parameters (FWI), initial wavefields, or source wavelets. You can use it to integrate wave propagation into a larger chain of operations with end-to-end forward and backpropagation. Deepwave enables you to easily experiment with your own objective functions or functions that generate the inputs to the propagator, letting PyTorch's automatic differentiation do the hard work of calculating how to backpropagate through them. To install it, I recommend first installing PyTorch using the instructions on the PyTorch website. Deepwave can then be installed using pip install deepwave The documentation contains examples and instructions on how to install and use Deepwave. You might also like to watch a video summary of Deepwave.   Features Supports the 2D constant density acoustic / scalar wave equation (regular and Born modelling) and 2D elastic wave equation (P-SV) Runs on CPUs and appropriate GPUs The gradient of all outputs (final wavefields and receiver data) can be calculated with respect to the model parameters (wavespeed, scattering potential, etc.), initial wavefields, and source amplitudes Uses the Pasalic and McGarry PML for accurate absorbing boundaries in the scalar wave propagator Uses C-PML with the W-AFDA free-surface method for the elastic wave propagator The PML width for each edge can be set independently, allowing a free surface (no PML) on any side Finite difference accuracy can be set by the user A region of the model around the sources and receivers currently being propagated can be automatically extracted to avoid the unnecessary computation of propagation in distant parts of the model Double backpropagation through the regular scalar propagator, including calculating the Hessian Quick Example In a few lines you can make a velocity model, propagate a wave from a source in the top left corner to a receiver in the top right, calculate an objective function, and backpropagate to obtain its gradient with respect to the velocity. import torch import deepwave import matplotlib.pyplot as plt v = 1500 * torch.ones(100, 100) v[50:] = 2000 v.requires\_grad\_() out = deepwave.scalar( v, grid\_spacing=4, dt=0.004, source\_amplitudes=deepwave.wavelets.ricker(25, 200, 0.004, 0.06).reshape(1, 1, -1), source\_locations=torch.tensor([[[0, 0]]]), receiver\_locations=torch.tensor([[[0, 99]]]) ) (out[-1]**2).sum().backward() \_, ax = plt.subplots(1, 3, figsize=(9, 3)) ax[0].imshow(v.detach()) ax[0].set\_title("Velocity model") ax[1].plot(out[-1].detach().flatten()) ax[1].set\_title("Receiver data") ax[2].imshow(v.grad.detach(), vmin=-1e-5, vmax=1e-5) ax[2].set\_title("Gradient") There are more examples in the documentation.},
  howpublished = {Zenodo},
  keywords = {full waveform inversion,fwi,geophysics,least squares reverse time migration,lsrtm,pytorch,seismic,wave propagation}
}

@misc{richardsonSeismicFullWaveformInversion2018,
  title = {Seismic {{Full-Waveform Inversion Using Deep Learning Tools}} and {{Techniques}}},
  author = {Richardson, Alan},
  year = {2018},
  month = jan,
  number = {arXiv:1801.07232},
  eprint = {1801.07232},
  primaryclass = {physics},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1801.07232},
  urldate = {2024-01-17},
  abstract = {I demonstrate that the conventional seismic full-waveform inversion algorithm can be constructed as a recurrent neural network and so implemented using deep learning software such as TensorFlow. Applying another deep learning concept, the Adam optimizer with minibatches of data, produces quicker convergence toward the true wave speed model on a 2D dataset than Stochastic Gradient Descent and than the L-BFGS-B optimizer with the cost function and gradient computed using the entire training dataset. I also show that the cost function gradient calculation using reverse-mode automatic differentiation is the same as that used in the adjoint state method.},
  archiveprefix = {arxiv},
  keywords = {Physics - Computational Physics,Physics - Geophysics},
  file = {/home/cbd/Zotero/storage/7M8NGPIA/Richardson - 2018 - Seismic Full-Waveform Inversion Using Deep Learnin.pdf;/home/cbd/Zotero/storage/RABEAMCX/1801.html}
}

@article{riedmaierSurveyScenarioBasedSafety2020,
  title = {Survey on {{Scenario-Based Safety Assessment}} of {{Automated Vehicles}}},
  author = {Riedmaier, Stefan and Ponn, Thomas and Ludwig, Dieter and Schick, Bernhard and Diermeyer, Frank},
  year = {2020},
  journal = {IEEE access : practical innovations, open solutions},
  volume = {8},
  pages = {87456--87477},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2993730},
  abstract = {When will automated vehicles come onto the market? This question has puzzled the automotive industry and society for years. The technology and its implementation have made rapid progress over the last decade, but the challenge of how to prove the safety of these systems has not yet been solved. Since a market launch without proof of safety would neither be accepted by society nor by legislators, much time and many resources have been invested into safety assessment in recent years in order to develop new approaches for an efficient assessment. This paper therefore provides an overview of various approaches, and gives a comprehensive survey of the so-called scenario-based approach. The scenario-based approach is a promising method, in which individual traffic situations are typically tested by means of virtual simulation. Since an infinite number of different scenarios can theoretically occur in real-world traffic, even the scenario-based approach leaves the question unanswered as to how to break these down into a finite set of scenarios, and find those which are representative in order to render testing more manageable. This paper provides a comprehensive literature review of related safety-assessment publications that deal precisely with this question. Therefore, this paper develops a novel taxonomy for the scenario-based approach, and classifies all literature sources. Based on this, the existing methods will be compared with each other and, as one conclusion, the alternative concept of formal verification will be combined with the scenario-based approach. Finally, future research priorities are derived.},
  keywords = {00-read,00-relevant,Automated vehicles,Automation,autonomous vehicles,Bibliographies,data analysis,formal verification,intelligent vehicles,key performance indicators,Microscopy,Safety,simulation,Taxonomy,Testing,vehicle safety,Vehicles},
  file = {/home/cbd/Zotero/storage/39NMLKP8/Riedmaier et al. - 2020 - Survey on Scenario-Based Safety Assessment of Auto.pdf;/home/cbd/Zotero/storage/T6BXRTXR/9090897.html}
}

@misc{ritchieDeepAmortizedInference2016,
  title = {Deep {{Amortized Inference}} for {{Probabilistic Programs}}},
  author = {Ritchie, Daniel and Horsfall, Paul and Goodman, Noah D.},
  year = {2016},
  month = oct,
  number = {arXiv:1610.05735},
  eprint = {1610.05735},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1610.05735},
  urldate = {2024-01-03},
  abstract = {Probabilistic programming languages (PPLs) are a powerful modeling tool, able to represent any computable probability distribution. Unfortunately, probabilistic program inference is often intractable, and existing PPLs mostly rely on expensive, approximate sampling-based methods. To alleviate this problem, one could try to learn from past inferences, so that future inferences run faster. This strategy is known as amortized inference; it has recently been applied to Bayesian networks and deep generative models. This paper proposes a system for amortized inference in PPLs. In our system, amortization comes in the form of a parameterized guide program. Guide programs have similar structure to the original program, but can have richer data flow, including neural network components. These networks can be optimized so that the guide approximately samples from the posterior distribution defined by the original program. We present a flexible interface for defining guide programs and a stochastic gradient-based scheme for optimizing guide parameters, as well as some preliminary results on automatically deriving guide programs. We explore in detail the common machine learning pattern in which a 'local' model is specified by 'global' random values and used to generate independent observed data points; this gives rise to amortized local inference supporting global model learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/KNY2NCQN/Ritchie et al. - 2016 - Deep Amortized Inference for Probabilistic Program.pdf;/home/cbd/Zotero/storage/3RDZS37L/1610.html}
}

@book{robertMonteCarloStatistical2004,
  title = {Monte {{Carlo Statistical Methods}}},
  author = {Robert, Christian P. and Casella, George},
  year = {2004},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4757-4145-2},
  urldate = {2023-09-25},
  isbn = {978-1-4419-1939-7 978-1-4757-4145-2},
  keywords = {algorithms,computer,Importance Sampling,Markov chain,Markov chain Monte Carlo,Mathematica,mathematical statistics,mathematics,optimization,programming,Random variable,Ringe,simulation,statistical inference,statistics},
  file = {/home/cbd/Zotero/storage/W9AR495E/Robert and Casella - 2004 - Monte Carlo Statistical Methods.pdf}
}

@article{robertsLangevinDiffusionsMetropolisHastings2002,
  title = {Langevin {{Diffusions}} and {{Metropolis-Hastings Algorithms}}},
  author = {Roberts, G. O. and Stramer, O.},
  year = {2002},
  month = dec,
  journal = {Methodology And Computing In Applied Probability},
  volume = {4},
  number = {4},
  pages = {337--357},
  issn = {1573-7713},
  doi = {10.1023/A:1023562417138},
  urldate = {2023-01-05},
  abstract = {We consider a class of Langevin diffusions with state-dependent volatility. The volatility of the diffusion is chosen so as to make the stationary distribution of the diffusion with respect to its natural clock, a heated version of the stationary density of interest. The motivation behind this construction is the desire to construct uniformly ergodic diffusions with required stationary densities. Discrete time algorithms constructed by Hastings accept reject mechanisms are constructed from discretisations of the algorithms, and the properties of these algorithms are investigated.},
  langid = {english},
  keywords = {Langevin diffusions and algorithms,MCMC},
  file = {/home/cbd/Zotero/storage/KALKR6IF/Roberts and Stramer - 2002 - Langevin Diffusions and Metropolis-Hastings Algori.pdf}
}

@article{roseSouthwestWillPay2023,
  title = {Southwest Will Pay a \$140 Million Fine for Its Meltdown during the 2022 Holidays},
  author = {Rose, Joel},
  year = {2023},
  month = dec,
  journal = {NPR},
  urldate = {2024-01-03},
  abstract = {The U.S. Transportation Department ordered Southwest Airlines to pay a \$140 million civil penalty as part of an agreement over operational failures that stranded millions of passengers a year ago.},
  chapter = {National},
  langid = {english},
  file = {/home/cbd/Zotero/storage/KJUAVFXJ/southwest-airlines-2022-meltdown-fined-faa.html}
}

@article{rosskyBrownianDynamicsSmart2008,
  title = {Brownian Dynamics as Smart {{Monte Carlo}} Simulation},
  author = {Rossky, P. J. and Doll, J. D. and Friedman, H. L.},
  year = {2008},
  month = aug,
  journal = {The Journal of Chemical Physics},
  volume = {69},
  number = {10},
  pages = {4628--4633},
  issn = {0021-9606},
  doi = {10.1063/1.436415},
  urldate = {2023-05-15},
  abstract = {A new Monte Carlo simulation procedure is developed which is expected to produce more rapid convergence than the standard Metropolis method. The trial particle moves are chosen in accord with a Brownian dynamics algorithm rather than at random. For two model systems, a string of point masses joined by harmonic springs and a cluster of charged soft spheres, the new procedure is compared to the standard one and shown to manifest a more rapid convergence rate for some important energetic and structural properties.},
  file = {/home/cbd/Zotero/storage/5CASXKGU/Rossky et al. - 2008 - Brownian dynamics as smart Monte Carlo simulation.pdf;/home/cbd/Zotero/storage/YSQNT4VD/Brownian-dynamics-as-smart-Monte-Carlo-simulation.html}
}

@incollection{rubinoIntroductionRareEvent2009a,
  title = {Introduction to {{Rare Event Simulation}}},
  booktitle = {Rare {{Event Simulation}} Using {{Monte Carlo Methods}}},
  author = {Rubino, Gerardo and Tuffin, Bruno},
  year = {2009},
  pages = {1--13},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9780470745403.ch1},
  urldate = {2023-03-14},
  abstract = {Basics in Monte Carlo Importance sampling Splitting techniques About the book References},
  chapter = {1},
  isbn = {978-0-470-74540-3},
  langid = {english},
  keywords = {basics in Monte Carlo,importance sampling (IS),rare event simulation,splitting technique (fixed-splitting version),splitting techniques,techniques for rare event simulation,transportation systems - catastrophic failures being rare,transportation systems - critical in dependability area},
  file = {/home/cbd/Zotero/storage/I2GRJP95/Rubino and Tuffin - 2009 - Introduction to Rare Event Simulation.pdf;/home/cbd/Zotero/storage/QDSJMKTT/9780470745403.html}
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  year = {1986},
  month = oct,
  journal = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/323533a0},
  urldate = {2023-06-07},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  copyright = {1986 Springer Nature Limited},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science}
}

@misc{rychenerEndtoEndLearningStochastic2023,
  title = {End-to-{{End Learning}} for {{Stochastic Optimization}}: {{A Bayesian Perspective}}},
  shorttitle = {End-to-{{End Learning}} for {{Stochastic Optimization}}},
  author = {Rychener, Yves and Sutter, Daniel Kuhn Tobias},
  year = {2023},
  month = jun,
  number = {arXiv:2306.04174},
  eprint = {2306.04174},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2306.04174},
  urldate = {2023-06-12},
  abstract = {We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/W76NRQL3/Rychener and Sutter - 2023 - End-to-End Learning for Stochastic Optimization A.pdf;/home/cbd/Zotero/storage/THLELGI9/2306.html}
}

@article{sadraddiniRobustTemporalLogic2016,
  title = {Robust Temporal Logic Model Predictive Control},
  author = {Sadraddini, Sadra and Belta, Calin},
  year = {2016},
  month = apr,
  journal = {2015 53rd Annual Allerton Conference on Communication, Control, and Computing, Allerton 2015},
  eprint = {1511.00347},
  pages = {772--779},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/ALLERTON.2015.7447084},
  urldate = {2022-03-01},
  abstract = {Control synthesis from temporal logic specifications has gained popularity in recent years. In this paper, we use a model predictive approach to control discrete time linear systems with additive bounded disturbances subject to constraints given as formulas of signal temporal logic (STL). We introduce a (conservative) computationally efficient framework to synthesize control strategies based on mixed integer programs. The designed controllers satisfy the temporal logic requirements, are robust to all possible realizations of the disturbances, and optimal with respect to a cost function. In case the temporal logic constraint is infeasible, the controller satisfies a relaxed, minimally violating constraint. An illustrative case study is included.},
  archiveprefix = {arxiv},
  isbn = {9781509018239},
  keywords = {to_read},
  file = {/home/cbd/Zotero/storage/ADJ54H75/full-text.pdf}
}

@inproceedings{salmanUnadversarialExamplesDesigning2021,
  title = {Unadversarial {{Examples}}: {{Designing Objects}} for {{Robust Vision}}},
  shorttitle = {Unadversarial {{Examples}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Salman, Hadi and Ilyas, Andrew and Engstrom, Logan and Vemprala, Sai and Madry, Aleksander and Kapoor, Ashish},
  year = {2021},
  volume = {34},
  pages = {15270--15284},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-14},
  abstract = {We study a class of computer vision settings wherein one can modify the design of the objects being recognized. We develop a framework that leverages this capability---and deep networks' unusual sensitivity to input perturbations---to design robust objects,'' i.e., objects that are explicitly optimized to be confidently classified. Our framework yields improved performance on standard benchmarks, a simulated robotics environment, and physical-world experiments.},
  keywords = {00-read}
}

@article{salvatier_wiecki_fonnesbeck_2016,
  title = {Probabilistic Programming in Python Using {{PyMC3}}},
  author = {Salvatier, John and Wiecki, Thomas V. and Fonnesbeck, Christopher},
  year = {2016},
  journal = {PeerJ Computer Science},
  volume = {2},
  doi = {10.7717/peerj-cs.55}
}

@article{sankaranarayananFalsificationTemporalProperties2012,
  title = {Falsification of {{Temporal Properties}} of {{Hybrid Systems Using}} the {{Cross-Entropy Method}}},
  author = {Sankaranarayanan, Sriram and Fainekos, Georgios},
  year = {2012},
  journal = {Proceedings of the 15th ACM international conference on Hybrid Systems: Computation and Control - HSCC '12},
  publisher = {{ACM Press}},
  address = {{New York, New York, USA}},
  doi = {10.1145/2185632},
  urldate = {2022-02-18},
  abstract = {Randomized testing is a popular approach for checking properties of large embedded system designs. It is well known that a uniform random choice of test inputs is often sub-optimal. Ideally, the choice of inputs has to be guided by choosing the right input distributions in order to expose corner-case violations. However, this is also known to be a hard problem, in practice. In this paper, we present an application of the cross-entropy method for adaptively choosing input distributions for falsifying temporal logic properties of hybrid systems. We present various choices for representing input distribution families for the cross-entropy method, ranging from a complete partitioning of the input space into cells to a fac-tored distribution of the input using graphical models. Finally, we experimentally compare the falsification approach using the cross-entropy method to other stochastic and heuristic optimization techniques implemented inside the tool S-Taliro over a set of benchmark systems. The performance of the cross entropy method is quite promising. We find that sampling inputs using the cross-entropy method guided by trace robustness can discover violations faster, and more consistently than the other competing methods considered.},
  isbn = {9781450312202},
  keywords = {Cross-Entropy Method,falsification,G3 [Mathematics of Computing]: Probability and Statistics-Probabilistic algorithms (including Monte Carlo) General Terms Verification Keywords Hybrid Systems,Metric Temporal Logic,Monte-Carlo Simulation,optimization,Robustness,stl,Testing},
  file = {/home/cbd/Zotero/storage/TGHLI6TJ/full-text.pdf}
}

@article{scherEllipticalSliceSampling2022,
  title = {Elliptical {{Slice Sampling}} for {{Probabilistic Verification}} of {{Stochastic Systems}} with {{Signal Temporal Logic Specifications}}},
  author = {Scher, Guy and Sadraddini, Sadra and Tedrake, Russ and {Kress-Gazit}, Hadas},
  year = {2022},
  month = feb,
  eprint = {2203.00078},
  doi = {10.48550/arxiv.2203.00078},
  urldate = {2022-04-18},
  abstract = {Autonomous robots typically incorporate complex sensors in their decision-making and control loops. These sensors, such as cameras and Lidars, have imperfections in their sensing and are influenced by environmental conditions. In this paper, we present a method for probabilistic verification of linearizable systems with Gaussian and Gaussian mixture noise models (e.g. from perception modules, machine learning components). We compute the probabilities of task satisfaction under Signal Temporal Logic (STL) specifications, using its robustness semantics, with a Markov Chain Monte-Carlo slice sampler. As opposed to other techniques, our method avoids over-approximations and double-counting of failure events. Central to our approach is a method for efficient and rejection-free sampling of signals from a Gaussian distribution such that satisfy or violate a given STL formula. We show illustrative examples from applications in robot motion planning.},
  archiveprefix = {arxiv},
  keywords = {Probabilistic verification,Signal Temporal Logic,stll,to_read},
  file = {/home/cbd/Zotero/storage/RZS7MUEA/full-text.pdf}
}

@article{schulmanGradientEstimationUsing2015,
  title = {Gradient {{Estimation Using Stochastic Computation Graphs}}},
  author = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
  year = {2015},
  month = jun,
  journal = {Advances in Neural Information Processing Systems},
  volume = {2015-January},
  eprint = {1506.05254},
  pages = {3528--3536},
  publisher = {{Neural information processing systems foundation}},
  issn = {10495258},
  doi = {10.48550/arxiv.1506.05254},
  urldate = {2022-04-14},
  abstract = {In a variety of problems originating in supervised, unsupervised, and reinforcement learning, the loss function is defined by an expectation over a collection of random variables, which might be part of a probabilistic model or the external world. Estimating the gradient of this loss function, using samples, lies at the core of gradient-based learning algorithms for these problems. We introduce the formalism of stochastic computation graphs---directed acyclic graphs that include both deterministic functions and conditional probability distributions---and describe how to easily and automatically derive an unbiased estimator of the loss function's gradient. The resulting algorithm for computing the gradient estimator is a simple modification of the standard backpropagation algorithm. The generic scheme we propose unifies estimators derived in variety of prior work, along with variance-reduction techniques therein. It could assist researchers in developing intricate models involving a combination of stochastic and deterministic operations, enabling, for example, attention, memory, and control actions.},
  archiveprefix = {arxiv},
  file = {/home/cbd/Zotero/storage/4UV36W9S/full-text.pdf}
}

@article{schulmanMotionPlanningSequential2014,
  title = {Motion Planning with Sequential Convex Optimization and Convex Collision Checking},
  author = {Schulman, John and Duan, Yan and Ho, Jonathan and Lee, Alex and Awwal, Ibrahim and Bradlow, Henry and Pan, Jia and Patil, Sachin and Goldberg, Ken and Abbeel, Pieter},
  year = {2014},
  month = aug,
  journal = {The International Journal of Robotics Research},
  volume = {33},
  number = {9},
  pages = {1251--1270},
  issn = {0278-3649},
  doi = {10.1177/0278364914528132},
  langid = {english}
}

@misc{schulmanProximalPolicyOptimization2017,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  year = {2017},
  month = aug,
  number = {arXiv:1707.06347},
  eprint = {1707.06347},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1707.06347},
  urldate = {2023-05-17},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/cbd/Zotero/storage/6ICW6KWN/Schulman et al. - 2017 - Proximal Policy Optimization Algorithms.pdf;/home/cbd/Zotero/storage/CXTDEF2N/1707.html}
}

@article{Schulz_robogami,
  title = {Interactive Robogami: {{An}} End-to-End System for Design of Robots with Ground Locomotion},
  author = {Schulz, Adriana and Sung, Cynthia and Spielberg, Andrew and Zhao, Wei and Cheng, Robin and Grinspun, Eitan and Rus, Daniela and Matusik, Wojciech},
  year = {2017},
  journal = {The International Journal of Robotics Research},
  volume = {36},
  number = {10},
  pages = {1131--1147},
  publisher = {{SAGE Publications Sage UK: London, England}}
}

@inproceedings{shafahiAdversarialTrainingFree2019,
  title = {Adversarial Training for Free!},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-18},
  abstract = {Adversarial training, in which a network is trained on adversarial examples, is one of the few defenses against adversarial attacks that withstands strong attacks. Unfortunately, the high cost of generating strong adversarial examples makes standard adversarial training impractical on large-scale problems like ImageNet. We present an algorithm that eliminates the overhead cost of generating adversarial examples by recycling the gradient information computed when updating model parameters. Our "free" adversarial training algorithm achieves comparable robustness to PGD adversarial training on the CIFAR-10 and CIFAR-100 datasets at negligible additional cost compared to natural training, and can be 7 to 30 times faster than other strong adversarial training methods. Using a single workstation with 4 P100 GPUs and 2 days of runtime, we can train a robust model for the large-scale ImageNet classification task that maintains 40\% accuracy against PGD attacks.},
  keywords = {00-read}
}

@mastersthesis{sharpe_thesis,
  title = {{{AeroSandbox}}: {{A}} Differentiable Framework for Aircraft Design Optimization},
  author = {Sharpe, Peter D.},
  year = {2021},
  school = {MIT}
}

@inproceedings{shayevitzRenyiMeasuresHypothesis2011,
  title = {On {{R{\'e}nyi}} Measures and Hypothesis Testing},
  booktitle = {2011 {{IEEE International Symposium}} on {{Information Theory Proceedings}}},
  author = {Shayevitz, Ofer},
  year = {2011},
  month = jul,
  pages = {894--898},
  issn = {2157-8117},
  doi = {10.1109/ISIT.2011.6034266},
  urldate = {2024-01-06},
  abstract = {We provide a variational characterization for the various R{\'e}nyi information measures via their Shannon counterparts, and demonstrate how properties of the former can be recovered from first principle via the associated properties of the latter. Motivated by this characterization, we give a new operational interpretation for the R{\'e}nyi divergence in a two-sensor composite hypothesis testing framework.},
  file = {/home/cbd/Zotero/storage/6FHP8QCA/Shayevitz - 2011 - On Rnyi measures and hypothesis testing.pdf}
}

@inproceedings{shenGradientFreeAdversarialTraining2021,
  title = {Gradient-{{Free Adversarial Training Against Image Corruption}} for {{Learning-based Steering}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shen, Yu and Zheng, Laura and Shu, Manli and Li, Weizi and Goldstein, Tom and Lin, Ming},
  year = {2021},
  volume = {34},
  pages = {26250--26263},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-14},
  abstract = {We introduce a simple yet effective framework for improving the robustness of learning algorithms against image corruptions for autonomous driving. These corruptions can occur due to both internal (e.g., sensor noises and hardware abnormalities) and external factors (e.g., lighting, weather, visibility, and other environmental effects). Using sensitivity analysis with FID-based parameterization, we propose a novel algorithm exploiting basis perturbations to improve the overall performance of autonomous steering and other image processing tasks, such as classification and detection, for self-driving cars. Our model not only improves the performance on the original dataset, but also achieves significant performance improvement on datasets with multiple and unseen perturbations, up to 87\% and 77\%, respectively. A comparison between our approach and other SOTA techniques confirms the effectiveness of our technique in improving the robustness of neural network training for learning-based steering and other image processing tasks.},
  keywords = {00-read}
}

@article{shiNeuralLanderStable2019,
  title = {Neural {{Lander}}: {{Stable Drone Landing Control Using Learned Dynamics}}},
  shorttitle = {Neural {{Lander}}},
  author = {Shi, Guanya and Shi, Xichen and O'Connell, Michael and Yu, Rose and Azizzadenesheli, Kamyar and Anandkumar, Animashree and Yue, Yisong and Chung, Soon-Jo},
  year = {2019},
  month = may,
  journal = {2019 International Conference on Robotics and Automation (ICRA)},
  pages = {9784--9790},
  publisher = {{IEEE}},
  address = {{Montreal, QC, Canada}},
  doi = {10.1109/ICRA.2019.8794351},
  urldate = {2024-01-22},
  abstract = {Precise near-ground trajectory control is difficult for multi-rotor drones, due to the complex aerodynamic effects caused by interactions between multi-rotor airflow and the environment. Conventional control methods often fail to properly account for these complex effects and fall short in accomplishing smooth landing. In this paper, we present a novel deep-learning-based robust nonlinear controller (Neural-Lander) that improves control performance of a quadrotor during landing. Our approach combines a nominal dynamics model with a Deep Neural Network (DNN) that learns high-order interactions. We apply spectral normalization (SN) to constrain the Lipschitz constant of the DNN. Leveraging this Lipschitz property, we design a nonlinear feedback linearization controller using the learned model and prove system stability with disturbance rejection. To the best of our knowledge, this is the first DNN-based nonlinear feedback controller with stability guarantees that can utilize arbitrarily large neural nets. Experimental results demonstrate that the proposed controller significantly outperforms a Baseline Nonlinear Tracking Controller in both landing and cross-table trajectory tracking cases. We also empirically show that the DNN generalizes well to unseen data outside the training domain.},
  isbn = {9781538660270},
  file = {/home/cbd/Zotero/storage/NQZMSK9N/Shi et al. - 2019 - Neural Lander Stable Drone Landing Control Using .pdf}
}

@article{shishikaCooperativeTeamStrategies2020,
  title = {Cooperative {{Team Strategies}} for {{Multi-Player Perimeter-Defense Games}}},
  author = {Shishika, Daigo and Paulos, James and Kumar, Vijay},
  year = {2020},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {2},
  pages = {2738--2745},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.2972818},
  abstract = {This letter studies a variant of the multi-player reach-avoid game played between intruders and defenders with applications to perimeter defense. The intruder team tries to score by sending as many intruders as possible to the target area, while the defender team tries to minimize this score by intercepting them. Finding the optimal strategies of the game is challenging due to the high dimensionality of the joint state space. Existing works have proposed approximation methods to reduce the design of the defense strategy into assignment problems, however, they suffer from either suboptimal defender performance or computational complexity. Based on a novel decomposition method, this letter proposes a scalable (polynomial-time) assignment algorithm that accommodates cooperative behaviors and outperforms the existing defense strategies. For a certain class of initial configurations, we derive the exact score by showing that the lower bound provided by the intruder team matches the upper bound provided by the defender team, which also proves the optimality of the team strategies.},
  keywords = {Approximation methods,Bipartite graph,Computational complexity,cooperating robots,Games,Multi-robot systems,perimeter defense,pursuit-evasion games,Robots,Task analysis,Upper bound},
  file = {/home/cbd/Zotero/storage/ZWUIH9F3/Shishika et al. - 2020 - Cooperative Team Strategies for Multi-Player Perim.pdf}
}

@book{shishkoNASASystemsEngineering1995,
  title = {{{NASA}} Systems Engineering Handbook},
  author = {Shishko, Robert},
  year = {1995},
  series = {Nasa Sp},
  number = {6105},
  publisher = {{National Aeronautics and Space Administration}},
  address = {{Washington, D.C.?}},
  collaborator = {Aster, Robert and Cassingham, R. C. and {United States National Aeronautics and Space Administration}},
  langid = {english},
  keywords = {Aeronautics,Astronautics,Manned space flight,Systems engineering,United States National Aeronautics and Space Administration}
}

@misc{shreveDeepDecarbonisationMultitrillion2019,
  title = {Deep Decarbonisation: {{The}} Multi-Trillion Dollar Question},
  shorttitle = {Deep Decarbonisation},
  author = {Shreve, Dan},
  year = {2019},
  month = jun,
  urldate = {2022-12-17},
  abstract = {Achieving deep decarbonisation: how to cope with intermittent supply, how to calculate the cost of transition, with a US-focused case study, and four possible routes to RE100},
  chapter = {Featured},
  langid = {english}
}

@inproceedings{shuAmortizedInferenceRegularization2018a,
  title = {Amortized {{Inference Regularization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shu, Rui and Bui, Hung H and Zhao, Shengjia and Kochenderfer, Mykel J and Ermon, Stefano},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2024-01-19},
  abstract = {The variational autoencoder (VAE) is a popular model for density estimation and representation learning. Canonically, the variational principle suggests to prefer an expressive inference model so that the variational approximation is accurate. However, it is often overlooked that an overly-expressive inference model can be detrimental to the test set performance of both the amortized posterior approximator and, more importantly, the generative density estimator. In this paper, we leverage the fact that VAEs rely on amortized inference and propose techniques for amortized inference regularization (AIR) that control the smoothness of the inference model. We demonstrate that, by applying AIR, it is possible to improve VAE generalization on both inference and generative performance. Our paper challenges the belief that amortized inference is simply a mechanism for approximating maximum likelihood training and illustrates that regularization of the amortization family provides a new direction for understanding and improving generalization in VAEs.},
  file = {/home/cbd/Zotero/storage/RAILYDBE/Shu et al. - 2018 - Amortized Inference Regularization.pdf}
}

@inproceedings{sinhaNeuralBridgeSampling2020,
  title = {Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Sinha, Aman and O'Kelly, Matthew and Tedrake, Russ and Duchi, John},
  year = {2020},
  month = dec,
  series = {{{NIPS}}'20},
  pages = {6402--6416},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  urldate = {2022-11-23},
  abstract = {Learning-based methodologies increasingly find applications in safety-critical domains like autonomous driving and medical robotics. Due to the rare nature of dangerous events, real-world testing is prohibitively expensive and unscalable. In this work, we employ a probabilistic approach to safety evaluation in simulation, where we are concerned with computing the probability of dangerous events. We develop a novel rare-event simulation method that combines exploration, exploitation, and optimization techniques to find failure modes and estimate their rate of occurrence. We provide rigorous guarantees for the performance of our method in terms of both statistical and computational efficiency. Finally, we demonstrate the efficacy of our approach on a variety of scenarios, illustrating its usefulness as a tool for rapid sensitivity analysis and model comparison that are essential to developing and testing safety-critical autonomous systems.},
  isbn = {978-1-71382-954-6},
  file = {/home/cbd/Zotero/storage/Y3BJ4KDW/Sinha et al. - 2020 - Neural bridge sampling for evaluating safety-criti.pdf}
}

@article{soft_robot_optimization_review,
  title = {Design Optimization of Soft Robots: {{A}} Review of the State of the Art},
  author = {Chen, Feifei and Wang, Michael Yu},
  year = {2020},
  journal = {IEEE Robotics Automation Magazine},
  volume = {27},
  number = {4},
  pages = {27--43},
  doi = {10.1109/MRA.2020.3024280}
}

@article{soklakovEconomicsDisagreementFinancial2020,
  title = {Economics of {{Disagreement}}---{{Financial Intuition}} for the {{R{\'e}nyi Divergence}}},
  author = {Soklakov, Andrei N.},
  year = {2020},
  month = aug,
  journal = {Entropy. An International and Interdisciplinary Journal of Entropy and Information Studies},
  volume = {22},
  number = {8},
  pages = {860},
  issn = {1099-4300},
  doi = {10.3390/e22080860},
  urldate = {2024-01-06},
  abstract = {Disagreement is an essential element of science and life in general. The language of probabilities and statistics is often used to describe disagreements quantitatively. In practice, however, we want much more than that. We want disagreements to be resolved. This leaves us with a substantial knowledge gap, which is often perceived as a lack of practical intuition regarding probabilistic and statistical concepts. Here, we propose to address disagreements using the methods of financial economics. In particular, we show how a large class of disagreements can be transformed into investment opportunities. The expected financial performance of such investments quantifies the amount of disagreement in a tangible way. This provides intuition for statistical concepts such as the R{\'e}nyi divergence, which becomes connected to the financial performance of optimized investments. Investment optimization takes into account individual opinions as well as attitudes towards risk. The result is a market-like social mechanism by which funds flow naturally to support a more accurate view. Such social mechanisms can help us with difficult disagreements (e.g., financial arguments concerning the future climate). In terms of scientific validation, we used the findings of independent neurophysiological experiments as well as our own research on the equity premium.},
  pmcid = {PMC7517462},
  pmid = {33286632},
  file = {/home/cbd/Zotero/storage/XR522B9R/Soklakov - 2020 - Economics of DisagreementFinancial Intuition for .pdf}
}

@misc{soklakovInformationGeometryRisks2022,
  type = {{{SSRN Scholarly Paper}}},
  title = {Information {{Geometry}} of {{Risks}} and {{Returns}}},
  author = {Soklakov, Andrei N.},
  year = {2022},
  month = jun,
  number = {4134885},
  address = {{Rochester, NY}},
  doi = {10.2139/ssrn.4134885},
  urldate = {2024-01-06},
  abstract = {We reveal a geometric structure underlying both hedging and investment products. The structure follows from a simple formula expressing investment risks in terms of returns. This informs optimal product designs. Optimal pure hedging (including cost-optimal products) and hybrid hedging (where a partial hedge is built into an optimal investment product) are considered. Duality between hedging and investment is demonstrated with applications to optimal risk recycling. A geometric interpretation of rationality is presented.},
  langid = {english},
  keywords = {Information derivatives,Information geometry,Product design,Rationality},
  file = {/home/cbd/Zotero/storage/WGBTA4W9/Soklakov - 2022 - Information Geometry of Risks and Returns.pdf}
}

@incollection{songGenerativeModelingEstimating2019,
  title = {Generative Modeling by Estimating Gradients of the Data Distribution},
  booktitle = {Proceedings of the 33rd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Song, Yang and Ermon, Stefano},
  year = {2019},
  month = dec,
  number = {1067},
  pages = {11918--11930},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  urldate = {2023-03-23},
  abstract = {We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients can be ill-defined and hard to estimate when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise, and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments.}
}

@inproceedings{songScoreBasedGenerativeModeling2023,
  title = {Score-{{Based Generative Modeling}} through {{Stochastic Differential Equations}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Song, Yang and {Sohl-Dickstein}, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  year = {2023},
  month = jan,
  urldate = {2023-03-23},
  abstract = {Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of \$1024{\textbackslash}times 1024\$ images for the first time from a score-based generative model.},
  langid = {english},
  keywords = {00-read,00-relevant}
}

@inproceedings{soSolvingStabilizeAvoidEpigraph2023,
  title = {Solving {{Stabilize-Avoid}} via {{Epigraph Form Optimal Control}} Using {{Deep Reinforcement Learning}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {So, Oswin and Fan, Chuchu},
  year = {2023},
  month = jul,
  volume = {19},
  urldate = {2023-08-09},
  isbn = {978-0-9923747-9-2},
  file = {/home/cbd/Zotero/storage/T5DAJUHF/So and Fan - 2023 - Solving Stabilize-Avoid via Epigraph Form Optimal .pdf}
}

@misc{southwestairlinesFinalSummaryAction2023,
  title = {Final {{Summary}} and {{Action Plan}}},
  author = {{Southwest Airlines}},
  year = {2023}
}

@incollection{spall,
  title = {Stochastic Approximation for Nonlinear Root-Finding},
  booktitle = {Introduction to Stochastic Search and Optimization},
  author = {Spall, James C.},
  year = {2003},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471722138.ch4},
  pages = {95--125},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/0471722138.ch4},
  isbn = {978-0-471-72213-7}
}

@article{sridhar2021improving,
  title = {Improving Neural Network Robustness via Persistency of Excitation},
  author = {Sridhar, Kaustubh and Sokolsky, Oleg and Lee, Insup and Weimer, James},
  year = {2021},
  journal = {arXiv},
  eprint = {2106.02078},
  primaryclass = {stat.ML},
  archiveprefix = {arxiv}
}

@misc{StrengtheningAirlineOperations,
  title = {Strengthening {{Airline Operations}} and {{Consumer Protections}}},
  urldate = {2024-01-26},
  file = {/home/cbd/Zotero/storage/9TLQMGR8/B8D729EC-5F96-4E8D-A902-F43DA29F2E08.pdf}
}

@article{stuartInverseProblemsBayesian2010,
  title = {Inverse Problems: {{A Bayesian}} Perspective},
  shorttitle = {Inverse Problems},
  author = {Stuart, A. M.},
  year = {2010},
  month = may,
  journal = {Acta Numerica},
  volume = {19},
  pages = {451--559},
  publisher = {{Cambridge University Press}},
  issn = {1474-0508, 0962-4929},
  doi = {10.1017/S0962492910000061},
  urldate = {2024-01-02},
  abstract = {The subject of inverse problems in differential equations is of enormous practical importance, and has also generated substantial mathematical and computational innovation. Typically some form of regularization is required to ameliorate ill-posed behaviour. In this article we review the Bayesian approach to regularization, developing a function space viewpoint on the subject. This approach allows for a full characterization of all possible solutions, and their relative probabilities, whilst simultaneously forcing significant modelling issues to be addressed in a clear and precise fashion. Although expensive to implement, this approach is starting to lie within the range of the available computational resources in many application areas. It also allows for the quantification of uncertainty and risk, something which is increasingly demanded by these applications. Furthermore, the approach is conceptually important for the understanding of simpler, computationally expedient approaches to inverse problems.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/YHI9VK7B/Stuart - 2010 - Inverse problems A Bayesian perspective.pdf}
}

@article{suh2021_bundled_gradients,
  title = {Bundled Gradients through Contact via Randomized Smoothing},
  author = {Suh, Hongseok and Pang, Tao and Tedrake, Russ},
  year = {2021},
  journal = {ArXiv},
  volume = {abs/2109.05143}
}

@inproceedings{suhDifferentiableSimulatorsGive2022,
  title = {Do {{Differentiable Simulators Give Better Policy Gradients}}?},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Suh, Hyung Ju and Simchowitz, Max and Zhang, Kaiqing and Tedrake, Russ},
  year = {2022},
  month = jun,
  pages = {20668--20696},
  publisher = {{PMLR}},
  issn = {2640-3498},
  urldate = {2023-06-07},
  abstract = {Differentiable simulators promise faster computation time for reinforcement learning by replacing zeroth-order gradient estimates of a stochastic objective with an estimate based on first-order gradients. However, it is yet unclear what factors decide the performance of the two estimators on complex landscapes that involve long-horizon planning and control on physical systems, despite the crucial relevance of this question for the utility of differentiable simulators. We show that characteristics of certain physical systems, such as stiffness or discontinuities, may compromise the efficacy of the first-order estimator, and analyze this phenomenon through the lens of bias and variance. We additionally propose an A{$\alpha\backslash$}alpha-order gradient estimator, with A{$\in$}[0,1]{$\alpha\in$}[0,1]{\textbackslash}alpha {\textbackslash}in [0,1], which correctly utilizes exact gradients to combine the efficiency of first-order estimates with the robustness of zero-order methods. We demonstrate the pitfalls of traditional estimators and the advantages of the A{$\alpha\backslash$}alpha-order estimator on some numerical examples.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/5LZ8U3N9/Suh et al. - 2022 - Do Differentiable Simulators Give Better Policy Gr.pdf}
}

@article{sunCornerCaseGeneration2021,
  title = {Corner {{Case Generation}} and {{Analysis}} for {{Safety Assessment}} of {{Autonomous Vehicles}}},
  author = {Sun, Haowei and Feng, Shuo and Yan, Xintao and Liu, Henry X.},
  year = {2021},
  month = nov,
  journal = {Transportation Research Record},
  volume = {2675},
  number = {11},
  pages = {587--600},
  publisher = {{SAGE Publications Inc}},
  issn = {0361-1981},
  doi = {10.1177/03611981211018697},
  urldate = {2023-03-14},
  abstract = {Testing and evaluation is a crucial step in the development and deployment of connected and automated vehicles (CAVs). To comprehensively evaluate the performance of CAVs, it is necessary to test the CAVs in safety-critical scenarios, which rarely happen in a naturalistic driving environment. Therefore, how to purposely and systematically generate these corner cases becomes an important problem. Most existing studies focus on generating adversarial examples for perception systems of CAVs, whereas limited efforts have been put into decision-making systems, which is the highlight of this paper. As the CAVs need to interact with numerous background vehicles (BVs) for a long duration, variables that define the corner cases are usually high-dimensional, which makes the generation a challenging problem. In this paper, a unified framework is proposed to generate corner cases for decision-making systems. To address the challenge brought by high dimensionality, the driving environment is formulated based on the Markov decision process, and the deep reinforcement learning techniques are applied to learn the behavior policy of BVs. With the learned policy, BVs behave and interact with the CAVs more aggressively, resulting in more corner cases. To further analyze the generated corner cases, the techniques of feature extraction and clustering are utilized. By selecting representative cases of each cluster and outliers, the valuable corner cases can be identified from all generated corner cases. Simulation results of a highway driving environment show that the proposed methods can effectively generate and identify the valuable corner cases.},
  keywords = {00-read,00-relevant,rl},
  file = {/home/cbd/Zotero/storage/6Y556XSK/Sun et al. - 2021 - Corner Case Generation and Analysis for Safety Ass.pdf}
}

@article{sunMultiagentMotionPlanning2022,
  title = {Multi-Agent {{Motion Planning}} from {{Signal Temporal Logic Specifications}}},
  author = {Sun, Dawei and Chen, Jingkai and Mitra, Sayan and Fan, Chuchu},
  year = {2022},
  month = jan,
  journal = {IEEE Robotics and Automation Letters (RA-L)},
  eprint = {2201.05247},
  urldate = {2022-01-30},
  abstract = {We tackle the challenging problem of multi-agent cooperative motion planning for complex tasks described using signal temporal logic (STL), where robots can have nonlinear and nonholonomic dynamics. Existing methods in multi-agent motion planning, especially those based on discrete abstractions and model predictive control (MPC), suffer from limited scalability with respect to the complexity of the task, the size of the workspace, and the planning horizon. We present a method based on \{{\textbackslash}em timed waypoints{\textbackslash}/\} to address this issue. We show that timed waypoints can help abstract nonlinear behaviors of the system as safety envelopes around the reference path defined by those waypoints. Then the search for waypoints satisfying the STL specifications can be inductively encoded as a mixed-integer linear program. The agents following the synthesized timed waypoints have their tasks automatically allocated, and are guaranteed to satisfy the STL specifications while avoiding collisions. We evaluate the algorithm on a wide variety of benchmarks. Results show that it supports multi-agent planning from complex specification over long planning horizons, and significantly outperforms state-of-the-art abstraction-based and MPC-based motion planning methods. The implementation is available at https://github.com/sundw2014/STLPlanning.},
  archiveprefix = {arxiv},
  keywords = {done,Index Terms-Task and Motion Planning,multi-agent,path planning,Path Planning for Multiple Mobile Robots or Agents,stl,tamp},
  file = {/home/cbd/Zotero/storage/5RUIH6C7/full-text.pdf}
}

@article{tabakDensityEstimationDual2010,
  title = {Density Estimation by Dual Ascent of the Log-Likelihood},
  author = {Tabak, Esteban G. and {Vanden-Eijnden}, Eric},
  year = {2010},
  month = mar,
  journal = {Communications in Mathematical Sciences},
  volume = {8},
  number = {1},
  pages = {217--233},
  publisher = {{International Press of Boston}},
  issn = {1539-6746, 1945-0796},
  urldate = {2024-01-21},
  abstract = {A methodology is developed to assign, from an observed sample, a joint-probability distribution to a set of continuous variables. The algorithm proposed performs this assignment by mapping the original variables onto a jointly-Gaussian set. The map is built iteratively, ascending the log-likelihood of the observations, through a series of steps that move the marginal distributions along a random set of orthogonal directions towards normality.},
  keywords = {34A50,60H35,65C30,65L20,Density estimation,machine learning,maximum likelihood},
  file = {/home/cbd/Zotero/storage/W6W7XQQ4/Tabak and Vanden-Eijnden - 2010 - Density estimation by dual ascent of the log-likel.pdf}
}

@article{tabakFamilyNonparametricDensity2013,
  title = {A {{Family}} of {{Nonparametric Density Estimation Algorithms}}},
  author = {Tabak, E. G. and Turner, Cristina V.},
  year = {2013},
  journal = {Communications on Pure and Applied Mathematics},
  volume = {66},
  number = {2},
  pages = {145--164},
  issn = {1097-0312},
  doi = {10.1002/cpa.21423},
  urldate = {2024-01-21},
  abstract = {A new methodology for density estimation is proposed. The methodology, which builds on the one developed by Tabak and Vanden-Eijnden, normalizes the data points through the composition of simple maps. The parameters of each map are determined through the maximization of a local quadratic approximation to the log-likelihood. Various candidates for the elementary maps of each step are proposed; criteria for choosing one includes robustness, computational simplicity, and good behavior in high-dimensional settings. A good choice is that of localized radial expansions, which depend on a single parameter: all the complexity of arbitrary, possibly convoluted probability densities can be built through the composition of such simple maps. {\copyright} 2012 Wiley Periodicals, Inc.},
  copyright = {Copyright {\copyright} 2012 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/V76LQIRS/Tabak and Turner - 2013 - A Family of Nonparametric Density Estimation Algor.pdf;/home/cbd/Zotero/storage/TKUEQCXF/cpa.html}
}

@inproceedings{takanoContinuousOptimizationBasedTask2021,
  title = {Continuous {{Optimization-Based Task}} and {{Motion Planning}} with {{Signal Temporal Logic Specifications}} for {{Sequential Manipulation}}},
  booktitle = {Proceedings of the 40th {{IEEE Conference}} on {{Decision}} and {{Control}}},
  author = {Takano, Rin and Oyama, Hiroyuki and Yamakita, Masaki},
  year = {2021},
  month = oct,
  pages = {8409--8415},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  doi = {10.1109/ICRA48506.2021.9561209},
  urldate = {2022-02-03},
  abstract = {We propose a new optimization-based task and motion planning (TAMP) with signal temporal logic (STL) specifications for robotic sequential manipulation such as pick-and-place tasks. Given a high-level task specification, the TAMP problem is to plan a trajectory that satisfies the specification. This is, however, a challenging problem due to the difficulty of combining continuous motion planning and discrete task specifications. The optimization-based TAMP with temporal logic specifications is a promising method, but existing works use mixed integer problems (MIP) and do not scale well. To address this issue, in our approach, a new hybrid system model without discrete variables is introduced and combined with smooth approximation methods for STL. This allows the TAMP to be formulated as a nonlinear programming problem whose computational cost is significantly less than that of MIP. Furthermore, it is also possible to deal with nonlinear dynamics and geometric constraints represented by nonlinear functions. The effectiveness of the proposed method is demonstrated with both numerical experiments and a real robot.},
  keywords = {optimization,stl,tamp},
  file = {/home/cbd/Zotero/storage/8BM2DPJ4/full-text.pdf}
}

@misc{tensorflow2015-whitepaper,
  title = {{{TensorFlow}}: {{Large-scale}} Machine Learning on Heterogeneous Systems},
  author = {Abadi, Mart{\'i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man{\'e}, Dandelion and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vi{\'e}gas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  year = {2015}
}

@inproceedings{tobinDomainRandomizationTransferring2017,
  title = {Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  year = {2017},
  month = sep,
  pages = {23--30},
  issn = {2153-0866},
  doi = {10.1109/IROS.2017.8202133},
  abstract = {Bridging the `reality gap' that separates simulated robotics from experiments on hardware could accelerate robotic research through improved data availability. This paper explores domain randomization, a simple technique for training models on simulated images that transfer to real images by randomizing rendering in the simulator. With enough variability in the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization, which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object detector that is accurate to 1.5 cm and robust to distractors and partial occlusions using only data from a simulator with non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on simulated RGB images (without pre-training on real images) to the real world for the purpose of robotic control.},
  keywords = {Adaptation models,Cameras,Data models,Robots,Solid modeling,Three-dimensional displays,Training},
  file = {/home/cbd/Zotero/storage/9UJKHGIU/Tobin et al. - 2017 - Domain randomization for transferring deep neural .pdf;/home/cbd/Zotero/storage/7XFNCBIW/8202133.html}
}

@misc{tongEnforcingSafetyVisionbased2023,
  title = {Enforcing Safety for Vision-Based Controllers via {{Control Barrier Functions}} and {{Neural Radiance Fields}}},
  author = {Tong, Mukun and Dawson, Charles and Fan, Chuchu},
  year = {2023},
  month = feb,
  number = {arXiv:2209.12266},
  eprint = {2209.12266},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2209.12266},
  urldate = {2023-05-23},
  abstract = {To navigate complex environments, robots must increasingly use high-dimensional visual feedback (e.g. images) for control. However, relying on high-dimensional image data to make control decisions raises important questions; particularly, how might we prove the safety of a visual-feedback controller? Control barrier functions (CBFs) are powerful tools for certifying the safety of feedback controllers in the state-feedback setting, but CBFs have traditionally been poorly-suited to visual feedback control due to the need to predict future observations in order to evaluate the barrier function. In this work, we solve this issue by leveraging recent advances in neural radiance fields (NeRFs), which learn implicit representations of 3D scenes and can render images from previously-unseen camera perspectives, to provide single-step visual foresight for a CBF-based controller. This novel combination is able to filter out unsafe actions and intervene to preserve safety. We demonstrate the effect of our controller in real-time simulation experiments where it successfully prevents the robot from taking dangerous actions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {/home/cbd/Zotero/storage/PJX2Y7P9/Tong et al. - 2023 - Enforcing safety for vision-based controllers via .pdf;/home/cbd/Zotero/storage/9FMBJ24F/2209.html}
}

@misc{trippeConditionalDensityEstimation2018,
  title = {Conditional {{Density Estimation}} with {{Bayesian Normalising Flows}}},
  author = {Trippe, Brian L. and Turner, Richard E.},
  year = {2018},
  month = feb,
  number = {arXiv:1802.04908},
  eprint = {1802.04908},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1802.04908},
  urldate = {2024-01-19},
  abstract = {Modeling complex conditional distributions is critical in a variety of settings. Despite a long tradition of research into conditional density estimation, current methods employ either simple parametric forms or are difficult to learn in practice. This paper employs normalising flows as a flexible likelihood model and presents an efficient method for fitting them to complex densities. These estimators must trade-off between modeling distributional complexity, functional complexity and heteroscedasticity without overfitting. We recognize these trade-offs as modeling decisions and develop a Bayesian framework for placing priors over these conditional density estimators using variational Bayesian neural networks. We evaluate this method on several small benchmark regression datasets, on some of which it obtains state of the art performance. Finally, we apply the method to two spatial density modeling tasks with over 1 million datapoints using the New York City yellow taxi dataset and the Chicago crime dataset.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/YGXZ2BRS/Trippe and Turner - 2018 - Conditional Density Estimation with Bayesian Norma.pdf;/home/cbd/Zotero/storage/DEVHMPA3/1802.html}
}

@article{tsukamoto21survey,
  title = {Contraction Theory for Nonlinear Stability Analysis and Learning-Based Control: {{A}} Tutorial Overview},
  author = {Tsukamoto, Hiroyasu and Chung, Soon-Jo and Slotine, Jean-Jaques E.},
  year = {2021},
  month = jan,
  journal = {Annual Reviews in Control},
  volume = {52},
  pages = {135--169},
  publisher = {{Pergamon}},
  issn = {13675788},
  doi = {10.1016/j.arcontrol.2021.10.001},
  urldate = {2022-02-03},
  abstract = {Contraction theory is an analytical tool to study differential dynamics of a non-autonomous (i.e., time-varying) nonlinear system under a contraction metric defined with a uniformly positive definite matrix, the existence of which results in a necessary and sufficient characterization of incremental exponential stability of multiple solution trajectories with respect to each other. By using a squared differential length as a Lyapunov-like function, its nonlinear stability analysis boils down to finding a suitable contraction metric that satisfies a stability condition expressed as a linear matrix inequality, indicating that many parallels can be drawn between well-known linear systems theory and contraction theory for nonlinear systems. Furthermore, contraction theory takes advantage of a superior robustness property of exponential stability used in conjunction with the comparison lemma. This yields much-needed safety and stability guarantees for neural network-based control and estimation schemes, without resorting to a more involved method of using uniform asymptotic stability for input-to-state stability. Such distinctive features permit systematic construction of a contraction metric via convex optimization, thereby obtaining an explicit exponential bound on the distance between a time-varying target trajectory and solution trajectories perturbed externally due to disturbances and learning errors. The objective of this paper is therefore to present a tutorial overview of contraction theory and its advantages in nonlinear stability analysis of deterministic and stochastic systems, with an emphasis on deriving formal robustness and stability guarantees for various learning-based and data-driven automatic control methods. In particular, we provide a detailed review of techniques for finding contraction metrics and associated control and estimation laws using deep neural networks.},
  keywords = {Adaptive control,contraction metrics,Contraction theory,Data-driven control,Learning-based control,Nonlinear stability,Optimal control and estimation,Robust control and estimation},
  file = {/home/cbd/Zotero/storage/PJXZ4ZEX/tutorial.pdf}
}

@inproceedings{tuncaliUtilizingSTaLiRoAutomatic2016,
  title = {Utilizing {{S-TaLiRo}} as an Automatic Test Generation Framework for Autonomous Vehicles},
  booktitle = {2016 {{IEEE}} 19th {{International Conference}} on {{Intelligent Transportation Systems}} ({{ITSC}})},
  author = {Tuncali, Cumhur Erkan and Pavlic, Theodore P. and Fainekos, Georgios},
  year = {2016},
  month = nov,
  pages = {1470--1475},
  issn = {2153-0017},
  doi = {10.1109/ITSC.2016.7795751},
  abstract = {This paper proposes an approach to automatically generating test cases for testing motion controllers of autonomous vehicular systems. Test scenarios may consist of single or multiple vehicles under test at the same time. Tests are performed in simulation environments. The approach is based on using a robustness metric for evaluating simulation outcomes as a cost function. Initial states and inputs are updated by stochastic optimization methods between the tests for achieving smaller robustness values. The test generation framework has been implemented in the toolbox S-TaLiRo. The proposed framework's ability to generate interesting test cases is demonstrated by a case study.},
  keywords = {00-read,00-relevant,Autonomous vehicles,Engines,Measurement,Robustness,Testing,Trajectory},
  file = {/home/cbd/Zotero/storage/7NGQ8NRW/Tuncali et al. - 2016 - Utilizing S-TaLiRo as an automatic test generation.pdf;/home/cbd/Zotero/storage/F5Q2TAP8/7795751.html}
}

@misc{u.s.departmentofenergyGridOptimizationCompetition,
  title = {Grid {{Optimization Competition}}},
  author = {{U.S. Department of Energy}},
  urldate = {2022-12-15},
  file = {/home/cbd/Zotero/storage/HU8NUP6P/gocompetition.energy.gov.html}
}

@inproceedings{ulusoyRecedingHorizonControl2013,
  title = {Receding {{Horizon Control}} in {{Dynamic Environments}} from {{Temporal Logic Specifications}}},
  booktitle = {Robotics: {{Science}} and {{Systems}}},
  author = {Ulusoy, Alphan and Marrazzo, Michael and Belta, Calin},
  year = {2013},
  month = jan,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2013.IX.013},
  urldate = {2022-02-10},
  abstract = {We present a control strategy for an autonomous vehicle that is required to satisfy a rich mission specification over service requests occurring at the regions of a partitioned environment. The overall mission specification consists of a temporal logic statement over a set of static, a priori known requests, and a servicing priority order over a set of dynamic requests that can be sensed locally. Our approach is based on two main steps. First, we construct an abstraction for the motion of the vehicle in the environment by using input output linearization and assignment of vector fields to the regions in the partition. Second, a receding horizon controller computes local plans within the sensing range of the vehicle such that both local and global mission specifications are satisfied. We implement and evaluate our method in an experimental setup consisting of a quadrotor performing a persistent surveillance task over a planar grid environment.},
  keywords = {automata,ltl},
  file = {/home/cbd/Zotero/storage/ESH9R9HY/full-text.pdf}
}

@article{umenbergerGloballyConvergentPolicy2022,
  title = {Globally {{Convergent Policy Search}} over {{Dynamic Filters}} for {{Output Estimation}}},
  author = {Umenberger, Jack and Simchowitz, Max and Perdomo, Juan C. and Zhang, Kaiqing and Tedrake, Russ},
  year = {2022},
  month = feb,
  eprint = {2202.11659},
  doi = {10.48550/arxiv.2202.11659},
  urldate = {2022-04-18},
  abstract = {We introduce the first direct policy search algorithm which provably converges to the globally optimal \${\textbackslash}textit\{dynamic\}\$ filter for the classical problem of predicting the outputs of a linear dynamical system, given noisy, partial observations. Despite the ubiquity of partial observability in practice, theoretical guarantees for direct policy search algorithms, one of the backbones of modern reinforcement learning, have proven difficult to achieve. This is primarily due to the degeneracies which arise when optimizing over filters that maintain internal state. In this paper, we provide a new perspective on this challenging problem based on the notion of \${\textbackslash}textit\{informativity\}\$, which intuitively requires that all components of a filter's internal state are representative of the true state of the underlying dynamical system. We show that informativity overcomes the aforementioned degeneracy. Specifically, we propose a \${\textbackslash}textit\{regularizer\}\$ which explicitly enforces informativity, and establish that gradient descent on this regularized objective - combined with a ``reconditioning step'' - converges to the globally optimal cost a \${\textbackslash}mathcal\{O\}(1/T)\$ rate. Our analysis relies on several new results which may be of independent interest, including a new framework for analyzing non-convex gradient descent via convex reformulation, and novel bounds on the solution to linear Lyapunov equations in terms of (our quantitative measure of) informativity.},
  archiveprefix = {arxiv},
  keywords = {to_read},
  file = {/home/cbd/Zotero/storage/PRG85VRS/full-text.pdf}
}

@book{underactuated,
  title = {Underactuated Robotics. {{Algorithms}} for {{Walking}}, {{Running}}, {{Swimming}}, {{Flying}}, and {{Manipulation}}},
  author = {Tedrake, Russ},
  year = {2023},
  howpublished = {Course Notes for MIT 6.832}
}

@techreport{universityoftexasataustinTimelineEventsFebruary2021,
  title = {The {{Timeline}} and {{Events}} of the {{February}} 2021 {{Texas Electric Grid Blackouts}}},
  author = {{University of Texas at Austin}},
  year = {2021},
  month = jul,
  institution = {{University of Texas at Austin}},
  urldate = {2022-12-31},
  abstract = {This report recounts the factors contributing to the disruptions in electricity and natural gas service in Texas during Winter Storm Uri, with a particular focus on the outages in electrical service in the Electric Reliability Council of Texas (ERCOT) power region during the period from February 15-18, 2021. In pursuing this report's objective, the Energy Institute at the University of Texas at Austin assembled a team of faculty and researchers to identify and review credible sources of data in an attempt to provide a factual account of what happened and what went wrong during the winter storm. The report provide recommendations, but to create a common basis of fact to educate the debate over policy changes under consideration as a response to the winter storm. The report specifically limited the scope of this report to the events and economic impacts of February 2021, including a comparison to previous winter storm blackouts of 1989 and 2011. To provide additional historical context, the report include an appendix that describes the long-term evolution of the ERCOT electricity market. This report is not intended to comprehensively address all issues stemming from such a complex event, but can inform future assessments.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/JHPG38FJ/citation.html}
}

@article{vanravenzwaaijSimpleIntroductionMarkov2018,
  title = {A Simple Introduction to {{Markov Chain Monte}}--{{Carlo}} Sampling},
  author = {{van Ravenzwaaij}, Don and Cassey, Pete and Brown, Scott D.},
  year = {2018},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  volume = {25},
  number = {1},
  pages = {143--154},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1015-8},
  urldate = {2023-01-27},
  abstract = {Markov Chain Monte--Carlo (MCMC) is an increasingly popular method for obtaining information about distributions, especially for estimating posterior distributions in Bayesian inference. This article provides a very basic introduction to MCMC sampling. It describes what MCMC is, and what it can be used for, with simple illustrative examples. Highlighted are some of the benefits and limitations of MCMC sampling, as well as different approaches to circumventing the limitations most likely to trouble cognitive scientists.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/5C6CAKIY/van Ravenzwaaij et al. - 2018 - A simple introduction to Markov Chain MonteCarlo .pdf}
}

@inproceedings{vasile17,
  title = {Sampling-Based Synthesis of Maximally-Satisfying Controllers for Temporal Logic Specifications},
  booktitle = {2017 {{IEEE}}/{{RSJ}} International Conference on Intelligent Robots and Systems ({{IROS}})},
  author = {Vasile, Cristian-Ioan and Raman, Vasumathi and Karaman, Sertac},
  year = {2017},
  pages = {3840--3847},
  doi = {10.1109/IROS.2017.8206235}
}

@article{veerRecedingHorizonPlanning2022,
  title = {Receding {{Horizon Planning}} with {{Rule Hierarchies}} for {{Autonomous Vehicles}}},
  author = {Veer, Sushant and Leung, Karen and Cosner, Ryan and Chen, Yuxiao and Pavone, Marco},
  year = {2022},
  doi = {10.48550/ARXIV.2212.03323},
  urldate = {2023-05-15},
  abstract = {Autonomous vehicles must often contend with conflicting planning requirements, e.g., safety and comfort could be at odds with each other if avoiding a collision calls for slamming the brakes. To resolve such conflicts, assigning importance ranking to rules (i.e., imposing a rule hierarchy) has been proposed, which, in turn, induces rankings on trajectories based on the importance of the rules they satisfy. On one hand, imposing rule hierarchies can enhance interpretability, but introduce combinatorial complexity to planning; while on the other hand, differentiable reward structures can be leveraged by modern gradient-based optimization tools, but are less interpretable and unintuitive to tune. In this paper, we present an approach to equivalently express rule hierarchies as differentiable reward structures amenable to modern gradient-based optimizers, thereby, achieving the best of both worlds. We achieve this by formulating rank-preserving reward functions that are monotonic in the rank of the trajectories induced by the rule hierarchy; i.e., higher ranked trajectories receive higher reward. Equipped with a rule hierarchy and its corresponding rank-preserving reward function, we develop a two-stage planner that can efficiently resolve conflicting planning requirements. We demonstrate that our approach can generate motion plans in {\textasciitilde}7-10 Hz for various challenging road navigation and intersection negotiation scenarios.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Robotics (cs.RO),Systems and Control (eess.SY)}
}

@inproceedings{Venkatesh_2023_WACV,
  title = {Adversarial Robustness in Discontinuous Spaces via Alternating Sampling \& Descent},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Winter Conference on Applications of Computer Vision ({{WACV}})},
  author = {Venkatesh, Rahul and Wong, Eric and Kolter, Zico},
  year = {2023},
  month = jan,
  pages = {4662--4671}
}

@inproceedings{wangAdversarialAttackGeneration2021,
  title = {Adversarial {{Attack Generation Empowered}} by {{Min-Max Optimization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wang, Jingkang and Zhang, Tianyun and Liu, Sijia and Chen, Pin-Yu and Xu, Jiacen and Fardad, Makan and Li, Bo},
  year = {2021},
  volume = {34},
  pages = {16020--16033},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-14},
  abstract = {The worst-case training principle that minimizes the maximal adversarial loss, also known as adversarial training (AT), has shown to be a state-of-the-art approach for enhancing adversarial robustness. Nevertheless, min-max optimization beyond the purpose of AT has not been rigorously explored in the adversarial context. In this paper, we show how a general notion of min-max optimization over multiple domains can be leveraged to the design of different types of adversarial attacks. In particular, given a set of risk sources, minimizing the worst-case attack loss can be reformulated as a min-max problem by introducing domain weights that are maximized over the probability simplex of the domain set. We showcase this unified framework in three attack generation problems -- attacking model ensembles, devising universal perturbation under multiple inputs, and crafting attacks resilient to data transformations. Extensive experiments demonstrate that our approach leads to substantial attack improvement over the existing heuristic strategies as well as robustness improvement over state-of-the-art defense methods against multiple perturbation types. Furthermore, we find that the self-adjusted domain weights learned from min-max optimization can provide a holistic tool to explain the difficulty level of attack across domains.},
  keywords = {00-read}
}

@inproceedings{wangAdvSimGeneratingSafetyCritical2021,
  title = {{{AdvSim}}: {{Generating Safety-Critical Scenarios}} for {{Self-Driving Vehicles}}},
  shorttitle = {{{AdvSim}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Wang, Jingkang and Pun, Ava and Tu, James and Manivasagam, Sivabalan and Sadat, Abbas and Casas, Sergio and Ren, Mengye and Urtasun, Raquel},
  year = {2021},
  pages = {9909--9918},
  urldate = {2023-09-15},
  langid = {english},
  file = {/home/cbd/Zotero/storage/PC4RH4VP/Wang et al. - 2021 - AdvSim Generating Safety-Critical Scenarios for S.pdf}
}

@article{wangGeneralizingFewExamples2020,
  title = {Generalizing from a {{Few Examples}}: {{A Survey}} on {{Few-shot Learning}}},
  shorttitle = {Generalizing from a {{Few Examples}}},
  author = {Wang, Yaqing and Yao, Quanming and Kwok, James T. and Ni, Lionel M.},
  year = {2020},
  month = jun,
  journal = {ACM Computing Surveys},
  volume = {53},
  number = {3},
  pages = {63:1--63:34},
  issn = {0360-0300},
  doi = {10.1145/3386252},
  urldate = {2024-01-30},
  abstract = {Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research.1},
  keywords = {Few-shot learning,low-shot learning,meta-learning,one-shot learning,prior knowledge,small sample learning},
  file = {/home/cbd/Zotero/storage/QKLBWH8W/Wang et al. - 2020 - Generalizing from a Few Examples A Survey on Few-.pdf}
}

@article{wangTwostageRobustOptimization2013,
  title = {Two-Stage Robust Optimization for {{N-k}} Contingency-Constrained Unit Commitment},
  author = {Wang, Qianfan and Watson, Jean-Paul and Guan, Yongpei},
  year = {2013},
  month = aug,
  journal = {IEEE Transactions on Power Systems},
  volume = {28},
  number = {3},
  pages = {2366--2375},
  issn = {1558-0679},
  doi = {10.1109/TPWRS.2013.2244619},
  abstract = {This paper proposes a two-stage robust optimization approach to solve the N- k contingency-constrained unit commitment (CCUC) problem. In our approach, both generator and transmission line contingencies are considered. Compared to the traditional approach using a given set of components as candidates for possible failures, our approach considers all possible component failure scenarios. We consider the objectives of minimizing the total generation cost under the worst-case contingency scenario and/or the total pre-contingency cost. We formulate CCUC as a two-stage robust optimization problem and develop a decomposition framework to enable tractable computation. In our framework, the master problem makes unit commitment decisions and the subproblem discovers the worst-case contingency scenarios. By using linearization techniques and duality theory, we transform the subproblem into a mixed-integer linear program (MILP). The most violated inequalities generated from the subproblem are fed back into the master problem during each iteration. Our approach guarantees a globally optimal solution in a finite number of iterations. In reported computational experiments, we test both primal and dual decomposition approaches. Our computational results verify the effectiveness of our proposed approach.},
  keywords = {$N$-$k$ security criterion,Contingency analysis,Economics,Generators,Optimization,Power transmission lines,robust optimization,Robustness,Security,Switches,unit commitment},
  file = {/home/cbd/Zotero/storage/PLRKNZ3K/Wang et al. - 2013 - Two-stage robust optimization for N-k contingency-.pdf}
}

@inproceedings{wellingBayesianLearningStochastic2011,
  title = {Bayesian {{Learning}} via {{Stochastic Gradient Langevin Dynamics}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Welling, M. and Teh, Y.},
  year = {2011},
  month = jun,
  urldate = {2023-03-06},
  abstract = {In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a "sampling threshold" and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients.},
  file = {/home/cbd/Zotero/storage/U7WKF4VJ/Welling and Teh - 2011 - Bayesian Learning via Stochastic Gradient Langevin.pdf}
}

@article{wilsonRobotariumGloballyImpactful2020,
  title = {The {{Robotarium}}: {{Globally Impactful Opportunities}}, {{Challenges}}, and {{Lessons Learned}} in {{Remote-Access}}, {{Distributed Control}} of {{Multirobot Systems}}},
  shorttitle = {The {{Robotarium}}},
  author = {Wilson, Sean and Glotfelter, Paul and Wang, Li and Mayya, Siddharth and Notomista, Gennaro and Mote, Mark and Egerstedt, Magnus},
  year = {2020},
  month = feb,
  journal = {IEEE Control Systems Magazine},
  volume = {40},
  number = {1},
  pages = {26--44},
  issn = {1941-000X},
  doi = {10.1109/MCS.2019.2949973},
  abstract = {Distributed control has emerged as a major focus in the systems and controls area, with multiagent robotics playing a prominent role both as a canonical instantiation of a system, where control decisions must be made by individual nodes across an information-exchange network, and as a rich source of applications [1]-[5]. These applications include environmental monitoring [6], collective materials handling [7], construction [8], disaster response [9], and precision agriculture [10].},
  keywords = {Collision avoidance,Decentralized control,Mobile robots,Robot kinematics,Robot sensing systems},
  file = {/home/cbd/Zotero/storage/N5HJULP7/8960572.html}
}

@article{winkelmannProbabilisticMetamodelsEfficient2022,
  title = {Probabilistic {{Metamodels}} for an {{Efficient Characterization}} of {{Complex Driving Scenarios}}},
  author = {Winkelmann, Max and Kohlhoff, Mike and Tadjine, Hadj Hamma and M{\"u}ller, Steffen},
  year = {2022},
  month = dec,
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {23},
  number = {12},
  pages = {23896--23905},
  issn = {1558-0016},
  doi = {10.1109/TITS.2022.3206882},
  abstract = {To validate the safety of automated vehicles (AV), scenario-based testing aims to systematically describe driving scenarios an AV might encounter. In this process, continuous inputs such as velocities result in an infinite number of possible variations of a scenario. Thus, metamodels are used to perform analyses or to select specific variations for examination. However, despite the safety criticality of AV testing, metamodels are usually seen as a part of an overall approach, and their predictions are not questioned. This paper analyzes the predictive performance of Gaussian processes (GP), deep Gaussian processes, extra-trees, and Bayesian neural networks (BNN), considering four scenarios with 5 to 20 inputs. Building on this, an iterative approach is introduced and evaluated, which allows to efficiently select test cases for common analysis tasks. The results show that regarding predictive performance, the appropriate selection of test cases is more important than the choice of metamodels. However, the choice of metamodels remains crucial: Their great flexibility allows BNNs to benefit from large amounts of data and to model even the most complex scenarios. In contrast, less flexible models like GPs convince with higher reliability. Hence, relevant test cases are best explored using scalable virtual test setups and flexible models. Subsequently, more realistic test setups and more reliable models can be used for targeted testing and validation.},
  keywords = {00-read,00-relevant,Automated driving,Bayesian neural networks,Behavioral sciences,deep Gaussian processes,Gaussian processes,Probabilistic logic,probabilistic metamodels,Safety,safety validation,scenario-based testing,Task analysis,Uncertainty,Vehicles}
}

@article{wood_zhang_1996,
  title = {Estimation of the {{Lipschitz}} Constant of a Function},
  author = {Wood, G.R. and Zhang, B.P.},
  year = {1996},
  journal = {Journal of Global Optimization},
  volume = {8},
  number = {1},
  doi = {10.1007/bf00229304}
}

@inproceedings{woodNewApproachProbabilistic2014,
  title = {A {{New Approach}} to {{Probabilistic Programming Inference}}},
  booktitle = {Proceedings of the {{Seventeenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Wood, Frank and Meent, Jan Willem and Mansinghka, Vikash},
  year = {2014},
  month = apr,
  pages = {1024--1032},
  publisher = {{PMLR}},
  issn = {1938-7228},
  urldate = {2023-06-07},
  abstract = {We introduce and demonstrate a new approach to inference in expressive probabilistic programming languages based on particle Markov chain Monte Carlo. Our approach is easy to implement and to parallelize, applies to Turing-complete probabilistic programming languages, and supports accurate inference in models that make use of complex control flow, including stochastic recursion, as well as primitives from nonparametric Bayesian statistics. Our experiments show that this approach can be more efficient than previously introduced single-site Metropolis-Hastings samplers.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/CH8VCBZR/Wood et al. - 2014 - A New Approach to Probabilistic Programming Infere.pdf}
}

@article{wuComprehensiveSurveyGraph2021,
  title = {A {{Comprehensive Survey}} on {{Graph Neural Networks}}},
  author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  year = {2021},
  month = jan,
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {32},
  number = {1},
  eprint = {1901.00596},
  pages = {4--24},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {21622388},
  doi = {10.1109/TNNLS.2020.2978386},
  abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-The-Art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-Temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.},
  archiveprefix = {arxiv},
  pmid = {32217482},
  keywords = {Deep learning,graph autoencoder (GAE),graph convolutional networks (GCNs),graph neural networks (GNNs),graph representation learning,network embedding,survey},
  file = {/home/cbd/Zotero/storage/9NJMKRRL/full-text.pdf}
}

@article{xiao2010_regularized_stochastic_learning,
  title = {Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization},
  author = {Xiao, Lin},
  year = {2010},
  journal = {Journal of Machine Learning Research},
  volume = {11},
  number = {88},
  pages = {2543--2596}
}

@article{xu_uav_controllers,
  title = {Learning to Fly: {{Computational}} Controller Design for Hybrid {{UAVs}} with Reinforcement Learning},
  author = {Xu, Jie and Du, Tao and Foshey, Michael and Li, Beichen and Zhu, Bo and Schulz, Adriana and Matusik, Wojciech},
  year = {2019},
  month = jul,
  journal = {ACM Trans. Graph.},
  volume = {38},
  number = {4},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  issn = {0730-0301},
  doi = {10.1145/3306346.3322940},
  articleno = {42},
  issue_date = {July 2019},
  keywords = {hybrid UAVs,neural network controllers}
}

@inproceedings{xuAcceleratedPolicyLearning2022,
  title = {Accelerated {{Policy Learning}} with {{Parallel Differentiable Simulation}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Xu, Jie and Makoviychuk, Viktor and Narang, Yashraj and Ramos, Fabio and Matusik, Wojciech and Garg, Animesh and Macklin, Miles},
  year = {2022},
  month = jan,
  urldate = {2023-05-15},
  abstract = {Deep reinforcement learning can generate complex control policies, but requires large amounts of training data to work effectively. Recent work has attempted to address this issue by leveraging differentiable simulators. However, inherent problems such as local minima and exploding/vanishing numerical gradients prevent these methods from being generally applied to control tasks with complex contact-rich dynamics, such as humanoid locomotion in classical RL benchmarks. In this work we present a high-performance differentiable simulator and a new policy learning algorithm (SHAC) that can effectively leverage simulation gradients, even in the presence of non-smoothness. Our learning algorithm alleviates problems with local minima through a smooth critic function, avoids vanishing/exploding gradients through a truncated learning window, and allows many physical environments to be run in parallel. We evaluate our method on classical RL control tasks, and show substantial improvements in sample efficiency and wall-clock time over state-of-the-art RL and differentiable simulation-based algorithms. In addition, we demonstrate the scalability of our method by applying it to the challenging high-dimensional problem of muscle-actuated locomotion with a large action space, achieving a greater than \$17{\textbackslash}times\$ reduction in training time over the best-performing established RL algorithm. More visual results are provided at: https://short-horizon-actor-critic.github.io/.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/GUHL7T2S/Xu et al. - 2022 - Accelerated Policy Learning with Parallel Differen.pdf}
}

@article{xuAdversarialAttacksDefenses2020,
  title = {Adversarial {{Attacks}} and {{Defenses}} in {{Images}}, {{Graphs}} and {{Text}}: {{A Review}}},
  shorttitle = {Adversarial {{Attacks}} and {{Defenses}} in {{Images}}, {{Graphs}} and {{Text}}},
  author = {Xu, Han and Ma, Yao and Liu, Hao-Chen and Deb, Debayan and Liu, Hui and Tang, Ji-Liang and Jain, Anil K.},
  year = {2020},
  month = apr,
  journal = {International Journal of Automation and Computing},
  volume = {17},
  number = {2},
  pages = {151--178},
  issn = {1751-8520},
  doi = {10.1007/s11633-019-1211-x},
  urldate = {2023-01-18},
  abstract = {Deep neural networks (DNN) have achieved unprecedented success in numerous machine learning tasks in various domains. However, the existence of adversarial examples raises our concerns in adopting deep learning to safety-critical applications. As a result, we have witnessed increasing interests in studying attack and defense mechanisms for DNN models on different data types, such as images, graphs and text. Thus, it is necessary to provide a systematic and comprehensive overview of the main threats of attacks and the success of corresponding countermeasures. In this survey, we review the state of the art algorithms for generating adversarial examples and the countermeasures against adversarial examples, for three most popular data types, including images, graphs and text.},
  langid = {english},
  keywords = {Adversarial example,deep learning,defenses,model safety,robustness},
  file = {/home/cbd/Zotero/storage/98YV2YRC/Xu et al. - 2020 - Adversarial Attacks and Defenses in Images, Graphs.pdf}
}

@article{xuSafeBenchBenchmarkingPlatform2022,
  title = {{{SafeBench}}: {{A Benchmarking Platform}} for {{Safety Evaluation}} of {{Autonomous Vehicles}}},
  shorttitle = {{{SafeBench}}},
  author = {Xu, Chejian and Ding, Wenhao and Lyu, Weijie and Liu, Zuxin and Wang, Shuai and He, Yihan and Hu, Hanjiang and Zhao, Ding and Li, Bo},
  year = {2022},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {25667--25682},
  urldate = {2023-04-11},
  langid = {english}
}

@article{yaghoubiGrayboxAdversarialTesting2018,
  title = {Gray-Box {{Adversarial Testing}} for {{Control Systems}} with {{Machine Learning Component}}},
  author = {Yaghoubi, Shakiba and Fainekos, Georgios},
  year = {2018},
  month = dec,
  journal = {HSCC 2019 - Proceedings of the 2019 22nd ACM International Conference on Hybrid Systems: Computation and Control},
  eprint = {1812.11958},
  pages = {179--184},
  publisher = {{Association for Computing Machinery, Inc}},
  doi = {10.48550/arxiv.1812.11958},
  urldate = {2022-10-18},
  abstract = {Neural Networks (NN) have been proposed in the past as an effective means for both modeling and control of systems with very complex dynamics. However, despite the extensive research, NN-based controllers have not been adopted by the industry for safety critical systems. The primary reason is that systems with learning based controllers are notoriously hard to test and verify. Even harder is the analysis of such systems against system-level specifications. In this paper, we provide a gradient based method for searching the input space of a closed-loop control system in order to find adversarial samples against some system-level requirements. Our experimental results show that combined with randomized search, our method outperforms Simulated Annealing optimization.},
  archiveprefix = {arxiv},
  isbn = {9781450362825},
  keywords = {Neural network,Optimization,Testing and verification},
  file = {/home/cbd/Zotero/storage/XDZWVBP7/full-text.pdf}
}

@article{yanConvexThreeStageSCOPF2021,
  title = {A {{Convex Three-Stage SCOPF Approach}} to {{Power System Flexibility With Unified Power Flow Controllers}}},
  author = {Yan, Mingyu and Shahidehpour, Mohammad and Paaso, Aleksi and Zhang, Liuxi and Alabdulwahab, Ahmed and Abusorrah, Abdullah},
  year = {2021},
  month = may,
  journal = {IEEE Transactions on Power Systems},
  volume = {36},
  number = {3},
  pages = {1947--1960},
  issn = {1558-0679},
  doi = {10.1109/TPWRS.2020.3036653},
  abstract = {This paper proposes a methodology for enhancing the power system flexibility, which can respond properly to contingencies in real-time operations. The proposed approach introduces a unified power flow controller (UPFC) in a three-stage security-constrained optimal power flow (SCOPF). The pre- and post-contingency system operation states are divided into three stages including the base case, post-contingency short-term, and post-contingency long-term periods. The UPFC applications re-route active power flow and provide reactive power to mitigate overloads and voltage violations when line outages occur in power systems. UPFC is adopted as a fast-response corrective control device during the post-contingency short-term period, which is coordinated with the conventional slow-response corrective control system during the post-contingency long-term period. A convex approach is applied to reformulate the original nonlinear nonconvex SCOPF problem into a second-order cone programming (SOCP) problem. A two-level algorithm using Benders decomposition and sequential cone programming (SCP) is applied to solve the large-scale SOCP problem. An improved covering cut bundle (CCB) strategy is proposed to accelerate the convergence of the Benders decomposition algorithm. Numerical results show the effectiveness of the proposed model and its solution technique for enhancing the power system flexibility.},
  keywords = {Benders decomposition,convex approach,fast-response corrective action,Generators,Load flow,Power system stability,Programming,Reactive power,Security,Sensitivity,sequential cone programming,Three-stage security-constrained optimal power flow,UPFC},
  file = {/home/cbd/Zotero/storage/MAXAVR8E/Yan et al. - 2021 - A Convex Three-Stage SCOPF Approach to Power Syste.pdf}
}

@article{Yang20tro-teaser,
  title = {{{TEASER}}: {{Fast}} and Certifiable Point Cloud Registration},
  author = {Yang, H. and Shi, J. and Carlone, L.},
  year = {2020},
  journal = {IEEE Trans. Robotics}
}

@article{yangDoublyGraduatedMethod2021,
  title = {A {{Doubly Graduated Method}} for {{Inference}} in {{Markov Random Field}}},
  author = {Yang, Xu and Liu, Zhi-Yong},
  year = {2021},
  month = jan,
  journal = {SIAM Journal on Imaging Sciences},
  volume = {14},
  number = {3},
  pages = {1354--1373},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/20M1383574},
  urldate = {2024-01-03},
  abstract = {The goal of this paper is to develop a multiphase image segmentation method based on fuzzy region competition. A new variational functional with constraints is proposed by introducing fuzzy membership functions which represent several different regions in an image. The existence of a minimizer of this functional is established. We propose three methods for handling the constraints of membership functions in the minimization. We also add auxiliary variables to approximate the membership functions in the functional such that Chambolle's fast dual projection method can be used. An alternate minimization method can be employed to find the solution, in which the region parameters and the membership functions have closed form solutions. Numerical examples using grayscale and color images are given to demonstrate the effectiveness of the proposed methods.},
  file = {/home/cbd/Zotero/storage/FRNTA3V4/Yang and Liu - 2021 - A Doubly Graduated Method for Inference in Markov .pdf}
}

@article{yangSynthesisguidedAdversarialScenario2021,
  title = {Synthesis-Guided {{Adversarial Scenario Generation}} for {{Gray-box Feedback Control Systems}} with {{Sensing Imperfections}}},
  author = {Yang, Liren and Ozay, Necmiye},
  year = {2021},
  month = sep,
  journal = {ACM Transactions on Embedded Computing Systems},
  volume = {20},
  number = {5s},
  pages = {102:1--102:25},
  issn = {1539-9087},
  doi = {10.1145/3477033},
  urldate = {2023-03-14},
  abstract = {In this paper, we study feedback dynamical systems with memoryless controllers under imperfect information. We develop an algorithm that searches for ``adversarial scenarios'', which can be thought of as the strategy for the adversary representing the noise and disturbances, that lead to safety violations. The main challenge is to analyze the closed-loop system's vulnerabilities with a potentially complex or even unknown controller in the loop. As opposed to commonly adopted approaches that treat the system under test as a black-box, we propose a synthesis-guided approach, which leverages the knowledge of a plant model at hand. This hence leads to a way to deal with gray-box systems (i.e., with known plant and unknown controller). Our approach reveals the role of the imperfect information in the violation. Examples show that our approach can find non-trivial scenarios that are difficult to expose by random simulations. This approach is further extended to incorporate model mismatch and to falsify vision-in-the-loop systems against finite-time reach-avoid specifications.},
  keywords = {00-read,00-relevant,formal methods},
  file = {/home/cbd/Zotero/storage/9B6XCBBX/Yang and Ozay - 2021 - Synthesis-guided Adversarial Scenario Generation f.pdf}
}

@inproceedings{yaoAutomatedDiscoveryAdaptive2021,
  title = {Automated {{Discovery}} of {{Adaptive Attacks}} on {{Adversarial Defenses}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Yao, Chengyuan and Bielik, Pavol and Tsankov, Petar and Vechev, Martin},
  year = {2021},
  volume = {34},
  pages = {26858--26870},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-15},
  abstract = {Reliable evaluation of adversarial defenses is a challenging task, currently limited to an expert who manually crafts attacks that exploit the defense's inner workings, or to approaches based on ensemble of fixed attacks, none of which may be effective for the specific defense at hand. Our key observation is that adaptive attacks are composed from a set of reusable building blocks that can be formalized in a search space and used to automatically discover attacks for unknown defenses. We evaluated our approach on 24 adversarial defenses and show that it outperforms AutoAttack, the current state-of-the-art tool for reliable evaluation of adversarial defenses: our tool discovered significantly stronger attacks by producing 3.0\%-50.8\% additional adversarial examples for 10 models, while obtaining attacks with slightly stronger or similar strength for the remaining models.},
  keywords = {00-read}
}

@article{yoshidaSpectralNormRegularization2017,
  title = {Spectral {{Norm Regularization}} for {{Improving}} the {{Generalizability}} of {{Deep Learning}}},
  author = {Yoshida, Yuichi and Miyato, Takeru},
  year = {2017},
  month = may,
  journal = {ArXiv},
  urldate = {2024-01-22},
  abstract = {We investigate the generalizability of deep learning based on the sensitivity to input perturbation. We hypothesize that the high sensitivity to the perturbation of data degrades the performance on it. To reduce the sensitivity to perturbation, we propose a simple and effective regularization method, referred to as spectral norm regularization, which penalizes the high spectral norm of weight matrices in neural networks. We provide supportive evidence for the abovementioned hypothesis by experimentally confirming that the models trained using spectral norm regularization exhibit better generalizability than other baseline methods.},
  file = {/home/cbd/Zotero/storage/9QL356PY/Yoshida and Miyato - 2017 - Spectral Norm Regularization for Improving the Gen.pdf}
}

@article{zhang_mdo_analysis,
  title = {Study on Multidisciplinary Design Optimization of a 2-Degree-of-Freedom Robot Based on Sensitivity Analysis and Structural Analysis},
  author = {Zhang, Jing and Liu, Jinzeng and Wang, Chengjie and Song, Yang and Li, Bailin},
  year = {2017},
  journal = {Advances in Mechanical Engineering},
  volume = {9},
  number = {4},
  eprint = {https://doi.org/10.1177/1687814017696656},
  pages = {1687814017696656},
  doi = {10.1177/1687814017696656}
}

@inproceedings{zhangAdversarialRobustnessTrajectory2022,
  title = {On {{Adversarial Robustness}} of {{Trajectory Prediction}} for {{Autonomous Vehicles}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Zhang, Qingzhao and Hu, Shengtuo and Sun, Jiachen and Chen, Qi Alfred and Mao, Z. Morley},
  year = {2022},
  pages = {15159--15168},
  urldate = {2023-04-12},
  langid = {english}
}

@article{zhangBayesianSpatialModelling2016,
  title = {Bayesian {{Spatial Modelling}} for {{High Dimensional Seismic Inverse Problems}}},
  author = {Zhang, Ran and Czado, Claudia and Sigloch, Karin},
  year = {2016},
  month = feb,
  journal = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  volume = {65},
  number = {2},
  pages = {187--213},
  issn = {0035-9254},
  doi = {10.1111/rssc.12118},
  urldate = {2024-01-19},
  abstract = {We study the application of Bayesian spatial modelling to seismic tomography, a geophysical, high dimensional, linearized inverse problem that infers the three-dimensional structure of the Earth's interior. We develop a spatial dependence model of seismic wave velocity variations in the Earth's mantle based on a Gaussian Mat{\'e}rn field approximation. Using the theory of stochastic partial differential equations, this model quantifies the uncertainties in the parameter space by means of the integrated nested Laplace approximation. In resolution tests using simulated data and in inversions using real data, our model matches the performance of conventional deterministic optimization approaches in retrieving three-dimensional structure of the Earth's mantle. In addition it delivers estimates of the full parameter covariance matrix. Our model substantially improves on previous work relying on Markov chain Monte Carlo methods in terms of statistical misfits and computing time.},
  file = {/home/cbd/Zotero/storage/IHGWEEVG/Zhang et al. - 2016 - Bayesian Spatial Modelling for High Dimensional Se.pdf}
}

@misc{zhangFindingCriticalScenarios2021,
  title = {Finding {{Critical Scenarios}} for {{Automated Driving Systems}}: {{A Systematic Literature Review}}},
  shorttitle = {Finding {{Critical Scenarios}} for {{Automated Driving Systems}}},
  author = {Zhang, Xinhai and Tao, Jianbo and Tan, Kaige and T{\"o}rngren, Martin and S{\'a}nchez, Jos{\'e} Manuel Gaspar and Ramli, Muhammad Rusyadi and Tao, Xin and Gyllenhammar, Magnus and Wotawa, Franz and Mohan, Naveen and Nica, Mihai and Felbinger, Hermann},
  year = {2021},
  month = oct,
  number = {arXiv:2110.08664},
  eprint = {2110.08664},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2110.08664},
  urldate = {2023-03-14},
  abstract = {Scenario-based approaches have been receiving a huge amount of attention in research and engineering of automated driving systems. Due to the complexity and uncertainty of the driving environment, and the complexity of the driving task itself, the number of possible driving scenarios that an ADS or ADAS may encounter is virtually infinite. Therefore it is essential to be able to reason about the identification of scenarios and in particular critical ones that may impose unacceptable risk if not considered. Critical scenarios are particularly important to support design, verification and validation efforts, and as a basis for a safety case. In this paper, we present the results of a systematic literature review in the context of autonomous driving. The main contributions are: (i) introducing a comprehensive taxonomy for critical scenario identification methods; (ii) giving an overview of the state-of-the-art research based on the taxonomy encompassing 86 papers between 2017 and 2020; and (iii) identifying open issues and directions for further research. The provided taxonomy comprises three main perspectives encompassing the problem definition (the why), the solution (the methods to derive scenarios), and the assessment of the established scenarios. In addition, we discuss open research issues considering the perspectives of coverage, practicability, and scenario space explosion.},
  archiveprefix = {arxiv},
  keywords = {00-read,Computer Science - Artificial Intelligence,Computer Science - Software Engineering,Electrical Engineering and Systems Science - Systems and Control},
  file = {/home/cbd/Zotero/storage/VCFPRRQ7/Zhang et al. - 2021 - Finding Critical Scenarios for Automated Driving S.pdf;/home/cbd/Zotero/storage/7BXY8JZM/2110.html}
}

@article{zhangGaussianProcessBasedConfidence2021,
  title = {Gaussian {{Process-Based Confidence Estimation}} for {{Hybrid System Falsification}}},
  author = {Zhang, Zhenya and Arcaini, Paolo},
  year = {2021},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {13047 LNCS},
  pages = {330--348},
  publisher = {{Springer Science and Business Media Deutschland GmbH}},
  issn = {16113349},
  doi = {10.1007/978-3-030-90870-6_18},
  urldate = {2022-10-18},
  abstract = {Cyber-Physical Systems (CPSs) are widely adopted in safety-critical domains, raising great demands on their quality assurance. However, the application of formal verification is limited due to the continuous dynamics of CPSs. Instead, simulation-based falsification, which aims at finding a counterexample to refute the system specification, is a more feasible and hence actively pursued approach. Falsification adopts an optimization approach, treating robustness, given by the quantitative semantics of the specification language (usually Signal Temporal Logic (STL)), as the objective function. However, similarly to traditional testing, in the absence of found counterexamples, falsification does not give any guarantee on the system safety. To fill this gap, in this paper, we propose a confidence measure that estimates the probability that a formal specification is indeed not falsifiable, by relying on the information encapsulated in the simulation data collected during falsification. Methodologically, we approximate the robustness domain by feeding simulation data into a Gaussian Process (GP) Regression process; we then do a minimization sampling on the trained GP, and then estimate the probability that all the robustness values inferred from these sampled points are positive; we take this probability as the confidence measure. We experimentally study the properties of monotonicity and soundness of the proposed confidence measure. We also apply the measure to several state-of-the-art falsification algorithms to assess the maximum confidence they provide when they do not find a falsifying input, and the stability of such confidence across different repetitions.},
  isbn = {9783030908690},
  keywords = {Confidence estimation,Gaussian process regression,Hybrid system falsification,Surrogate model},
  file = {/home/cbd/Zotero/storage/APCM2AQJ/full-text.pdf}
}

@article{zhangMachineLearningTesting2022,
  title = {Machine {{Learning Testing}}: {{Survey}}, {{Landscapes}} and {{Horizons}}},
  shorttitle = {Machine {{Learning Testing}}},
  author = {Zhang, Jie M. and Harman, Mark and Ma, Lei and Liu, Yang},
  year = {2022},
  month = jan,
  journal = {IEEE Transactions on Software Engineering},
  volume = {48},
  number = {1},
  pages = {1--36},
  issn = {1939-3520},
  doi = {10.1109/TSE.2019.2962027},
  abstract = {This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.},
  keywords = {00-read,Data models,deep neural network,Machine learning,Robustness,Software engineering,software testing,Software testing,Training data},
  file = {/home/cbd/Zotero/storage/K7YMMU2V/Zhang et al. - 2022 - Machine Learning Testing Survey, Landscapes and H.pdf;/home/cbd/Zotero/storage/54HKEXZZ/9000651.html}
}

@inproceedings{zhaoPhysicsbasedDifferentiableRendering2020,
  title = {Physics-Based Differentiable Rendering: {{From}} Theory to Implementation},
  shorttitle = {Physics-Based Differentiable Rendering},
  booktitle = {{{ACM SIGGRAPH}} 2020 {{Courses}}},
  author = {Zhao, Shuang and Jakob, Wenzel and Li, Tzu-Mao},
  year = {2020},
  month = aug,
  series = {{{SIGGRAPH}} '20},
  pages = {1--30},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3388769.3407454},
  urldate = {2023-07-06},
  abstract = {Physics-based rendering algorithms generate photorealistic images by simulating the flow of light through a detailed mathematical representation of a virtual scene. In contrast, physics-based differentiable rendering algorithms focus on computing derivative of images exhibiting complex light transport effects (e.g., soft shadows, interreflection, and caustics) with respect to arbitrary scene parameters such as camera pose, object geometry (e.g., vertex positions) as well as spatially varying material properties expressed as 2D textures and 3D volumes. This new level of generality has made physics-based differentiable rendering a key ingredient for solving many challenging inverse-rendering problems, that is, the search of scene configurations optimizing user-specified objective functions, using gradient-based methods (as illustrated in the figure below). Further, these techniques can be incorporated into probabilistic inference and machine learning pipelines. For instance, differentiable renderers allow "rendering losses" to be computed with complex light transport effects captured. Additionally, they can be used as generative models that synthesize photorealistic images.},
  isbn = {978-1-4503-7972-4},
  file = {/home/cbd/Zotero/storage/T33J5F72/Zhao et al. - 2020 - Physics-based differentiable rendering from theor.pdf}
}

@misc{zhongGuidedConditionalDiffusion2022,
  title = {Guided {{Conditional Diffusion}} for {{Controllable Traffic Simulation}}},
  author = {Zhong, Ziyuan and Rempe, Davis and Xu, Danfei and Chen, Yuxiao and Veer, Sushant and Che, Tong and Ray, Baishakhi and Pavone, Marco},
  year = {2022},
  month = oct,
  number = {arXiv:2210.17366},
  eprint = {2210.17366},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.17366},
  urldate = {2023-05-15},
  abstract = {Controllable and realistic traffic simulation is critical for developing and verifying autonomous vehicles. Typical heuristic-based traffic models offer flexible control to make vehicles follow specific trajectories and traffic rules. On the other hand, data-driven approaches generate realistic and human-like behaviors, improving transfer from simulated to real-world traffic. However, to the best of our knowledge, no traffic model offers both controllability and realism. In this work, we develop a conditional diffusion model for controllable traffic generation (CTG) that allows users to control desired properties of trajectories at test time (e.g., reach a goal or follow a speed limit) while maintaining realism and physical feasibility through enforced dynamics. The key technical idea is to leverage recent advances from diffusion modeling and differentiable logic to guide generated trajectories to meet rules defined using signal temporal logic (STL). We further extend guidance to multi-agent settings and enable interaction-based rules like collision avoidance. CTG is extensively evaluated on the nuScenes dataset for diverse and composite rules, demonstrating improvement over strong baselines in terms of the controllability-realism tradeoff.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/home/cbd/Zotero/storage/XG42IRCD/Zhong et al. - 2022 - Guided Conditional Diffusion for Controllable Traf.pdf;/home/cbd/Zotero/storage/A5764ITL/2210.html}
}

@article{zhouGradientBasedAdaptiveStochastic2014,
  title = {Gradient-{{Based Adaptive Stochastic Search}} for {{Non-Differentiable Optimization}}},
  author = {Zhou, Enlu and Hu, Jiaqiao},
  year = {2014},
  month = jul,
  journal = {IEEE Transactions on Automatic Control},
  volume = {59},
  number = {7},
  pages = {1818--1832},
  issn = {1558-2523},
  doi = {10.1109/TAC.2014.2310052},
  abstract = {In this paper, we propose a stochastic search algorithm for solving general optimization problems with little structure. The algorithm iteratively finds high quality solutions by randomly sampling candidate solutions from a parameterized distribution model over the solution space. The basic idea is to convert the original (possibly non-differentiable) problem into a differentiable optimization problem on the parameter space of the parameterized sampling distribution, and then use a direct gradient search method to find improved sampling distributions. Thus, the algorithm combines the robustness feature of stochastic search from considering a population of candidate solutions with the relative fast convergence speed of classical gradient methods by exploiting local differentiable structures. We analyze the convergence and converge rate properties of the proposed algorithm, and carry out numerical study to illustrate its performance.},
  keywords = {00-read,Aerospace electronics,Approximation algorithms,Approximation methods,black-box optimization,Convergence,Optimization,Reactive power,Stochastic approximation,Stochastic processes,stochastic search},
  file = {/home/cbd/Zotero/storage/3HXZ7PYS/Zhou and Hu - 2014 - Gradient-Based Adaptive Stochastic Search for Non-.pdf}
}

@article{zhouHamiltonianMonteCarlo2018,
  title = {Hamiltonian {{Monte Carlo}} for {{Probabilistic Programs}} with {{Discontinuities}}},
  author = {Zhou, Yuan and {Gram-Hansen}, Bradley J and Kohn, Tobias and Rainforth, Tom and Yang, Hongseok and Wood, Kaist Frank},
  year = {2018},
  month = apr,
  eprint = {1804.03523},
  doi = {10.48550/arxiv.1804.03523},
  urldate = {2022-09-29},
  abstract = {Hamiltonian Monte Carlo (HMC) is arguably the dominant statistical inference algorithm used in most popular "first-order differentiable" Probabilistic Programming Languages (PPLs). However, the fact that HMC uses derivative information causes complications when the target distribution is non-differentiable with respect to one or more of the latent variables. In this paper, we show how to use extensions to HMC to perform inference in probabilistic programs that contain discontinuities. To do this, we design a Simple first-order Probabilistic Programming Language (SPPL) that contains a sufficient set of language restrictions together with a compilation scheme. This enables us to preserve both the statistical and syntactic interpretation of if-else statements in the probabilistic program, within the scope of first-order PPLs. We also provide a corresponding mathematical formalism that ensures any joint density denoted in such a language has a suitably low measure of discontinuities.},
  archiveprefix = {arxiv},
  keywords = {compilers,discontinu-ous densities,HMC,probabilistic programming},
  file = {/home/cbd/Zotero/storage/SI3HSDAY/full-text.pdf}
}

@inproceedings{zhouRoCUSRobotController2021,
  title = {{{RoCUS}}: {{Robot Controller Understanding}} via {{Sampling}}},
  shorttitle = {{{RoCUS}}},
  booktitle = {5th {{Annual Conference}} on {{Robot Learning}}},
  author = {Zhou, Yilun and Booth, Serena and Figueroa, Nadia and Shah, Julie},
  year = {2021},
  month = nov,
  urldate = {2022-12-31},
  abstract = {As robots are deployed in complex situations, engineers and end users must develop a holistic understanding of their behaviors, capabilities, and limitations. Some behaviors are directly optimized by the objective function. They often include success rate, completion time or energy consumption. Other behaviors -- e.g., collision avoidance, trajectory smoothness or motion legibility -- are typically emergent but equally important for safe and trustworthy deployment. Designing an objective which optimizes every aspect of robot behavior is hard. In this paper, we advocate for systematic analysis of a wide array of behaviors for holistic understanding of robot controllers and, to this end, propose a framework, RoCUS, which uses Bayesian posterior sampling to find situations where the robot controller exhibits user-specified behaviors, such as highly jerky motions. We use RoCUS to analyze three controller classes (deep learning models, rapidly exploring random trees and dynamical system formulations) on two domains (2D navigation and a 7 degree-of-freedom arm reaching), and uncover insights to further our understanding of these controllers and ultimately improve their designs.},
  langid = {english},
  file = {/home/cbd/Zotero/storage/Z9266Q4V/Zhou et al. - 2021 - RoCUS Robot Controller Understanding via Sampling.pdf}
}

@article{zimmermanMATPOWERSteadyStateOperations2011,
  title = {{{MATPOWER}}: {{Steady-State Operations}}, {{Planning}}, and {{Analysis Tools}} for {{Power Systems Research}} and {{Education}}},
  shorttitle = {{{MATPOWER}}},
  author = {Zimmerman, Ray Daniel and {Murillo-S{\'a}nchez}, Carlos Edmundo and Thomas, Robert John},
  year = {2011},
  month = feb,
  journal = {IEEE Transactions on Power Systems},
  volume = {26},
  number = {1},
  pages = {12--19},
  issn = {1558-0679},
  doi = {10.1109/TPWRS.2010.2051168},
  abstract = {MATPOWER is an open-source Matlab-based power system simulation package that provides a high-level set of power flow, optimal power flow (OPF), and other tools targeted toward researchers, educators, and students. The OPF architecture is designed to be extensible, making it easy to add user-defined variables, costs, and constraints to the standard OPF problem. This paper presents the details of the network modeling and problem formulations used by MATPOWER, including its extensible OPF architecture. This structure is used internally to implement several extensions to the standard OPF problem, including piece-wise linear cost functions, dispatchable loads, generator capability curves, and branch angle difference limits. Simulation results are presented for a number of test cases comparing the performance of several available OPF solvers and demonstrating MATPOWER's ability to solve large-scale AC and DC OPF problems.},
  keywords = {Computer languages,Costs,Load flow,Load flow analysis,Mathematical model,Open source software,optimal power flow,optimization methods,Packaging,power engineering,power engineering education,Power system analysis computing,power system economics,Power system planning,power system simulation,Power system simulation,power systems,simulation software,software tools,Steady-state},
  file = {/home/cbd/Zotero/storage/ZZCIH3Y6/Zimmerman et al. - 2011 - MATPOWER Steady-State Operations, Planning, and A.pdf}
}
